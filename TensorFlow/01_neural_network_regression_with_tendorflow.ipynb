{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Regression with Neural Networks in TensorFlow\n",
        "\n",
        "There are many definitions for a regression problem but in our case, we're going to simplify it: predicting a numerical variable based on some other combination of variables, even shorter... predicting a number "
      ],
      "metadata": {
        "id": "ktJ5jWbBpLo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNACRZ86rGBT",
        "outputId": "b60ecc50-71cf-4096-9614-49f02a266c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(X, y);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "f2WGhqe6rOfO",
        "outputId": "2d61bf08-eba4-44ab-a8d8-217caf8d1bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y == X+10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vF1nI5js02-",
        "outputId": "d76da976-666d-4274-a0d2-afe0fb4af082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input and output shapes"
      ],
      "metadata": {
        "id": "SjYLAq3UtCDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a demo tensor for our housing price prediction problem\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QffV8XzhtNgQ",
        "outputId": "197b9f0a-05e2-42ca-b365-ecc2bdaf2bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features (using tensors)\n",
        "X = tf.constant([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels (using tensors)\n",
        "y = tf.constant([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(X, y);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "-DlUWSj-Xj3U",
        "outputId": "af28d45f-1029-44df-948e-7fadbf4847bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a single example of X\n",
        "input_shape = X[0].shape \n",
        "\n",
        "# Take a single example of y\n",
        "output_shape = y[0].shape\n",
        "\n",
        "input_shape, output_shape # these are both scalars (no shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdP8nQpct1-g",
        "outputId": "6af76ffb-cb61-407a-e01b-bbfd06ad8b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's take a look at the single examples invidually\n",
        "X[0], y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvD9DnV1Xrsm",
        "outputId": "296d1c92-5ab0-4512-f05f-775259657ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=-7.0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=3.0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps in creating a model with TensorFlow\n",
        "\n",
        "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
        "2. **Compiling a model** - define the loss function (in other words, the function tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns it is learning) and evaluation metrics (what we can use to interpret the performance of our model).\n",
        "3. **Fitting a model** - letting the model try to find patterns between X and y (features and labels)"
      ],
      "metadata": {
        "id": "6mrQ7dO-vjEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, # mae is short for mean absolute error\n",
        "              optimizer=tf.keras.optimizers.SGD(), # SGD is short for stochastic gradient descent\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "# model.fit(X, y, epochs=5) # this will break with TensorFlow 2.7.0+\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNunhgrBwsdq",
        "outputId": "c0f228a9-10b6-4d9e-b1f4-52ea3fffa030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 13.0725 - mae: 13.0725\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.9400 - mae: 12.9400\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.8075 - mae: 12.8075\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.6750 - mae: 12.6750\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.5425 - mae: 12.5425\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f87495f9730>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out X and y\n",
        "X, y"
      ],
      "metadata": {
        "id": "VwJj73xe5fMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "363d6a0f-dfa0-4322-f56f-f92e3fff3c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try and make prediction using our model\n",
        "pred = model.predict([17.0])\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6VjPSolV5mY",
        "outputId": "e9f43d41-7b56-4005-b776-cc5f86513501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 89ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1012044]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred + 11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO9oYRYjWB15",
        "outputId": "abacfd00-46e0-4d49-c707-a06f533efdab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16.101204]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving our model\n",
        "\n",
        "We can improve our model, by altering the steps we took to create a model.\n",
        "\n",
        "1. **Creating a model** - Here we might add more layers, increase the number of hidden units (all called neurons) within each of the hidden layers, change the activation fucntion of each layer.\n",
        "\n",
        "2. **Compiling a model** - Here we might change the optimization function or perhaps the **learning rate** of the optimization function.\n",
        "\n",
        "3. **Fitting the model** - Here we might fit a model for more **epochs** (leave it training for longer) or on more data (give the model more examples to learn from)."
      ],
      "metadata": {
        "id": "H6SkxNUxWQqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model (same as above)\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile model (same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit model (this time we'll train for longer)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100) # train for 100 epochs not 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4FkG9TzZidR",
        "outputId": "9b26e87a-1fc7-417d-cd61-c367289823a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 11.9537 - mae: 11.9537\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.8212 - mae: 11.8212\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.6887 - mae: 11.6887\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.5562 - mae: 11.5562\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.4237 - mae: 11.4237\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.2912 - mae: 11.2912\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.1587 - mae: 11.1587\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.0262 - mae: 11.0262\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.8937 - mae: 10.8937\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.7612 - mae: 10.7612\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.6287 - mae: 10.6287\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.4962 - mae: 10.4962\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.3637 - mae: 10.3637\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.2312 - mae: 10.2312\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.0987 - mae: 10.0987\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.9662 - mae: 9.9662\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.8337 - mae: 9.8337\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.7012 - mae: 9.7012\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.5687 - mae: 9.5687\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.4362 - mae: 9.4362\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.3037 - mae: 9.3037\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.1712 - mae: 9.1712\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0387 - mae: 9.0387\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.9062 - mae: 8.9062\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7737 - mae: 8.7737\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.6412 - mae: 8.6412\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.5087 - mae: 8.5087\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3762 - mae: 8.3762\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.2437 - mae: 8.2437\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.1112 - mae: 8.1112\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.9787 - mae: 7.9787\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.8462 - mae: 7.8462\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.7137 - mae: 7.7137\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.5812 - mae: 7.5812\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.4487 - mae: 7.4487\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.3162 - mae: 7.3162\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1738 - mae: 7.1738\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1062 - mae: 7.1062\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8869 - mae: 6.8869\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8813 - mae: 6.8813\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8756 - mae: 6.8756\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8750d961f0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remind ourselves of the data\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07n-A07EfgSm",
        "outputId": "061ab697-5979-4d50-cc25-7c37d1e2b5ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if our model's prediction has improved\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeeVmefDgI2u",
        "outputId": "57eb3699-98eb-4d48-f210-43eb6ab3993c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.770662]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the optimizers of the original model\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model (same as above)\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile model (same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(lr = 0.0001),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit model (this time we'll train for longer)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100) # train for 100 epochs not 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hqix-HFgU6b",
        "outputId": "10ab7c1f-4a1d-4b86-a509-c237086f962c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 9.0086 - mae: 9.0086\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.0041 - mae: 9.0041\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9996 - mae: 8.9996\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9951 - mae: 8.9951\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9906 - mae: 8.9906\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9861 - mae: 8.9861\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9816 - mae: 8.9816\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9771 - mae: 8.9771\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9726 - mae: 8.9726\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9681 - mae: 8.9681\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9636 - mae: 8.9636\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9591 - mae: 8.9591\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.9546 - mae: 8.9546\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.9501 - mae: 8.9501\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9456 - mae: 8.9456\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9411 - mae: 8.9411\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9366 - mae: 8.9366\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9321 - mae: 8.9321\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9276 - mae: 8.9276\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9231 - mae: 8.9231\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9186 - mae: 8.9186\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9141 - mae: 8.9141\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9096 - mae: 8.9096\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9051 - mae: 8.9051\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9006 - mae: 8.9006\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8961 - mae: 8.8961\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8916 - mae: 8.8916\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.8871 - mae: 8.8871\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.8826 - mae: 8.8826\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.8781 - mae: 8.8781\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.8736 - mae: 8.8736\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8691 - mae: 8.8691\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.8646 - mae: 8.8646\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8601 - mae: 8.8601\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8556 - mae: 8.8556\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8511 - mae: 8.8511\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8466 - mae: 8.8466\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.8421 - mae: 8.8421\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8376 - mae: 8.8376\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8331 - mae: 8.8331\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8286 - mae: 8.8286\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8241 - mae: 8.8241\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.8196 - mae: 8.8196\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.8151 - mae: 8.8151\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.8106 - mae: 8.8106\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8061 - mae: 8.8061\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.8016 - mae: 8.8016\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.7971 - mae: 8.7971\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.7926 - mae: 8.7926\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7881 - mae: 8.7881\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7836 - mae: 8.7836\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7791 - mae: 8.7791\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7746 - mae: 8.7746\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7701 - mae: 8.7701\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7656 - mae: 8.7656\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.7611 - mae: 8.7611\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.7566 - mae: 8.7566\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7521 - mae: 8.7521\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.7476 - mae: 8.7476\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7431 - mae: 8.7431\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.7386 - mae: 8.7386\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7341 - mae: 8.7341\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7296 - mae: 8.7296\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7251 - mae: 8.7251\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.7206 - mae: 8.7206\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.7161 - mae: 8.7161\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7115 - mae: 8.7115\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7071 - mae: 8.7071\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.7025 - mae: 8.7025\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.6980 - mae: 8.6980\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.6936 - mae: 8.6936\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.6890 - mae: 8.6890\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.6845 - mae: 8.6845\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.6800 - mae: 8.6800\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.6755 - mae: 8.6755\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.6710 - mae: 8.6710\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.6665 - mae: 8.6665\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.6620 - mae: 8.6620\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.6575 - mae: 8.6575\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.6530 - mae: 8.6530\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.6485 - mae: 8.6485\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.6440 - mae: 8.6440\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.6395 - mae: 8.6395\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.6350 - mae: 8.6350\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.6305 - mae: 8.6305\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.6260 - mae: 8.6260\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.6215 - mae: 8.6215\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.6170 - mae: 8.6170\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.6125 - mae: 8.6125\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.6080 - mae: 8.6080\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.6035 - mae: 8.6035\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.5990 - mae: 8.5990\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.5945 - mae: 8.5945\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.5900 - mae: 8.5900\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.5855 - mae: 8.5855\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5810 - mae: 8.5810\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5765 - mae: 8.5765\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5720 - mae: 8.5720\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5675 - mae: 8.5675\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5630 - mae: 8.5630\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8749f53370>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if our model's prediction has improved\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSKrv9qDgtzN",
        "outputId": "bc8b8d86-7ce5-4590-9fb6-87153206f257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23.615639]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding an extra layer to the original model with 100 hidden units\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model (same as above)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation = \"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile model (same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit model (this time we'll train for longer)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100) # train for 100 epochs not 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEW1RUckgyVA",
        "outputId": "c72fe1d5-a3f5-4c85-d479-59bfb9ba6f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 455ms/step - loss: 12.4330 - mae: 12.4330\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.9899 - mae: 11.9899\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.5354 - mae: 11.5354\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.0792 - mae: 11.0792\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.6038 - mae: 10.6038\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.1051 - mae: 10.1051\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.5781 - mae: 9.5781\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0194 - mae: 9.0194\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4253 - mae: 8.4253\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.8594 - mae: 7.8594\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2396 - mae: 7.2396\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.5654 - mae: 6.5654\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.8315 - mae: 5.8315\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 5.0310 - mae: 5.0310\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1839 - mae: 4.1839\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0930 - mae: 4.0930\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9995 - mae: 3.9995\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9056 - mae: 3.9056\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9664 - mae: 3.9664\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9005 - mae: 3.9005\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9579 - mae: 3.9579\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9061 - mae: 3.9061\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9320 - mae: 3.9320\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9119 - mae: 3.9119\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9059 - mae: 3.9059\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9196 - mae: 3.9196\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8895 - mae: 3.8895\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9342 - mae: 3.9342\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8687 - mae: 3.8687\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9337 - mae: 3.9337\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8746 - mae: 3.8746\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9075 - mae: 3.9075\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8805 - mae: 3.8805\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.8830 - mae: 3.8830\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8971 - mae: 3.8971\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8644 - mae: 3.8644\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9032 - mae: 3.9032\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8381 - mae: 3.8381\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9082 - mae: 3.9082\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8442 - mae: 3.8442\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8817 - mae: 3.8817\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8515 - mae: 3.8515\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8649 - mae: 3.8649\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8670 - mae: 3.8670\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8381 - mae: 3.8381\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8734 - mae: 3.8734\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8111 - mae: 3.8111\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8799 - mae: 3.8799\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8148 - mae: 3.8148\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8560 - mae: 3.8560\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8316 - mae: 3.8316\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8376 - mae: 3.8376\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8380 - mae: 3.8380\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8104 - mae: 3.8104\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8446 - mae: 3.8446\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7832 - mae: 3.7832\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8513 - mae: 3.8513\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7874 - mae: 3.7874\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8362 - mae: 3.8362\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8035 - mae: 3.8035\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8089 - mae: 3.8089\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8101 - mae: 3.8101\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7814 - mae: 3.7814\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8169 - mae: 3.8169\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7539 - mae: 3.7539\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8241 - mae: 3.8241\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7698 - mae: 3.7698\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8064 - mae: 3.8064\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7764 - mae: 3.7764\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7788 - mae: 3.7788\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7832 - mae: 3.7832\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7512 - mae: 3.7512\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7902 - mae: 3.7902\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7267 - mae: 3.7267\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8031 - mae: 3.8031\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7436 - mae: 3.7436\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7754 - mae: 3.7754\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7504 - mae: 3.7504\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7475 - mae: 3.7475\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7575 - mae: 3.7575\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7195 - mae: 3.7195\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7647 - mae: 3.7647\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7110 - mae: 3.7110\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7711 - mae: 3.7711\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7184 - mae: 3.7184\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7431 - mae: 3.7431\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7255 - mae: 3.7255\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7149 - mae: 3.7149\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7327 - mae: 3.7327\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6866 - mae: 3.6866\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7491 - mae: 3.7491\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6871 - mae: 3.6871\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7378 - mae: 3.7378\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6942 - mae: 3.6942\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7094 - mae: 3.7094\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7015 - mae: 3.7015\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6809 - mae: 3.6809\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7090 - mae: 3.7090\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6609 - mae: 3.6609\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7269 - mae: 3.7269\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8749ebc700>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if our model's prediction has improved\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0moicMsWhOzD",
        "outputId": "287ac55a-0343-4b4d-f2be-37b6ce7ca52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 415ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[32.08952]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the activation functions\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model (same as above)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(50, activation = None),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile model (same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit model (this time we'll train for longer)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100) # train for 100 epochs not 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnMVGILThbeh",
        "outputId": "7defa281-676d-4ef0-ad7c-68d16c8ad636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 13.2612 - mae: 13.2612\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.7666 - mae: 12.7666\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 12.2695 - mae: 12.2695\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 11.7672 - mae: 11.7672\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 11.2572 - mae: 11.2572\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 10.7369 - mae: 10.7369\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 10.2035 - mae: 10.2035\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 9.6544 - mae: 9.6544\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.0867 - mae: 9.0867\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.4976 - mae: 8.4976\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.8839 - mae: 7.8839\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.2426 - mae: 7.2426\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.1803 - mae: 7.1803\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.1582 - mae: 7.1582\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.1361 - mae: 7.1361\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.1139 - mae: 7.1139\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.1028 - mae: 7.1028\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.0815 - mae: 7.0815\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.0598 - mae: 7.0598\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.0379 - mae: 7.0379\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.0160 - mae: 7.0160\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9940 - mae: 6.9940\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.9719 - mae: 6.9719\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.9497 - mae: 6.9497\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.9275 - mae: 6.9275\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.9051 - mae: 6.9051\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.8827 - mae: 6.8827\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 6.8601 - mae: 6.8601\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.8375 - mae: 6.8375\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.8147 - mae: 6.8147\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.7919 - mae: 6.7919\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.7689 - mae: 6.7689\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.7458 - mae: 6.7458\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.7226 - mae: 6.7226\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 6.6992 - mae: 6.6992\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.6757 - mae: 6.6757\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.6521 - mae: 6.6521\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.6284 - mae: 6.6284\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.6045 - mae: 6.6045\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 6.5805 - mae: 6.5805\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.5563 - mae: 6.5563\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.5319 - mae: 6.5319\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.5121 - mae: 6.5121\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.5024 - mae: 6.5024\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 6.4782 - mae: 6.4782\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.4538 - mae: 6.4538\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.4292 - mae: 6.4292\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 6.4044 - mae: 6.4044\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.3795 - mae: 6.3795\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 6.3544 - mae: 6.3544\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 6.3291 - mae: 6.3291\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 6.3036 - mae: 6.3036\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 6.2779 - mae: 6.2779\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.2520 - mae: 6.2520\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 6.2259 - mae: 6.2259\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 6.1996 - mae: 6.1996\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 6.1730 - mae: 6.1730\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.1463 - mae: 6.1463\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 6.1193 - mae: 6.1193\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 6.0921 - mae: 6.0921\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.0646 - mae: 6.0646\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.0395 - mae: 6.0395\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.0341 - mae: 6.0341\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 6.0065 - mae: 6.0065\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.9787 - mae: 5.9787\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 5.9506 - mae: 5.9506\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 5.9223 - mae: 5.9223\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.8937 - mae: 5.8937\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 5.8648 - mae: 5.8648\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 5.8356 - mae: 5.8356\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.8062 - mae: 5.8062\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.7765 - mae: 5.7765\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 5.7465 - mae: 5.7465\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.7162 - mae: 5.7162\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 5.6856 - mae: 5.6856\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.6547 - mae: 5.6547\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.6234 - mae: 5.6234\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.5919 - mae: 5.5919\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.5876 - mae: 5.5876\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.5577 - mae: 5.5577\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.5258 - mae: 5.5258\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.4935 - mae: 5.4935\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.4609 - mae: 5.4609\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.4280 - mae: 5.4280\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 5.3947 - mae: 5.3947\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.3611 - mae: 5.3611\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3270 - mae: 5.3270\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 5.2926 - mae: 5.2926\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 5.2579 - mae: 5.2579\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.2227 - mae: 5.2227\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.1871 - mae: 5.1871\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.1512 - mae: 5.1512\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.1250 - mae: 5.1250\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.1894 - mae: 5.1894\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.2330 - mae: 5.2330\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.0342 - mae: 5.0342\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.9967 - mae: 4.9967\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 4.9588 - mae: 4.9588\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.9204 - mae: 4.9204\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.8816 - mae: 4.8816\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f87498a3a30>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if our model's prediction has improved\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmiGGiwJtbNd",
        "outputId": "c922829d-359f-4ed6-b98a-cefeeabeeaa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87498c3c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 309ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[30.035942]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the optimization function\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model (same as above)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(50, activation = None),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile model (same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit model (this time we'll train for longer)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100) # train for 100 epochs not 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuX01-Ketjk-",
        "outputId": "319dd333-9e07-4aac-d78c-728eb6168ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 14.2911 - mae: 14.2911\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 14.2265 - mae: 14.2265\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 14.1617 - mae: 14.1617\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 14.0969 - mae: 14.0969\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 14.0321 - mae: 14.0321\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 13.9672 - mae: 13.9672\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 13.9022 - mae: 13.9022\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 13.8371 - mae: 13.8371\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 13.7719 - mae: 13.7719\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 13.7066 - mae: 13.7066\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 13.6413 - mae: 13.6413\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 13.5758 - mae: 13.5758\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 13.5103 - mae: 13.5103\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 13.4446 - mae: 13.4446\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 13.3789 - mae: 13.3789\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 13.3130 - mae: 13.3130\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 13.2469 - mae: 13.2469\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 13.1808 - mae: 13.1808\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 13.1145 - mae: 13.1145\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 13.0480 - mae: 13.0480\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 12.9814 - mae: 12.9814\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 12.9146 - mae: 12.9146\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 12.8477 - mae: 12.8477\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 12.7805 - mae: 12.7805\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 12.7131 - mae: 12.7131\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 12.6456 - mae: 12.6456\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 12.5778 - mae: 12.5778\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 12.5098 - mae: 12.5098\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 12.4416 - mae: 12.4416\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 12.3732 - mae: 12.3732\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 12.3045 - mae: 12.3045\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.2355 - mae: 12.2355\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 12.1663 - mae: 12.1663\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 12.0969 - mae: 12.0969\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 12.0272 - mae: 12.0272\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 11.9572 - mae: 11.9572\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11.8869 - mae: 11.8869\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11.8163 - mae: 11.8163\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11.7455 - mae: 11.7455\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 11.6743 - mae: 11.6743\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 11.6028 - mae: 11.6028\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 11.5310 - mae: 11.5310\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 11.4589 - mae: 11.4589\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 11.3865 - mae: 11.3865\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.3137 - mae: 11.3137\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11.2406 - mae: 11.2406\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.1671 - mae: 11.1671\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.0933 - mae: 11.0933\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 11.0191 - mae: 11.0191\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 10.9446 - mae: 10.9446\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 10.8697 - mae: 10.8697\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 10.7944 - mae: 10.7944\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 10.7187 - mae: 10.7187\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 10.6426 - mae: 10.6426\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 10.5662 - mae: 10.5662\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.4893 - mae: 10.4893\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 10.4120 - mae: 10.4120\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 10.3343 - mae: 10.3343\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 10.2562 - mae: 10.2562\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 10.1776 - mae: 10.1776\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 10.0986 - mae: 10.0986\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 10.0192 - mae: 10.0192\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.9393 - mae: 9.9393\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.8590 - mae: 9.8590\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.7783 - mae: 9.7783\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.6970 - mae: 9.6970\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.6153 - mae: 9.6153\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 9.5332 - mae: 9.5332\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.4505 - mae: 9.4505\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 9.3674 - mae: 9.3674\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.2838 - mae: 9.2838\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.1997 - mae: 9.1997\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.1151 - mae: 9.1151\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 9.0300 - mae: 9.0300\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 8.9444 - mae: 8.9444\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.8583 - mae: 8.8583\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 8.7717 - mae: 8.7717\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 8.6845 - mae: 8.6845\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 8.5969 - mae: 8.5969\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.5087 - mae: 8.5087\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.4200 - mae: 8.4200\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 8.3307 - mae: 8.3307\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.2409 - mae: 8.2409\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.1506 - mae: 8.1506\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.0597 - mae: 8.0597\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.9683 - mae: 7.9683\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.8763 - mae: 7.8763\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.7837 - mae: 7.7837\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.6906 - mae: 7.6906\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.5969 - mae: 7.5969\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.5027 - mae: 7.5027\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.4078 - mae: 7.4078\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.3124 - mae: 7.3124\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2164 - mae: 7.2164\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1198 - mae: 7.1198\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.0227 - mae: 7.0227\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.9249 - mae: 6.9249\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.8265 - mae: 6.8265\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.7275 - mae: 6.7275\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.6683 - mae: 6.6683\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8749847af0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if our model's prediction has improved\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23s8oNchtyin",
        "outputId": "7b7463fd-0e50-4670-8a21-302d6a9aa98a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f874838ab80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 134ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.48586]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the learning rate \n",
        "# Learning rate is one of the best way to improve your model\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model (same as above)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(50, activation = None),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile model (same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(lr = 0.01),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit model (this time we'll train for longer)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100) # train for 100 epochs not 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPNhQH8zt0g4",
        "outputId": "b82a38db-4e64-435e-a15d-badc5cde3ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 12.4332 - mae: 12.4332\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 12.3661 - mae: 12.3661\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 12.2989 - mae: 12.2989\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.2317 - mae: 12.2317\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.1645 - mae: 12.1645\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 12.0972 - mae: 12.0972\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 12.0299 - mae: 12.0299\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 11.9625 - mae: 11.9625\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 11.8951 - mae: 11.8951\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 11.8276 - mae: 11.8276\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 11.7600 - mae: 11.7600\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 11.6924 - mae: 11.6924\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.6246 - mae: 11.6246\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.5568 - mae: 11.5568\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.4889 - mae: 11.4889\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 11.4209 - mae: 11.4209\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.3528 - mae: 11.3528\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.2846 - mae: 11.2846\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11.2163 - mae: 11.2163\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 11.1479 - mae: 11.1479\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 11.0793 - mae: 11.0793\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 11.0106 - mae: 11.0106\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 10.9418 - mae: 10.9418\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 10.8728 - mae: 10.8728\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 10.8036 - mae: 10.8036\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 10.7343 - mae: 10.7343\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.6648 - mae: 10.6648\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 10.5950 - mae: 10.5950\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.5251 - mae: 10.5251\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.4550 - mae: 10.4550\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 10.3847 - mae: 10.3847\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 10.3142 - mae: 10.3142\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 10.2434 - mae: 10.2434\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.1723 - mae: 10.1723\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 10.1010 - mae: 10.1010\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 10.0295 - mae: 10.0295\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 9.9577 - mae: 9.9577\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 9.8856 - mae: 9.8856\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 9.8132 - mae: 9.8132\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 9.7404 - mae: 9.7404\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 9.6674 - mae: 9.6674\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.5941 - mae: 9.5941\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.5204 - mae: 9.5204\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 9.4464 - mae: 9.4464\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.3720 - mae: 9.3720\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.2973 - mae: 9.2973\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 9.2222 - mae: 9.2222\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.1467 - mae: 9.1467\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.0708 - mae: 9.0708\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 8.9946 - mae: 8.9946\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 8.9179 - mae: 8.9179\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.8408 - mae: 8.8408\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 8.7633 - mae: 8.7633\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.6854 - mae: 8.6854\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.6071 - mae: 8.6071\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.5282 - mae: 8.5282\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 8.4490 - mae: 8.4490\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.3693 - mae: 8.3693\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.2891 - mae: 8.2891\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 8.2084 - mae: 8.2084\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 8.1273 - mae: 8.1273\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.0457 - mae: 8.0457\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.9636 - mae: 7.9636\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 7.8810 - mae: 7.8810\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.7979 - mae: 7.7979\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.7143 - mae: 7.7143\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.6301 - mae: 7.6301\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.5455 - mae: 7.5455\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.4603 - mae: 7.4603\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.3746 - mae: 7.3746\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7.2883 - mae: 7.2883\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 7.2015 - mae: 7.2015\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7.1142 - mae: 7.1142\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.0263 - mae: 7.0263\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9378 - mae: 6.9378\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.8624 - mae: 6.8624\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.8516 - mae: 6.8516\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.8410 - mae: 6.8410\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8307 - mae: 6.8307\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.8206 - mae: 6.8206\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.8106 - mae: 6.8106\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.8008 - mae: 6.8008\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.7912 - mae: 6.7912\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.7816 - mae: 6.7816\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 6.7722 - mae: 6.7722\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.7629 - mae: 6.7629\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.7536 - mae: 6.7536\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.7444 - mae: 6.7444\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.7353 - mae: 6.7353\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 6.7338 - mae: 6.7338\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.7378 - mae: 6.7378\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 6.7358 - mae: 6.7358\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 6.7284 - mae: 6.7284\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 6.7162 - mae: 6.7162\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 6.6997 - mae: 6.6997\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.6813 - mae: 6.6813\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.6745 - mae: 6.6745\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.6676 - mae: 6.6676\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.6605 - mae: 6.6605\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.6533 - mae: 6.6533\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8749493b80>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if our model's prediction has improved\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kdz-kKMYuQIC",
        "outputId": "8b8a5548-d69c-40cb-c93a-2c06128a899c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 374ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[31.541964]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating a model\n",
        "\n",
        "In practise, a typical workflow you'll go through when building neural networks is:\n",
        "\n",
        "```\n",
        "Build a model  -> evaluate it -> tweak a model -> fit it -> evaluate it...\n",
        "```\n"
      ],
      "metadata": {
        "id": "_0rwmzriuSVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When it comes to evaluation... there are 3 words you should memorize:\n",
        "> Visualize, Visualize, Visualize\n",
        "\n",
        "It's a good idea to visualize:\n",
        "* The data - what data are we working with? What does it look like?\n",
        "* The model itself - what does our model look like?\n",
        "* The training of a model - How does a model perform when it learns?\n",
        "* the presictions of the model - how do the predictions of a model line up against the ground truth (the original labels)?"
      ],
      "metadata": {
        "id": "w9Aqcw6lxOM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a bigger dataset\n",
        "X = tf.range(-100, 100, 4)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwNDrZQsz3ko",
        "outputId": "7c5bc4d5-ae02-417a-cf3f-3c648b8675bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make labels for the dataset\n",
        "y = X + 10\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDqVUGW20B9x",
        "outputId": "f4ce29e0-2e85-40c7-992b-86ffa370299c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X, y);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "dX46GLzU0KnZ",
        "outputId": "5709aeb6-7f9e-469f-e69b-5a7445cdd4d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The 3 sets:\n",
        "\n",
        "* **Training set** - The model learns from this data, which is typically 70-80% of the total data available.\n",
        "* **Validation set** - The model gets tuned on this data, which is typically 10-15% of the data available.\n",
        "* **Test set** - The model gets avaluated on this data to test what it has learned, typically 10-15% of the data available."
      ],
      "metadata": {
        "id": "92kNs-Y40Xm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the length of how many samples do we have\n",
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXKc0mMa1siX",
        "outputId": "258f15c1-f532-4491-f865-a945c5d18b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we don't have much data, we are skippping the validation data set"
      ],
      "metadata": {
        "id": "VaCL1AyB18iA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test sets\n",
        "X_train = X[:40] # first 40 are training samples (80% of the data)\n",
        "y_train = y[:40]\n",
        "\n",
        "X_test = X[40:] # last 10 are testing samples (20% of the data)\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edJGzp4R2Itj",
        "outputId": "1b8e3658-e1b8-4a08-c56c-7404caf661e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10, 40, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualising the data\n",
        "\n",
        "\n",
        "Now we've got our data in training and test sets... let's visualize it again!"
      ],
      "metadata": {
        "id": "SMfPhMPB3AKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10, 7))\n",
        "\n",
        "# Plot the training data in blue\n",
        "plt.scatter(X_train, y_train, c = \"b\", label = \"Training data\")\n",
        "\n",
        "# Plot the test data in green\n",
        "plt.scatter(X_test, y_test, c = \"g\", label= \"Testing data\")\n",
        "\n",
        "# Show a legend\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "nYYNK-Iq3V2l",
        "outputId": "77a46174-2d15-456a-afc2-2be9b21d4610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.expand_dims(X_train, axis=-1).shape, X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoKz_yj54gP-",
        "outputId": "58a2ae3c-181c-4a50-b145-2aebbb2102ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([40, 1]), TensorShape([40]))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's have a loook at how to build a neural network for our data\n",
        "\n",
        "# 1. Create a model \n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1) # 1 because we are using one variable to predict \n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics = ['mae'])\n",
        "\n",
        "# # 3. Fit the model\n",
        "# model.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs = 100)"
      ],
      "metadata": {
        "id": "lRcV7FVn32-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a model which builds automatically by defining the input shape argument in the first layer\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model (same as above)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, input_shape = [1], name= \"input_layer\"), # X[0], y[0] are just some single numbers hence 1 as the input shape. One can also check using X[0].shape\n",
        "    tf.keras.layers.Dense(1, name= \"output_layer\")\n",
        "    ], name = \"model_1\")\n",
        "\n",
        "# 2. Compile the model (same as above)\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics =  [\"mae\"])\n"
      ],
      "metadata": {
        "id": "RrD-0T22DZtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGOGuHGEZbPf",
        "outputId": "f02236fc-e343-474e-d621-537925e43a2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (Dense)         (None, 10)                20        \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Total params - Total number of parameters in the model \n",
        "* Trainable parameters - These are the parameters (patterns) the model can update as it train\n",
        "* Non-trainable params - These parameters aren't updated during training (this is typical when you bring in an already learn patterns or parameters from other models during **transfer learning**)\n",
        "\n",
        "\n",
        "**Resources:** For a more in depth overview of the trainable parameters within a layer, check out MIT's introduction to deep learning video\n",
        "**Exercise:** Try playing with the number of hidden units in the dense layer, see how that affects the number of parameters (total and trainable) by calling `model.summary()`"
      ],
      "metadata": {
        "id": "sr1-xeGnZcV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us fit the model to the training data\n",
        "model.fit(X_train, y_train, epochs=100, verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF7KfBjpeW87",
        "outputId": "3e826504-b831-418b-b49e-a09442909bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 25ms/step - loss: 46.8821 - mae: 46.8821\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 28.2911 - mae: 28.2911\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 16.3290 - mae: 16.3290\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.2119 - mae: 14.2119\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 15.7601 - mae: 15.7601\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 12.4833 - mae: 12.4833\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11.7366 - mae: 11.7366\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.0866 - mae: 12.0866\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 37.9168 - mae: 37.9168\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 25.5181 - mae: 25.5181\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 10.2458 - mae: 10.2458\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 25.3052 - mae: 25.3052\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 16.9836 - mae: 16.9836\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 25.9156 - mae: 25.9156\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 17.9888 - mae: 17.9888\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 7.3463 - mae: 7.3463\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 10.8635 - mae: 10.8635\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 19.5297 - mae: 19.5297\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.3433 - mae: 10.3433\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 17.6970 - mae: 17.6970\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.8961 - mae: 15.8961\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.1964 - mae: 14.1964\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.7687 - mae: 8.7687\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.0538 - mae: 11.0538\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.6831 - mae: 12.6831\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 26.1949 - mae: 26.1949\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 11.7406 - mae: 11.7406\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 22.8828 - mae: 22.8828\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.2420 - mae: 9.2420\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 29.2749 - mae: 29.2749\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 53.0425 - mae: 53.0425\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.9950 - mae: 11.9950\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.6405 - mae: 15.6405\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 12.6937 - mae: 12.6937\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.2383 - mae: 9.2383\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.8303 - mae: 16.8303\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.4883 - mae: 12.4883\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 18.1779 - mae: 18.1779\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 19.1141 - mae: 19.1141\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 20.4564 - mae: 20.4564\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 14.8776 - mae: 14.8776\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.2559 - mae: 12.2559\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 10.7188 - mae: 10.7188\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 22.9606 - mae: 22.9606\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.3690 - mae: 10.3690\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.7602 - mae: 11.7602\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 9.6541 - mae: 9.6541\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 17.2577 - mae: 17.2577\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.5548 - mae: 9.5548\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.7872 - mae: 13.7872\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11.5829 - mae: 11.5829\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 30.4797 - mae: 30.4797\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.3210 - mae: 14.3210\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 23.9140 - mae: 23.9140\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 23.1309 - mae: 23.1309\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.8620 - mae: 10.8620\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.7157 - mae: 12.7157\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.5828 - mae: 9.5828\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 12.4908 - mae: 12.4908\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 11.9000 - mae: 11.9000\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.9887 - mae: 16.9887\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.3965 - mae: 10.3965\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.3493 - mae: 10.3493\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 24.2183 - mae: 24.2183\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.5295 - mae: 10.5295\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 21.2271 - mae: 21.2271\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.5279 - mae: 10.5279\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.3852 - mae: 14.3852\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.6204 - mae: 10.6204\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.7060 - mae: 12.7060\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13.1356 - mae: 13.1356\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 19.6531 - mae: 19.6531\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 11.1987 - mae: 11.1987\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 21.9424 - mae: 21.9424\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.1875 - mae: 7.1875\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.4133 - mae: 9.4133\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 22.0348 - mae: 22.0348\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 17.7255 - mae: 17.7255\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 14.8783 - mae: 14.8783\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 25.2173 - mae: 25.2173\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 10.9432 - mae: 10.9432\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.7310 - mae: 12.7310\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 17.4964 - mae: 17.4964\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.2808 - mae: 7.2808\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 15.0228 - mae: 15.0228\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 15.3329 - mae: 15.3329\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 19.2017 - mae: 19.2017\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 29.5794 - mae: 29.5794\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 10.1426 - mae: 10.1426\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 21.3221 - mae: 21.3221\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 10.5266 - mae: 10.5266\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 18.2148 - mae: 18.2148\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.8119 - mae: 6.8119\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.0123 - mae: 13.0123\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 18.4025 - mae: 18.4025\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 10.3502 - mae: 10.3502\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.4182 - mae: 14.4182\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.5752 - mae: 6.5752\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 12.5976 - mae: 12.5976\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 19.4153 - mae: 19.4153\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f87492c23d0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a model which builds automatically by defining the input shape argument in the first layer\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model (same as above)\n",
        "model_trial = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(7, input_shape = [1]) # X[0], y[0] are just some single numbers hence 1 as the input shape. One can also check using X[0].shape\n",
        "])\n",
        "\n",
        "# 2. Compile the model (same as above)\n",
        "model_trial.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics =  [\"mae\"])\n",
        "\n",
        "model_trial.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJSPdCabejwZ",
        "outputId": "aaa340db-ad1e-452a-9b50-b00d5804adf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 7)                 14        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14\n",
            "Trainable params: 14\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Irg4wlRCluV",
        "outputId": "7a044d0b-3704-4edd-9b10-850a1e7a676a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (Dense)         (None, 10)                20        \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Another way of visualizing our machine learning model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model= model, show_shapes = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "yWiA8hAHDI_d",
        "outputId": "ee5634b1-985a-4faa-d708-8f3cc19b9373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing our model's predictions\n",
        "\n",
        "To visualize predictions, it's a good idea to plot them against ground truth labels. \n",
        "\n",
        "Often you'll see this is the form of `y_test` versus `y_preds` (ground truth versus your model's predictions)."
      ],
      "metadata": {
        "id": "CRD-H5oHDmZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions\n",
        "y_preds = model.predict(X_test)\n",
        "y_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD28c4NKFFBH",
        "outputId": "1f50efa7-b2bc-4421-d22c-198e0411f6fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 108ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 78.29776],\n",
              "       [ 83.39866],\n",
              "       [ 88.49956],\n",
              "       [ 93.60046],\n",
              "       [ 98.70136],\n",
              "       [103.80225],\n",
              "       [108.90315],\n",
              "       [114.00405],\n",
              "       [119.10496],\n",
              "       [124.20585]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2G9RHpqGkU7",
        "outputId": "765413c8-62ce-40e1-cef8-a89ed840d14a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** If you feel like you're going to reuse some kind of functionality in the future, it's a good idea to turn it into a function"
      ],
      "metadata": {
        "id": "kHnMgrSOGrfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a plotting function\n",
        "def plot_predictions(train_data = X_train,\n",
        "                     train_labels = y_train,\n",
        "                     test_data = X_test,\n",
        "                     test_labels = y_test,\n",
        "                     predictions = y_preds):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions to ground truth labels.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize = (10, 7))\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c = \"b\", label = \"Training Data\")\n",
        "  # Plot testing data in green\n",
        "  plt.scatter(test_data, test_labels, c = \"g\", label = \"Testing Data\")\n",
        "  # Plot model's prediction in red\n",
        "  plt.scatter(test_data, predictions, c = \"r\", label = \"Predictions\")\n",
        "  # Show the legend\n",
        "  plt.legend();"
      ],
      "metadata": {
        "id": "BnKA93BlHFow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(train_data = X_train,\n",
        "                     train_labels = y_train,\n",
        "                     test_data = X_test,\n",
        "                     test_labels = y_test,\n",
        "                     predictions = y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "ozC0u72DIupe",
        "outputId": "c85cf898-0710-4744-f746-76149efc2877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating our model's predictions with regression evaluation metrics\n",
        "\n",
        "Depending on the problem you are working on, there will be different evaluation metrics to avaluate your model's performance.\n",
        "\n",
        "Since we're working on a regression, two of the main metrics are:\n",
        "\n",
        "* MAE: Mean Absolute Error, \"on average, how wrong is each of my model's predictions\"\n",
        "\n",
        "* MSE: Mean Squared Error, \"square the average errors\"\n"
      ],
      "metadata": {
        "id": "laBKGaxLI0Tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr5YtLLHJevt",
        "outputId": "53e7926e-39e9-4e81-8daf-ebfc46fe3ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 295ms/step - loss: 13.2518 - mae: 13.2518\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[13.251803398132324, 13.251803398132324]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean absolute error\n",
        "tf.keras.losses.mean_absolute_error(y_true = y_test, y_pred =tf.constant(y_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePJB2F0MNt9M",
        "outputId": "3899cc1e-a539-4070-9cb3-7a8a4b1a7926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([12.280896, 10.520268, 10.      , 10.720091, 12.820818, 16.241802,\n",
              "       20.903152, 26.004053, 31.104956, 36.20585 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Buh-auGfOD35",
        "outputId": "7bfd21a5-5585-4bd3-9636-2afc6a19e8cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.constant(y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysfRth-UTAcZ",
        "outputId": "6cb030b9-3d09-4dd0-b568-385f85b4f855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              "array([[ 78.29776],\n",
              "       [ 83.39866],\n",
              "       [ 88.49956],\n",
              "       [ 93.60046],\n",
              "       [ 98.70136],\n",
              "       [103.80225],\n",
              "       [108.90315],\n",
              "       [114.00405],\n",
              "       [119.10496],\n",
              "       [124.20585]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are getting the matrix output due to the difference in the shapes of the two tensors"
      ],
      "metadata": {
        "id": "2M6DGHdBTDgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.squeeze(y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsB6AyNuTOn7",
        "outputId": "9cae9101-a0a4-4718-8d43-4b1b1b4218eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([ 78.29776,  83.39866,  88.49956,  93.60046,  98.70136, 103.80225,\n",
              "       108.90315, 114.00405, 119.10496, 124.20585], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean absolute error\n",
        "mae = tf.keras.losses.mean_absolute_error(y_true = y_test, y_pred =tf.squeeze(y_preds))\n",
        "mae"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHGjqzhHTRv9",
        "outputId": "6e5aa225-c669-46f6-fe1e-058221adc6c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=13.251806>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean squared error\n",
        "mse = tf.metrics.mean_squared_error(y_true = y_test,\n",
        "                                    y_pred = tf.squeeze(y_preds))\n",
        "mse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcalwd3cTf1r",
        "outputId": "a06eb446-3c72-4ccd-a694-7e86b08b2482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=185.60918>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some functions to reuse MAE and MSE \n",
        "def mae(y_true, y_pred):\n",
        "  return tf.keras.losses.mean_absolute_error(y_true  =y_true,\n",
        "                                      y_pred = tf.squeeze(y_pred))\n",
        "  \n",
        "def mse(y_true, y_pred):\n",
        "  return tf.metrics.mean_squared_error(y_true = y_true,\n",
        "                                     y_pred = tf.squeeze(y_pred))"
      ],
      "metadata": {
        "id": "fkp2m9kNDZQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running experiments to improve our model\n",
        "Build a model -> fit it -> evaluate it -> tweak it -> back to fit... and so on\n",
        "\n",
        "\n",
        "1. Get more data - get more examples for your model to train (more opportunities to learn patterns or relationships between features and labels).\n",
        "\n",
        "2. Make your model larger (using a more complex method) - this might come in the form of more layers or hidden units in each layer\n",
        "\n",
        "3. Train for longer - give your model more of a chance to find patterns in the data.\n",
        "\n",
        "Let's do 3 modelling experiments:\n",
        "\n",
        "1. `model_1` - same as the original model, 1 layer, trained for 100 epochs.\n",
        "\n",
        "2. `model_2` - 2 layers, trained for 100 epochs\n",
        "\n",
        "3. `model_3` - 2 layers, trained for 500 epochs\n",
        "\n",
        "**Build model_!**tf.metrics.mean_squared_errortf.metrics.mean_squared_errormetricsmmmverrevrfrdwcmmmmwdvbwhebkkkkkk"
      ],
      "metadata": {
        "id": "JtaOgz9LF-nF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_1.compile(loss = tf.keras.losses.mae,\n",
        "                optimizer = tf.keras.optimizers.SGD(),\n",
        "                metrics = [\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_1.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Btne6xZ-HA5l",
        "outputId": "8fb07610-c6ca-4090-e96b-72e4cdfc24d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 28ms/step - loss: 58.1266 - mae: 58.1266\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 23.6145 - mae: 23.6145\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.4135 - mae: 10.4135\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 12.8646 - mae: 12.8646\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11.9066 - mae: 11.9066\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11.0341 - mae: 11.0341\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 8.4442 - mae: 8.4442\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8.8733 - mae: 8.8733\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 17.0168 - mae: 17.0168\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.5314 - mae: 12.5314\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.2597 - mae: 10.2597\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 18.6681 - mae: 18.6681\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.7252 - mae: 9.7252\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.6034 - mae: 15.6034\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 11.3204 - mae: 11.3204\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8.5813 - mae: 8.5813\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 13.7167 - mae: 13.7167\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.5616 - mae: 11.5616\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 17.8228 - mae: 17.8228\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 14.9581 - mae: 14.9581\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 10.8448 - mae: 10.8448\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.5948 - mae: 8.5948\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.7341 - mae: 9.7341\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.9546 - mae: 10.9546\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.1681 - mae: 9.1681\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 13.1911 - mae: 13.1911\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.6682 - mae: 10.6682\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 12.8833 - mae: 12.8833\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.5195 - mae: 9.5195\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.3974 - mae: 16.3974\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 23.6011 - mae: 23.6011\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.6252 - mae: 7.6252\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.3230 - mae: 9.3230\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 13.7062 - mae: 13.7062\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.1577 - mae: 11.1577\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 13.3690 - mae: 13.3690\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 9.4717 - mae: 9.4717\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 10.1275 - mae: 10.1275\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 10.2097 - mae: 10.2097\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 10.9500 - mae: 10.9500\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 7.9383 - mae: 7.9383\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.0839 - mae: 10.0839\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.7040 - mae: 8.7040\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.1794 - mae: 12.1794\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.8388 - mae: 13.8388\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8.5021 - mae: 8.5021\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.1279 - mae: 9.1279\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.6067 - mae: 10.6067\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.7467 - mae: 7.7467\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.5299 - mae: 9.5299\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.1642 - mae: 9.1642\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.3202 - mae: 16.3202\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.1581 - mae: 14.1581\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 21.1816 - mae: 21.1816\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.3597 - mae: 16.3597\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.0216 - mae: 10.0216\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.9521 - mae: 9.9521\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.2154 - mae: 9.2154\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.4170 - mae: 8.4170\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.4849 - mae: 9.4849\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 11.4191 - mae: 11.4191\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 11.7299 - mae: 11.7299\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.0854 - mae: 7.0854\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 17.0085 - mae: 17.0085\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.4937 - mae: 12.4937\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.0596 - mae: 13.0596\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.0831 - mae: 8.0831\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 10.2187 - mae: 10.2187\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.4071 - mae: 12.4071\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 9.0467 - mae: 9.0467\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.0307 - mae: 10.0307\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 10.0487 - mae: 10.0487\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.5944 - mae: 12.5944\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.4256 - mae: 10.4256\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.7175 - mae: 9.7175\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.2140 - mae: 11.2140\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.3595 - mae: 8.3595\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.1111 - mae: 9.1111\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 19.5587 - mae: 19.5587\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.8625 - mae: 14.8625\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.0517 - mae: 9.0517\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.9961 - mae: 12.9961\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.9194 - mae: 7.9194\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.7081 - mae: 7.7081\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.0659 - mae: 10.0659\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.2687 - mae: 9.2687\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.0563 - mae: 12.0563\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.6767 - mae: 10.6767\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.2803 - mae: 7.2803\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.8196 - mae: 12.8196\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 7.4945 - mae: 7.4945\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 6.7632 - mae: 6.7632\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.9694 - mae: 11.9694\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.8996 - mae: 8.8996\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.7373 - mae: 7.7373\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.7633 - mae: 6.7633\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.6528 - mae: 8.6528\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 9.3989 - mae: 9.3989\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.1355 - mae: 9.1355\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.4900 - mae: 10.4900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8750c59b50>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make and plot predictions for model_1\n",
        "y_preds_1 = model_1.predict(X_test)\n",
        "plot_predictions(predictions = y_preds_1)"
      ],
      "metadata": {
        "id": "1dI_ZzTeIkjW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "25bb8061-ed3a-4b01-dfba-612d86ea99d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 76ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAGbCAYAAAAY8u5bAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsvUlEQVR4nO3df3xU9Z3v8fcHRBDhImKqCEKgVxFQDJKC1qK4oFK3FHBrK5td9doushV/7cP1V3a7uH2kD7W6etGrGLtutY9sq1eX+ot2FSqLXWRt0JSfUlATxMtiijVioxLgc/+YyTCESZgwZ36cc17PxyOPzJz5cb6ZmYQ333PO+5i7CwAAAMHpUewBAAAARA0BCwAAIGAELAAAgIARsAAAAAJGwAIAAAjYEcUeQLrjjjvOy8vLiz0MAACAQ1q9evXv3b0s020lFbDKy8tVX19f7GEAAAAckpk1dXYbmwgBAAACRsACAAAIGAELAAAgYCW1D1YmbW1t2rZtmz777LNiDwVp+vTpo6FDh6pXr17FHgoAACWn5APWtm3b1L9/f5WXl8vMij0cSHJ37dy5U9u2bdOIESOKPRwAAEpOyW8i/OyzzzRo0CDCVQkxMw0aNIhZRQAAOlHyAUsS4aoE8Z4AANC5UAQsAACAMCFgHcLOnTtVUVGhiooKnXDCCRoyZEjq+u7du7t8bH19va677rpDruPLX/5yIGNdvny5BgwYoPHjx2vUqFE699xz9cILL2T1uJUrVwYyBgAAEIKd3Itt0KBBamhokCQtWLBA/fr100033ZS6fc+ePTriiMwvY2VlpSorKw+5jiDDzeTJk1OhqqGhQbNmzdJRRx2lqVOndvqY5cuXq1+/foEFPQAA4i5yM1h1dVJ5udSjR+J7XV3w67jyyis1b948TZo0STfffLNef/11nX322Ro/fry+/OUva9OmTZISweVrX/uapEQ4u+qqqzRlyhSNHDlSCxcuTD1fv379UvefMmWKvvGNb+jUU09VVVWV3F2StGTJEp166qmaMGGCrrvuutTzdqWiokLf+9739OCDD0qSnn/+eU2aNEnjx4/XtGnTtGPHDjU2NmrRokW67777VFFRoVdffTXj/QAAQPYiNYNVVyfNnSu1tiauNzUlrktSVVWw69q2bZtWrlypnj176uOPP9arr76qI444QkuXLtXtt9+uZ5555qDHvPXWW3rllVe0a9cujRo1Sn/91399UI/Um2++qfXr1+vEE0/UOeeco//8z/9UZWWlrr76aq1YsUIjRozQnDlzsh7nmWeeqR/+8IeSpK985StatWqVzEw/+tGPdPfdd+vee+/VvHnzDpiZ+8Mf/pDxfgAAIDuRCljV1fvDVbvW1sTyoAPWpZdeqp49e0qSWlpadMUVV2jz5s0yM7W1tWV8zJ/+6Z+qd+/e6t27t77whS9ox44dGjp06AH3mThxYmpZRUWFGhsb1a9fP40cOTLVOTVnzhzV1tZmNc72GTApEQq/9a1vafv27dq9e3enHVbZ3g8AAGQWqU2EW7d2b3kujj766NTlv//7v9f555+vdevW6fnnn++0H6p3796pyz179tSePXsO6z7d8eabb2r06NGSpGuvvVbz58/X2rVr9cgjj3Q6zmzvBwBAqalbW6fy+8vV444eKr+/XHVr87CvUBYiFbCGDeve8qC0tLRoyJAhkqQf//jHgT//qFGj9M4776ixsVGS9OSTT2b1uDVr1uj73/++rrnmmoPG+fjjj6fu179/f+3atSt1vbP7AQBQyurW1mnu83PV1NIkl6uppUlzn59blJAVqYBVUyP17Xvgsr59E8vz6eabb9Ztt92m8ePH5zzjlMlRRx2lhx56SNOnT9eECRPUv39/DRgwION9X3311VRNwzXXXKOFCxemjiBcsGCBLr30Uk2YMEHHHXdc6jEzZszQ4sWLUzu5d3Y/AABKWfWyarW2HbivUGtbq6qXVRd8LJa+j06xVVZWen19/QHLNm7cmNrElY26usQ+V1u3JmauamqC3/+qGD755BP169dP7q5rrrlGJ598sm688caijqm77w0AAPnU444ech2ca0ymff+wL/D1mdlqd8/YxxSpGSwpEaYaG6V9+xLfoxCuJOnRRx9VRUWFxo4dq5aWFl199dXFHhIAACVl2IDM+wR1tjyfIhewourGG29UQ0ODNmzYoLq6OvXtuC0UAICYq5lao769Dvz3sW+vvqqZmud9hTIgYAEAgEioOr1KtTNqNXzAcJlMwwcMV+2MWlWdXvjNWZHqwQIAANFUt7ZO1cuqtbVlq4YNGKaaqTUZg1PV6VVFCVQdEbAAAEBJa69faD9CsL1+QVJJhKlM2EQIAABKWinVL2SrWwHLzB4zsw/MbF3asmPN7GUz25z8PjC53MxsoZltMbM1ZnZm0IMvhJ07d6qiokIVFRU64YQTNGTIkNT13bt3H/Lxy5cv18qVK1PXFy1apCeeeCKQsU2ZMkWjRo3SuHHjdOqpp2r+/Pn66KOPDvm4H/zgB4GsHwCAQtjakvmULJ0tLwXdncH6saTpHZbdKmmZu58saVnyuiR9VdLJya+5kh4+/GEWz6BBg9TQ0KCGhgbNmzcvdTRfQ0ODjjzyyEM+vmPAmjdvni6//PLAxldXV6c1a9ZozZo16t27t2bOnHnIxxCwAABhUkr1C9nqVsBy9xWSPuyweKak9vOpPC5pVtryJzxhlaRjzGxwDmPNSiHOQbR69Wqdd955mjBhgi666CJt375dkrRw4UKNGTNG48aN02WXXabGxkYtWrRI99133wEt6ffcc4+kxAzULbfcookTJ+qUU07Rq6++KklqbW3VN7/5TY0ZM0azZ8/WpEmT1LGAtaMjjzxSd999t7Zu3arf/va3kqRZs2ZpwoQJGjt2bOrk0Lfeeqs+/fRTVVRUqCpZEpbpfgAAlIpSql/IVhA7uR/v7tuTl/9b0vHJy0MkvZd2v23JZdvTlsnM5ioxw6VhOZ40sBA7wbm7rr32Wj377LMqKyvTk08+qerqaj322GO688479e6776p379766KOPdMwxx2jevHnq16+fbrrpJknSsmXLDni+PXv26PXXX9eSJUt0xx13aOnSpXrooYc0cOBAbdiwQevWrVNFRUVWY+vZs6fOOOMMvfXWWzrjjDP02GOP6dhjj9Wnn36qL33pS/qzP/sz3XnnnXrwwQfV0NCQelym+w0aNCiQ1wsAgFy1/xuezVGEpSLQowjd3c2sW+fecfdaSbVS4lQ5uay/q53ggnoTPv/8c61bt04XXHCBJGnv3r0aPDgxMTdu3DhVVVVp1qxZmjVrVlbPd8kll0iSJkyYkDqZ869//Wtdf/31kqTTTjtN48aNy3p86ac+WrhwoRYvXixJeu+997R58+aMwSnb+wEAEKRsqxek0qlfyFYQAWuHmQ129+3JTYAfJJe/L+mktPsNTS7Lm0LsBOfuGjt2rF577bWDbnvxxRe1YsUKPf/886qpqdHatWsP+Xy9e/eWlJh9yvVE0Xv37tXatWs1evRoLV++XEuXLtVrr72mvn37asqUKfrss88Oeky29wMAIEhhrF7ojiBqGp6TdEXy8hWSnk1bfnnyaMKzJLWkbUrMi0LsBNe7d281NzenAlZbW5vWr1+vffv26b333tP555+vu+66Sy0tLfrkk0/Uv39/7dq1q1vrOOecc/TUU09JkjZs2JBVUGtra9Ntt92mk046SePGjVNLS4sGDhyovn376q233tKqVatS9+3Vq5fa2tokqcv7AQCQL2GsXuiO7tY0/FTSa5JGmdk2M/u2pDslXWBmmyVNS16XpCWS3pG0RdKjkr4b2Kg7UYid4Hr06KGnn35at9xyi8444wxVVFRo5cqV2rt3r/7iL/5Cp59+usaPH6/rrrtOxxxzjGbMmKHFixendnLPxne/+101NzdrzJgx+ru/+zuNHTtWAwYMyHjfqqoqjRs3Tqeddpr++Mc/6tlnE/l2+vTp2rNnj0aPHq1bb71VZ511Vuoxc+fOTW3O7Op+AADkSxirF7rD0vfZKbbKykrveLTcxo0bNXr06Kyfozvbc0vV3r171dbWpj59+ujtt9/WtGnTtGnTpqxqIQqpu+8NAADtyu8vV1NL00HLhw8YrsYbGgs/oMNgZqvdvTLTbZE7VU7YdoLLpLW1Veeff77a2trk7nrooYdKLlwBAJCLmqk1B+yDJZV+9UJ3RC5gRUH//v0P2XsFAECYhbF6oTsIWAAAIFDZ7q4Tha1OnSFgAQCAwES9fiFbQdQ0AAAASIp+/UK2CFgAACAwUa9fyBYBKws9e/ZURUWFTjvtNF166aVqbW099IM6ceWVV+rpp5+WJH3nO9/Rhg0bOr3v8uXLtXLlytT1RYsW6YknnjjsdQMAkG+FKP0OAwJWFo466ig1NDRo3bp1OvLII7Vo0aIDbj/cU9z86Ec/0pgxYzq9vWPAmjdvni6//PLDWhcAAIVQiNLvMIhewKqrk8rLpR49Et/r6gJ9+smTJ2vLli1avny5Jk+erK9//esaM2aM9u7dq7/927/Vl770JY0bN06PPPKIpMS5C+fPn69Ro0Zp2rRp+uCDD1LPNWXKlFQdwy9/+UudeeaZOuOMMzR16lQ1NjZq0aJFuu+++1It8AsWLNA999wjSWpoaNBZZ52lcePGafbs2frDH/6Qes5bbrlFEydO1CmnnJJqj1+/fr0mTpyoiooKjRs3Tps3bw70dQEAQErsyF47o1bDBwyXyTR8wHDVzqiN1Q7uUtSOIqyrk+bOldo34TU1Ja5LUlXub+yePXv0i1/8QtOnT5ckvfHGG1q3bp1GjBih2tpaDRgwQL/5zW/0+eef65xzztGFF16oN998U5s2bdKGDRu0Y8cOjRkzRlddddUBz9vc3Ky/+qu/0ooVKzRixAh9+OGHOvbYYzVv3jz169dPN910kyRp2bJlqcdcfvnleuCBB3Teeefpe9/7nu644w7df//9qXG+/vrrWrJkie644w4tXbpUixYt0vXXX6+qqirt3r1be/fuzfn1AADEC/UL2YvWDFZ19f5w1a61NbE8B59++qkqKipUWVmpYcOG6dvf/rYkaeLEiRoxYoQk6aWXXtITTzyhiooKTZo0STt37tTmzZu1YsUKzZkzRz179tSJJ56oP/mTPzno+VetWqVzzz039VzHHntsl+NpaWnRRx99pPPOO0+SdMUVV2jFihWp2y+55BJJ0oQJE9TY2ChJOvvss/WDH/xAd911l5qamnTUUUfl9JoAAOKlvX6hqaVJLk/VL9StDXZLUc7yvCUrW9GawdrayREKnS3PUvs+WB0dffTRqcvurgceeEAXXXTRAfdZsmRJTus+HL1795aU2Dm/ff+wP//zP9ekSZP04osv6uKLL9YjjzySMewBAJBJV/ULJTNblectWd0RrRmsYZ0codDZ8gBddNFFevjhh9XW1iZJ+t3vfqc//vGPOvfcc/Xkk09q79692r59u1555ZWDHnvWWWdpxYoVevfddyVJH374oaTEKXN27dp10P0HDBiggQMHpvav+slPfpKazerMO++8o5EjR+q6667TzJkztWbNmpx+XgBAvISifiFPW7IOR7RmsGpqDkyuktS3b2J5nn3nO99RY2OjzjzzTLm7ysrK9POf/1yzZ8/Wr371K40ZM0bDhg3T2WeffdBjy8rKVFtbq0suuUT79u3TF77wBb388suaMWOGvvGNb+jZZ5/VAw88cMBjHn/8cc2bN0+tra0aOXKk/uVf/qXL8T311FP6yU9+ol69eumEE07Q7bffHujPDwCItmEDhqmppSnj8pKRpy1Zh8PcveAr7UxlZaV3PMnxxo0bNXr06OyfpK4ukVS3bk3MXNXUFHxaMC66/d4AAEKr4ylwpET9QkkdIVhentgs2NHw4VJyn+Qgmdlqd6/MdFu0NhFKiTDV2Cjt25f4TrgCACBnoahfqKlJbLlKV6AtWR1FL2ABAICs1a2tU/n95epxRw+V31/e5VGBVadXqfGGRu37h31qvKGxsOEqm6MDq6qk2trEjJVZ4nttbVEmW0KxD5a7y8yKPQykKaVNywCAw9Nxs1979YKk0pqZ6s7RgVVVJbH1quRnsPr06aOdO3fyD3oJcXft3LlTffr0KfZQAAA56Kp6oaSU0NGB2Sr5GayhQ4dq27Ztam5uLvZQkKZPnz4aOnRosYcBAMhBKKoXpJI6OjBbJR+wevXqlWo4BwAAwQlF9YKUaAXIdHRgAXouD1fJbyIEAAD5UTO1Rn17HXjUXd9efVUztfBH3XWphI4OzBYBCwCAmApF9YJUUkcHZqvki0YBAED31a2tU/Wyam1t2aphA4apZmpN6QWnkJeDd1U0WvL7YAEAgO4JRf1CCZ2YOR+YwQIAIGLK7y/PuPP68AHD1XhDY+EHlEmBT2uTD/E6VQ4AADEXivqFEFYvdAcBCwCAiOmsZqGk6hc6q1go4eqF7iBgAQAQMaGoXwhh9UJ3ELAAAIiYotcvhOzEzPnATu4AAIREaKoX0o8OlBIzUxEKT+3YyR0AgJBrr15oammSy1PVC3VrM8wOFVMIT8ycDwQsAABCoHpZdarXql1rW6uql5VYcIn40YHZImABABACoahekCJ/dGC2CFgAAIRAKKoXpMgfHZitnAOWmY0ys4a0r4/N7AYzW2Bm76ctvziIAQMAEEehqF6QIn90YLZyDljuvsndK9y9QtIESa2SFidvvq/9Nndfkuu6AACIq6JXL0jZ1S9IiTDV2Cjt25f4HrNwJQV/suepkt529yYzC/ipAQCIpmzrF6pOrypeLUPET84ctKD3wbpM0k/Trs83szVm9piZDcz0ADOba2b1Zlbf3Nwc8HAAACht1C9EU2BFo2Z2pKT/J2msu+8ws+Ml/V6SS/q+pMHuflVXz0HRKAAgbsrvL1dTS9NBy4cPGK7GGxoLP6DO9OghZcoMZolNgTFUqKLRr0p6w913SJK773D3ve6+T9KjkiYGuC4AACKB+oVoCjJgzVHa5kEzG5x222xJ6wJcFwAAkUD9QjQFErDM7GhJF0j6t7TFd5vZWjNbI+l8STcGsS4AAKKk6PUL3TkykPqFrHGyZwAAiqxoJ3GO0YmZ86GrfbAIWAAA5EnRglO2yssTdQsdDR+e6K9Cl7oKWEH3YAEAAO2vX2g/QXN7/YKk0glZnJg5bzgXIQAAeVC9rDoVrtq1trWqelkJ9UZxZGDeELAAAMiDUNQvcGRg3hCwAADIg6LXL2RzdCBHBuYNAQsAgDwoav1C+9GBTU2J9vX28wZ2FrJifmLmfCBgAQCQB1WnV6l2Rq2GDxguk2n4gOGqnVFbmB3cOW9g0VHTAABAN9TVJXLK1q2JfcFrakpw0ofzBhZEoc5FCABApHVny1tRcXRg0RGwAADIUmi2vHF0YNERsAAAyFJoejk5OrDoCFgAAGSp6Fvesj0xs8TRgUVGwAIAIEtF3fIWmh3AIBGwAADIWlG3vIVmBzBIBCwAACRlv/WtaFveQrMDGCQCFgAA4dj6VvQdwNAdBCwAQOyFYusb1QuhQsACAMRe0be+cWLmyDmi2AMAAKDYhg1LbBbMtDzv2rdPtk+htW+flA4OT1VVBKqQYAYLABB7Rd36Fortk+guAhYAIPaKuvWt6NsnkQ8ELABApJV8/QJHB0YSAQsAEFmhqF/g6MBIImABACIrFLs3cXRgJBGwAACRVfTdm0p++yTyhYAFAIisou7eFIrtk8gXAhYAILKoX0CxELAAAJFF/QKKhYAFAAidbHdtkqhfQHEQsAAAoRKaXZuoX4g1AhYAIFRCs2sT9QuxZu5e7DGkVFZWen19fbGHAQAoYT16JGauOjJLbAYECsXMVrt7ZabbmMECAIQKuzYhDAhYAIBQYdcmhAEBCwAQKuzahDAILGCZWaOZrTWzBjOrTy471sxeNrPNye8Dg1ofACB6OLMMoiLoGazz3b0ibYevWyUtc/eTJS1LXgcA4CChqV8AspDvTYQzJT2evPy4pFl5Xh8AIKRCU78AZCHIgOWSXjKz1WY2N7nseHffnrz835KO7/ggM5trZvVmVt/c3BzgcAAAYcKZZRAlQQasr7j7mZK+KukaMzs3/UZPFG4d1Fzi7rXuXunulWVlZQEOBwAQJtQvIEoCC1ju/n7y+weSFkuaKGmHmQ2WpOT3D4JaHwAgWqhfQJQEErDM7Ggz699+WdKFktZJek7SFcm7XSHp2SDWBwCIHuoXECVBzWAdL+nXZvZbSa9LetHdfynpTkkXmNlmSdOS1wEAMUP9AuLmiCCexN3fkXRGhuU7JU0NYh0AgHBqr19oP0KwvX5BIkAhumhyBwDkFfULiCMCFgAgr6hfQBwRsAAAeUX9AuKIgAUAyCvqFxBHBCwAQF5Rv4A4CuQoQgAAulJVRaBCvDCDBQA4LNl2WwFxxAwWAKDb6LYCusYMFgCg2+i2ArpGwAIAdBvdVkDXCFgAgG6j2wroGgELANBtdFsBXSNgAQC6jW4roGsELADAAbKtX6iqkhobpX37Et8JV8B+1DQAAFKoXwCCwQwWACCF+gUgGAQsAEAK9QtAMAhYAIAU6heAYBCwAAAp1C8AwSBgAQBSqF8AgkHAAoCYoH4BKBxqGgAgBqhfAAqLGSwAiAHqF4DCImABQAxQvwAUFgELAGKA+gWgsAhYABAD1C8AhUXAAoAYoH4BKCwCFgCEWLbVCxL1C0AhUdMAACFF9QJQupjBAoCQonoBKF0ELAAIKaoXgNJFwAKAkKJ6AShdBCwACCmqF4DSRcACgJCiegEoXQQsAChB2dYvUL0AlKacA5aZnWRmr5jZBjNbb2bXJ5cvMLP3zawh+XVx7sMFgOhrr19oapLc99cvdNVxBaC0mLvn9gRmgyUNdvc3zKy/pNWSZkn6pqRP3P2ebJ+rsrLS6+vrcxoPAIRdeXkiVHU0fHhilgpAaTCz1e5emem2nItG3X27pO3Jy7vMbKOkIbk+LwDEFfULQPgFug+WmZVLGi/pv5KL5pvZGjN7zMwGBrkuAIgq6heA8AssYJlZP0nPSLrB3T+W9LCkL0qqUGKG695OHjfXzOrNrL65uTmo4QBAaFG/AIRfIAHLzHopEa7q3P3fJMndd7j7XnffJ+lRSRMzPdbda9290t0ry8rKghgOAIQa9QtA+AVxFKFJ+mdJG939n9KWD06722xJ63JdFwCEHfULQDzkvJO7pHMk/aWktWbWkFx2u6Q5ZlYhySU1Sro6gHUBQGi11y+0n6C5vX5BIkABUZNzTUOQqGkAEGXULwDR0lVNA03uAFAg1C8A8UHAAoACoX4BiA8CFgAUCPULQHwQsACgQKhfAOKDgAUAOcq2ekGifgGIiyBqGgAgtqheAJAJM1gAkIPq6v3hql1ra2I5gPgiYAFADqheAJAJAQsAckD1AoBMCFgAkAOqFwBkQsACgBxQvQAgEwIWAHQi2/oFqhcAdERNAwBkQP0CgFwwgwUAGVC/ACAXBCwAyID6BQC5IGABQAbULwDIBQELADKgfgFALghYAJAB9QsAckHAAhA71C8AyDdqGgDECvULAAqBGSwAsUL9AoBCIGABiBXqFwAUAgELQKxQvwCgEAhYAGKF+gUAhUDAAhAr1C8AKAQCFoBIyLZ6QaJ+AUD+UdMAIPSoXgBQapjBAhB6VC8AKDUELAChR/UCgFJDwAIQelQvACg1BCwAoUf1AoBSQ8ACEHpULwAoNQQsACUt2/oFqhcAlBJqGgCULOoXAIQVM1gAShb1CwDCioAFoGRRvwAgrPIesMxsupltMrMtZnZrvtcHIDqoXwAQVnkNWGbWU9L/kfRVSWMkzTGzMflcJ4DooH4BQFjlewZroqQt7v6Ou++W9DNJM/O8TgARQf0CgLDKd8AaIum9tOvbkstSzGyumdWbWX1zc3OehwOgFGRbvSBRvwAgnIq+k7u717p7pbtXlpWVFXs4APKsvXqhqUly31+90FXIAoCwyXfAel/SSWnXhyaXAYgpqhcAxEG+A9ZvJJ1sZiPM7EhJl0l6Ls/rBFDCqF4AEAd5DVjuvkfSfEn/LmmjpKfcfX0+1wmgtFG9ACAO8r4PlrsvcfdT3P2L7s7B1UDMUb0AIA6KvpM7gHihegFAHBCwAAQm2/oFqhcARN0RxR4AgGhor19oP0KwvX5BIkABiB9msAAEgvoFANiPgAUgENQvAMB+BCwAgaB+AQD2I2ABCAT1CwCwHwELQCCoXwCA/QhYAA6J+gUA6B5qGgB0ifoFAOg+ZrAAdIn6BQDoPgIWgC5RvwAA3UfAAtAl6hcAoPsIWAC6RP0CAHQfAQtAl6hfAIDuI2ABMZVt9YJE/QIAdBc1DUAMUb0AAPnFDBYQQ1QvAEB+EbCAGKJ6AQDyi4AFxBDVCwCQXwQsIIaoXgCA/CJgATFE9QIA5BcBC4iYbOsXqF4AgPyhpgGIEOoXAKA0MIMFRAj1CwBQGghYQIRQvwAApYGABUQI9QsAUBoIWECEUL8AAKWBgAVECPULAFAaCFhASFC/AADhQU0DEALULwBAuDCDBYQA9QsAEC4ELCAEqF8AgHAhYAEhQP0CAIQLAQsIAeoXACBccgpYZvZDM3vLzNaY2WIzOya5vNzMPjWzhuTXokBGC8QU9QsAEC7m7of/YLMLJf3K3feY2V2S5O63mFm5pBfc/bTuPF9lZaXX19cf9ngAAAAKxcxWu3tlpttymsFy95fcfU/y6ipJQ3N5PiBusu22AgCES5D7YF0l6Rdp10eY2Ztm9h9mNrmzB5nZXDOrN7P65ubmAIcDlLb2bqumJsl9f7cVIQsAwu+QmwjNbKmkEzLcVO3uzybvUy2pUtIl7u5m1ltSP3ffaWYTJP1c0lh3/7irdbGJEHFSXp4IVR0NH55oYAcAlLauNhEessnd3acd4smvlPQ1SVM9mdbc/XNJnycvrzaztyWdIon0BCTRbQUA0ZXrUYTTJd0s6evu3pq2vMzMeiYvj5R0sqR3clkXEDV0WwFAdOW6D9aDkvpLerlDHcO5ktaYWYOkpyXNc/cPc1wXECl0WwFAdOV0smd3/5+dLH9G0jO5PDcQde0dVtXVic2Cw4YlwhXdVgAQfjS5A3mQbf1CVVVih/Z9+xLfCVcAEA05zWABOFh7/UJrcq/E9voFiQAFAHHBDBYQsOrq/eGqXWtrYjkAIB4IWEDAqF8AABCwgIBRvwAAIGABAaN+AQBAwAICVlUl1dYmTnljlvheW8sO7gAQJwQsoBuoXwAAZIOaBiBL1C8AALLFDBaQJeoXAADZImABWaJ+AQCQLQIWkCXqFwAA2SJgAVmifgEAkC0CFpAl6hcAANkiYCH2sq1ekKhfAABkh5oGxBrVCwCAfGAGC7FG9QIAIB8IWIg1qhcAAPlAwEKsUb0AAMgHAhZijeoFAEA+ELAQa1QvAADygYCFyMq2foHqBQBA0KhpQCRRvwAAKCZmsBBJ1C8AAIqJgIVIon4BAFBMBCxEEvULAIBiImAhkqhfAAAUEwELkUT9AgCgmAhYCB3qFwAApY6aBoQK9QsAgDBgBguhQv0CACAMCFgIFeoXAABhQMBCqFC/AAAIAwIWQoX6BQBAGBCwECrULwAAwiCngGVmC8zsfTNrSH5dnHbbbWa2xcw2mdlFuQ8VUZZt9YJE/QIAoPQFUdNwn7vfk77AzMZIukzSWEknSlpqZqe4+94A1oeIoXoBABA1+dpEOFPSz9z9c3d/V9IWSRPztC6EHNULAICoCSJgzTezNWb2mJkNTC4bIum9tPtsSy47iJnNNbN6M6tvbm4OYDgIG6oXAABRc8iAZWZLzWxdhq+Zkh6W9EVJFZK2S7q3uwNw91p3r3T3yrKysu4+HBFA9QIAIGoOuQ+Wu0/L5onM7FFJLySvvi/ppLSbhyaXAQepqTlwHyyJ6gUAQLjlehTh4LSrsyWtS15+TtJlZtbbzEZIOlnS67msC9FF9QIAIGpy3QfrbjNba2ZrJJ0v6UZJcvf1kp6StEHSLyVdwxGE8ZRt/QLVCwCAKMmppsHd/7KL22oksZEnxqhfAADEFU3uyBvqFwAAcUXAQt5QvwAAiCsCFvKG+gUAQFwRsJA3NTWJuoV01C8AAOKAgIW8oX4BABBXBCwcFuoXAADoXE41DYgn6hcAAOgaM1joNuoXAADoGgEL3Ub9AgAAXSNgoduoXwAAoGsELHQb9QsAAHSNgIVuo34BAICuEbCQkm31gkT9AgAAXaGmAZKoXgAAIEjMYEES1QsAAASJgAVJVC8AABAkAhYkUb0AAECQCFiQRPUCAABBImBBEtULAAAEiYAVA9nWL1C9AABAMKhpiDjqFwAAKDxmsCKO+gUAAAqPgBVx1C8AAFB4BKyIo34BAIDCI2BFHPULAAAUHgEr4qhfAACg8AhYIZVt9YJE/QIAAIVGTUMIUb0AAEBpYwYrhKheAACgtBGwQojqBQAAShsBK4SoXgAAoLQRsEKI6gUAAEobASuEqF4AAKC0EbBKTLb1C1QvAABQuqhpKCHULwAAEA05zWCZ2ZNm1pD8ajSzhuTycjP7NO22RYGMNuKoXwAAIBpymsFy92+1XzazeyW1pN38trtX5PL8cUP9AgAA0RDIPlhmZpK+KemnQTxfXFG/AABANAS1k/tkSTvcfXPashFm9qaZ/YeZTe7sgWY218zqzay+ubk5oOGEE/ULAABEwyEDlpktNbN1Gb5mpt1tjg6cvdouaZi7j5f0N5L+1cz+R6bnd/dad69098qysrJcfpbQo34BAIBoOGTAcvdp7n5ahq9nJcnMjpB0iaQn0x7zubvvTF5eLeltSafk50cIB+oXAACIjyBqGqZJesvdt7UvMLMySR+6+14zGynpZEnvBLCuUKJ+AQCAeAliH6zLdPDO7edKWpOsbXha0jx3/zCAdYUS9QsAAMRLzjNY7n5lhmXPSHom1+eOCuoXAACIF06VUwDULwAAEC8ErAKgfgEAgHghYBUA9QsAAMQLASsH2VYvSNQvAAAQJ0HUNMQS1QsAAKAzzGAdJqoXAABAZwhYh4nqBQAA0BkC1mGiegEAAHSGgHWYqF4AAACdIWAdJqoXAABAZwhYGWRbv0D1AgAAyISahg6oXwAAALliBqsD6hcAAECuCFgdUL8AAAByRcDqgPoFAACQKwJWB9QvAACAXBGwOqB+AQAA5IqjCDOoqiJQAQCAwxerGaxs+60AAAByEZsZLPqtAABAocRmBot+KwAAUCixCVj0WwEAgEKJTcCi3woAABRKbAIW/VYAAKBQYhOw6LcCAACFEpujCCX6rQAAQGHEZgYLAACgUAhYAAAAASNgAQAABIyABQAAEDACFgAAQMAIWAAAAAEjYAEAAASMgAUAABAwAhYAAEDACFgAAAABI2ABAAAEjIAFAAAQMHP3Yo8hxcyaJTUVYFXHSfp9AdZTquL+80u8BhKvgcRrEPefX+I1kHgNcvn5h7t7WaYbSipgFYqZ1bt7ZbHHUSxx//klXgOJ10DiNYj7zy/xGki8Bvn6+dlECAAAEDACFgAAQMDiGrBqiz2AIov7zy/xGki8BhKvQdx/fonXQOI1yMvPH8t9sAAAAPIprjNYAAAAeUPAAgAACFikA5aZXWpm681sn5lVdrjtNjPbYmabzOyitOXTk8u2mNmthR91/pjZk2bWkPxqNLOG5PJyM/s07bZFRR5q3pjZAjN7P+1nvTjttoyfiSgxsx+a2VtmtsbMFpvZMcnlsfkMSNH+Pe+MmZ1kZq+Y2Ybk38Xrk8s7/Z2ImuTfvbXJn7M+uexYM3vZzDYnvw8s9jjzxcxGpb3PDWb2sZndEPXPgJk9ZmYfmNm6tGUZ33dLWJj827DGzM487PVGeR8sMxstaZ+kRyTd5O7tv1BjJP1U0kRJJ0paKumU5MN+J+kCSdsk/UbSHHffUOCh552Z3Supxd3/0czKJb3g7qcVeVh5Z2YLJH3i7vd0WJ7xM+Huews+yDwyswsl/crd95jZXZLk7rfE7DPQUzH5PU9nZoMlDXb3N8ysv6TVkmZJ+qYy/E5EkZk1Sqp099+nLbtb0ofufmcybA9091uKNcZCSf4evC9pkqT/pQh/BszsXEmfSHqi/W9cZ+97MlxeK+liJV6b/+3ukw5nvZGewXL3je6+KcNNMyX9zN0/d/d3JW1R4h/WiZK2uPs77r5b0s+S940UMzMl/qj+tNhjKSGdfSYixd1fcvc9yaurJA0t5niKJBa/5x25+3Z3fyN5eZekjZKGFHdUJWGmpMeTlx9XInTGwVRJb7t7Ic6eUlTuvkLShx0Wd/a+z1QiiLm7r5J0TPI/J90W6YDVhSGS3ku7vi25rLPlUTNZ0g5335y2bISZvWlm/2Fmk4s1sAKZn5z6fSxtc0Bc3vt0V0n6Rdr1uHwG4vheHyA5Yzle0n8lF2X6nYgil/SSma02s7nJZce7+/bk5f+WdHxxhlZwl+nA/2TH5TPQrrP3PbC/D6EPWGa21MzWZfiK/P9IM8ny9ZijA3+xtksa5u7jJf2NpH81s/9RyHEH6RCvwcOSviipQomf+95ijjUfsvkMmFm1pD2S6pKLIvUZQOfMrJ+kZyTd4O4fKwa/E2m+4u5nSvqqpGuSm45SPLHPTHT3m0kysyMlfV3S/00uitNn4CD5et+PCPoJC83dpx3Gw96XdFLa9aHJZepieSgc6vUwsyMkXSJpQtpjPpf0efLyajN7W4l90urzONS8yfYzYWaPSnohebWrz0SoZPEZuFLS1yRNTf5hidxn4BAi8153l5n1UiJc1bn7v0mSu+9Iuz39dyJy3P395PcPzGyxEpuLd5jZYHffntwU9EFRB1kYX5X0Rvt7H6fPQJrO3vfA/j6EfgbrMD0n6TIz621mIySdLOl1JXZ2PdnMRiQT/mXJ+0bJNElvufu29gVmVpbc4VFmNlKJ1+OdIo0vrzpsS58tqf2oks4+E5FiZtMl3Szp6+7emrY8Np8BxeP3/CDJfS//WdJGd/+ntOWd/U5Eipkdndy5X2Z2tKQLlfhZn5N0RfJuV0h6tjgjLKgDtmLE5TPQQWfv+3OSLk8eTXiWEgeDbc/0BIcS+hmsrpjZbEkPSCqT9KKZNbj7Re6+3syekrRBic0k17QfLWZm8yX9u6Sekh5z9/VFGn6+dNzuLknnSvpHM2tT4qjLee7ecYfAqLjbzCqUmA5ulHS1JHX1mYiYByX1lvRy4t9brXL3eYrRZyB5BGXUf88zOUfSX0paa8mKFkm3S5qT6Xcigo6XtDj5uT9C0r+6+y/N7DeSnjKzb0tqUuIAoMhKhssLdOD7nPHvYlSY2U8lTZF0nJltk/QPku5U5vd9iRJHEG6R1KrEEZaHt94o1zQAAAAUQ1w3EQIAAOQNAQsAACBgBCwAAICAEbAAAAACRsACAAAIGAELAAAgYAQsAACAgP1/5A8pVASgO6QAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_1 evaluation metrics\n",
        "mae_1 = mae(y_test, y_preds_1)\n",
        "mse_1 = mse(y_test, y_preds_1)\n",
        "mae_1, mse_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOFGF_1JjruQ",
        "outputId": "c3b2a63e-d8cb-4294-bdfe-25f767d1ca1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=14.964757>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=224.79053>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Build `model_2`**\n",
        "\n",
        "* 2 dense layers, trained for 100 epochs"
      ],
      "metadata": {
        "id": "zgDLE28xkoC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_2.compile(loss = tf.keras.losses.mae,\n",
        "                optimizer = tf.keras.optimizers.SGD(),\n",
        "                metrics = [\"mse\"])\n",
        "\n",
        "# 4. Fit the model\n",
        "model_2.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq1gJHImnaCH",
        "outputId": "672ad222-862d-4a4a-c155-a4e1a267db81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 13ms/step - loss: 27.4169 - mse: 1247.8760\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 25.3289 - mse: 869.1691\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 29.2826 - mse: 1296.8933\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 16.4292 - mse: 380.3799\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 18.9667 - mse: 516.5408\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 14.1260 - mse: 281.2923\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 11.4491 - mse: 159.4910\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11.2221 - mse: 173.5045\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 41.8332 - mse: 2788.2356\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 29.0524 - mse: 1193.1322\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 8.5569 - mse: 96.4639\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 27.4352 - mse: 1034.9664\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 12.1462 - mse: 176.4271\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 35.0013 - mse: 2016.2836\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 22.7993 - mse: 739.2199\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 9.9758 - mse: 124.9450\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 17.9850 - mse: 430.4548\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 14.7988 - mse: 346.0312\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 11.6153 - mse: 196.2690\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.5564 - mse: 147.2797\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 15.4323 - mse: 324.6595\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.1129 - mse: 361.7249\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 9.2540 - mse: 118.6696\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 17.3298 - mse: 412.4175\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.9854 - mse: 336.2599\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 21.0378 - mse: 654.5240\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 25.7245 - mse: 1030.2322\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 18.2544 - mse: 527.0031\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 9.2386 - mse: 98.8252\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 28.8540 - mse: 1481.0878\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 52.2346 - mse: 4874.8223\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 11.8369 - mse: 201.0686\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 15.3679 - mse: 324.9239\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 12.5073 - mse: 204.2212\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 9.1569 - mse: 90.4324\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 16.3179 - mse: 386.3206\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 11.1288 - mse: 192.1623\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 18.2621 - mse: 440.4672\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 19.1887 - mse: 537.9027\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 20.5908 - mse: 619.0264\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 14.7108 - mse: 269.4500\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.1308 - mse: 178.0711\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.6649 - mse: 159.5092\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 32.0232 - mse: 1684.1449\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.4012 - mse: 197.6180\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 17.3271 - mse: 449.5259\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 15.8250 - mse: 341.9093\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.7977 - mse: 128.1344\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 13.0095 - mse: 244.5563\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 12.6041 - mse: 208.7324\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.6699 - mse: 299.6034\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 18.5892 - mse: 514.0114\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 23.8660 - mse: 810.7205\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.1261 - mse: 871.8494\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 23.3645 - mse: 818.2216\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.9470 - mse: 171.0500\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 12.8259 - mse: 201.7560\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 9.6482 - mse: 103.3153\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.9827 - mse: 231.7603\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 10.6827 - mse: 132.9998\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 17.4188 - mse: 426.3948\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 10.5939 - mse: 136.5462\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 10.4844 - mse: 151.3115\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 24.7783 - mse: 906.5203\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 10.6702 - mse: 141.9123\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 21.7205 - mse: 699.9588\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.7011 - mse: 135.3634\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 10.6324 - mse: 148.0652\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 22.6104 - mse: 736.6549\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.3524 - mse: 165.8464\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 15.4676 - mse: 324.3620\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0251 - mse: 67.7281\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.2263 - mse: 216.4086\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 17.3738 - mse: 408.7752\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.2302 - mse: 71.5724\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 9.4660 - mse: 148.9490\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.2033 - mse: 735.6512\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 17.4230 - mse: 461.5781\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 14.6775 - mse: 315.1710\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.6636 - mse: 930.1602\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 11.5270 - mse: 164.1201\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.4087 - mse: 226.2743\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 17.0658 - mse: 378.7738\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.2565 - mse: 75.7273\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 37.3216 - mse: 2241.7866\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 21.3011 - mse: 651.8675\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 11.0604 - mse: 148.5607\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 25.1692 - mse: 901.6702\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 9.3882 - mse: 136.5289\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 17.4410 - mse: 436.5051\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 10.8332 - mse: 160.7117\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 19.1261 - mse: 504.2479\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 8.3442 - mse: 102.4972\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 11.5868 - mse: 179.7085\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 26.1590 - mse: 1038.8386\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 11.2151 - mse: 170.0571\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 16.8171 - mse: 431.6719\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 6.6038 - mse: 60.9532\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 12.6067 - mse: 229.7338\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 19.4144 - mse: 553.3898\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8750b61580>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make and plot predictions of model_2\n",
        "y_preds_2 = model_2.predict(X_test)\n",
        "plot_predictions(predictions = y_preds_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "Cifraxu0n69N",
        "outputId": "8c7cffd3-6746-4695-f93e-4883ca77f605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 102ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_2 evaluation metrics\n",
        "mae_2 = mae(y_test, y_preds_2)\n",
        "mse_2 = mse(y_test, y_preds_2)\n",
        "mae_2, mse_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfBMypVtpBt0",
        "outputId": "7f10d43c-5551-4c7c-e045-bf764358242c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=13.202146>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=184.28748>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Build `model_3`**\n",
        "\n",
        "2 layers, 500 epochs"
      ],
      "metadata": {
        "id": "r4VHGHfksNlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_3  = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 3. Compile the model\n",
        "model_3.compile(loss = tf.keras.losses.mae,\n",
        "                optimizer = tf.keras.optimizers.SGD(),\n",
        "                metrics = [\"mae\"])\n",
        "\n",
        "# Fit the model_3\n",
        "model_3.fit(tf.expand_dims(X_train, axis = -1), y_train, epochs = 500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihNFeGaMsujQ",
        "outputId": "552ba3c6-4b9c-4b2b-c75a-bb19f71e3c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 1s 10ms/step - loss: 54.9859 - mae: 54.9859\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 29.0851 - mae: 29.0851\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 32.5785 - mae: 32.5785\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 17.5820 - mae: 17.5820\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 19.6864 - mae: 19.6864\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 14.7585 - mae: 14.7585\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.4350 - mae: 10.4350\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.1204 - mae: 12.1204\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 38.0169 - mae: 38.0169\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 25.6031 - mae: 25.6031\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.2606 - mae: 10.2606\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 25.3279 - mae: 25.3279\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.0361 - mae: 17.0361\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 26.0012 - mae: 26.0012\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 18.0608 - mae: 18.0608\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3618 - mae: 7.3618\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.8500 - mae: 10.8500\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 19.5096 - mae: 19.5096\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.3429 - mae: 10.3429\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 17.6828 - mae: 17.6828\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 15.8817 - mae: 15.8817\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.1748 - mae: 14.1748\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.7934 - mae: 8.7934\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.0798 - mae: 11.0798\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.7097 - mae: 12.7097\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 26.2507 - mae: 26.2507\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.7634 - mae: 11.7634\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 22.9326 - mae: 22.9326\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 9.2519 - mae: 9.2519\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 29.3157 - mae: 29.3157\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 53.1222 - mae: 53.1222\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.0200 - mae: 12.0200\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 15.6720 - mae: 15.6720\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.7202 - mae: 12.7202\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 9.2546 - mae: 9.2546\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.8629 - mae: 16.8629\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.4848 - mae: 12.4848\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 18.1752 - mae: 18.1752\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 19.1127 - mae: 19.1127\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.4514 - mae: 20.4514\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.8966 - mae: 14.8966\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.2711 - mae: 12.2711\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.7312 - mae: 10.7312\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 22.9686 - mae: 22.9686\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10.3805 - mae: 10.3805\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.7719 - mae: 11.7719\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.6600 - mae: 9.6600\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.2627 - mae: 17.2627\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 9.5623 - mae: 9.5623\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.7930 - mae: 13.7930\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.5905 - mae: 11.5905\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 30.4600 - mae: 30.4600\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.3167 - mae: 14.3167\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 23.6728 - mae: 23.6728\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 24.6080 - mae: 24.6080\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 11.3456 - mae: 11.3456\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 13.3659 - mae: 13.3659\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 9.9510 - mae: 9.9510\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.9211 - mae: 13.9211\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.9932 - mae: 9.9932\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.9771 - mae: 14.9771\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.9288 - mae: 11.9288\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.2887 - mae: 10.2887\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 23.8959 - mae: 23.8959\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10.4652 - mae: 10.4652\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 20.9404 - mae: 20.9404\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 10.4436 - mae: 10.4436\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 14.1814 - mae: 14.1814\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.5151 - mae: 10.5151\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 12.5865 - mae: 12.5865\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 13.0163 - mae: 13.0163\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 19.3660 - mae: 19.3660\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 11.1295 - mae: 11.1295\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 21.4541 - mae: 21.4541\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.4611 - mae: 9.4611\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 12.2848 - mae: 12.2848\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 16.3273 - mae: 16.3273\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.0088 - mae: 9.0088\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 23.5770 - mae: 23.5770\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 26.2749 - mae: 26.2749\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.4454 - mae: 11.4454\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.4386 - mae: 12.4386\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.1032 - mae: 17.1032\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.2543 - mae: 7.2543\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 37.1862 - mae: 37.1862\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 21.2028 - mae: 21.2028\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11.0208 - mae: 11.0208\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.0643 - mae: 25.0643\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.3535 - mae: 9.3535\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 17.3668 - mae: 17.3668\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.7943 - mae: 10.7943\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 19.0541 - mae: 19.0541\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.3122 - mae: 8.3122\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 11.5518 - mae: 11.5518\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 26.0886 - mae: 26.0886\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.1793 - mae: 11.1793\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.7654 - mae: 16.7654\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 6.5875 - mae: 6.5875\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.6069 - mae: 12.6069\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 19.4265 - mae: 19.4265\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.0382 - mae: 16.0382\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.1728 - mae: 11.1728\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.3194 - mae: 9.3194\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 24.8978 - mae: 24.8978\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.9565 - mae: 11.9565\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.0758 - mae: 10.0758\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 22.4504 - mae: 22.4504\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.1184 - mae: 8.1184\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.2945 - mae: 13.2945\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 7.9998 - mae: 7.9998\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 15.7869 - mae: 15.7869\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8.7434 - mae: 8.7434\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 22.6011 - mae: 22.6011\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 18.9601 - mae: 18.9601\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.0751 - mae: 11.0751\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 23.0408 - mae: 23.0408\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 9.5520 - mae: 9.5520\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.6086 - mae: 10.6086\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.0451 - mae: 8.0451\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 29.3094 - mae: 29.3094\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.0820 - mae: 8.0820\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 27.9889 - mae: 27.9889\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 32.5044 - mae: 32.5044\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 19.3372 - mae: 19.3372\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.5217 - mae: 9.5217\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.5952 - mae: 9.5952\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 12.6977 - mae: 12.6977\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.8041 - mae: 12.8041\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 13.9219 - mae: 13.9219\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 10.2362 - mae: 10.2362\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 21.6665 - mae: 21.6665\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.2777 - mae: 8.2777\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.0587 - mae: 9.0587\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 16.8732 - mae: 16.8732\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 10.6488 - mae: 10.6488\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 18.4804 - mae: 18.4804\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 23.4542 - mae: 23.4542\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.2660 - mae: 9.2660\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.0050 - mae: 9.0050\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.9231 - mae: 16.9231\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.3245 - mae: 8.3245\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 33.9519 - mae: 33.9519\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 23.0329 - mae: 23.0329\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.3468 - mae: 11.3468\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 25.0597 - mae: 25.0597\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.1230 - mae: 11.1230\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.1100 - mae: 14.1100\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 16.9673 - mae: 16.9673\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 9.2296 - mae: 9.2296\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.9319 - mae: 7.9319\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 16.4319 - mae: 16.4319\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 9.7861 - mae: 9.7861\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 26.7245 - mae: 26.7245\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 11.9508 - mae: 11.9508\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 15.3118 - mae: 15.3118\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.7056 - mae: 16.7056\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 19.1709 - mae: 19.1709\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 8.2274 - mae: 8.2274\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9983 - mae: 7.9983\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 21.0157 - mae: 21.0157\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.6636 - mae: 23.6636\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.6048 - mae: 18.6048\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 17.5612 - mae: 17.5612\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.0123 - mae: 11.0123\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 9.6371 - mae: 9.6371\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 21.6221 - mae: 21.6221\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 26.2144 - mae: 26.2144\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 9.8628 - mae: 9.8628\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 22.4745 - mae: 22.4745\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 10.1767 - mae: 10.1767\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 18.0915 - mae: 18.0915\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 28.7320 - mae: 28.7320\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 16.4519 - mae: 16.4519\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11.2320 - mae: 11.2320\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 27.6136 - mae: 27.6136\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.2586 - mae: 8.2586\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.2569 - mae: 9.2569\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 18.0421 - mae: 18.0421\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.6528 - mae: 10.6528\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 7.9024 - mae: 7.9024\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 17.3037 - mae: 17.3037\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.9854 - mae: 10.9854\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 11.6596 - mae: 11.6596\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 30.2242 - mae: 30.2242\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8.1989 - mae: 8.1989\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 18.7018 - mae: 18.7018\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 8.7845 - mae: 8.7845\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 23.6851 - mae: 23.6851\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.3977 - mae: 9.3977\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 17.1290 - mae: 17.1290\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 8.5849 - mae: 8.5849\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 15.1725 - mae: 15.1725\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 30.0114 - mae: 30.0114\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 9.6264 - mae: 9.6264\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 12.0087 - mae: 12.0087\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 23.3647 - mae: 23.3647\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 18.1157 - mae: 18.1157\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 10.8152 - mae: 10.8152\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 22.3980 - mae: 22.3980\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 17.0475 - mae: 17.0475\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.3921 - mae: 7.3921\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 26.1126 - mae: 26.1126\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 13.3600 - mae: 13.3600\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 18.3946 - mae: 18.3946\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 9.2246 - mae: 9.2246\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 10.3177 - mae: 10.3177\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 20.6272 - mae: 20.6272\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 16.1374 - mae: 16.1374\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 14.0437 - mae: 14.0437\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 18.9121 - mae: 18.9121\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 10.1993 - mae: 10.1993\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 19.4998 - mae: 19.4998\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 14.7444 - mae: 14.7444\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 14.4023 - mae: 14.4023\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 22.9089 - mae: 22.9089\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 14.3252 - mae: 14.3252\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 9.1180 - mae: 9.1180\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11.9632 - mae: 11.9632\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 6.7568 - mae: 6.7568\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 7.1340 - mae: 7.1340\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 38.2970 - mae: 38.2970\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 38.2808 - mae: 38.2808\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 5.5180 - mae: 5.5180\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 15.0491 - mae: 15.0491\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 17.1151 - mae: 17.1151\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 16.2964 - mae: 16.2964\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.6499 - mae: 16.6499\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.0474 - mae: 10.0474\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 17.9723 - mae: 17.9723\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 15.5706 - mae: 15.5706\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 21.0814 - mae: 21.0814\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 25.5670 - mae: 25.5670\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 16.5556 - mae: 16.5556\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 7.3802 - mae: 7.3802\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 17.1919 - mae: 17.1919\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 7.2429 - mae: 7.2429\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.3450 - mae: 9.3450\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.1941 - mae: 8.1941\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 17.1939 - mae: 17.1939\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.9671 - mae: 8.9671\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 13.2820 - mae: 13.2820\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 8.8735 - mae: 8.8735\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 18.9149 - mae: 18.9149\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 14.0520 - mae: 14.0520\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 14.6801 - mae: 14.6801\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 15.8153 - mae: 15.8153\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 17.6946 - mae: 17.6946\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 13.2519 - mae: 13.2519\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 14.5281 - mae: 14.5281\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 23.2514 - mae: 23.2514\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.3409 - mae: 9.3409\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 36.5911 - mae: 36.5911\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 21.7856 - mae: 21.7856\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 7.3239 - mae: 7.3239\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 24.6446 - mae: 24.6446\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 12.4223 - mae: 12.4223\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 10.5884 - mae: 10.5884\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 14.1824 - mae: 14.1824\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 11.2626 - mae: 11.2626\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 31.5374 - mae: 31.5374\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11.1815 - mae: 11.1815\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 10.0369 - mae: 10.0369\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.9560 - mae: 8.9560\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 21.4273 - mae: 21.4273\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 11.4802 - mae: 11.4802\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 13.3237 - mae: 13.3237\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 11.1047 - mae: 11.1047\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 19.1978 - mae: 19.1978\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 40.5842 - mae: 40.5842\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 12.8716 - mae: 12.8716\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 14.7806 - mae: 14.7806\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 28.5349 - mae: 28.5349\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.3597 - mae: 7.3597\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 6.3709 - mae: 6.3709\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 36.7718 - mae: 36.7718\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8.2931 - mae: 8.2931\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 27.6104 - mae: 27.6104\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 10.7080 - mae: 10.7080\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 16.1326 - mae: 16.1326\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 21.2797 - mae: 21.2797\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 23.6878 - mae: 23.6878\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.2475 - mae: 8.2475\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 8.4408 - mae: 8.4408\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 26.5177 - mae: 26.5177\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 14.1513 - mae: 14.1513\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.0202 - mae: 6.0202\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 19.0013 - mae: 19.0013\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 32.8681 - mae: 32.8681\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.3873 - mae: 8.3873\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 16.8789 - mae: 16.8789\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 17.2507 - mae: 17.2507\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 10.8896 - mae: 10.8896\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 14.5779 - mae: 14.5779\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 21.8124 - mae: 21.8124\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 19.9618 - mae: 19.9618\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 7.0087 - mae: 7.0087\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 9.0168 - mae: 9.0168\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 24.2667 - mae: 24.2667\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 17.8556 - mae: 17.8556\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 7.0244 - mae: 7.0244\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 25.3333 - mae: 25.3333\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 9.4577 - mae: 9.4577\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 14.4209 - mae: 14.4209\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 10.8399 - mae: 10.8399\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 12.6505 - mae: 12.6505\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 8.2826 - mae: 8.2826\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 13.0922 - mae: 13.0922\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 8.1448 - mae: 8.1448\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 11.7389 - mae: 11.7389\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 6.3498 - mae: 6.3498\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 4.9876 - mae: 4.9876\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 29.2899 - mae: 29.2899\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.9583 - mae: 8.9583\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 6.5096 - mae: 6.5096\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 23.9095 - mae: 23.9095\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 16.2475 - mae: 16.2475\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 20.8827 - mae: 20.8827\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 7.8763 - mae: 7.8763\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 17.8082 - mae: 17.8082\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 10.1305 - mae: 10.1305\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 8.2473 - mae: 8.2473\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 4.2663 - mae: 4.2663\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 14.6723 - mae: 14.6723\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 18.8614 - mae: 18.8614\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 17.6263 - mae: 17.6263\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 23.9722 - mae: 23.9722\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 10.3097 - mae: 10.3097\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 13.1233 - mae: 13.1233\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 15.9826 - mae: 15.9826\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 14.3235 - mae: 14.3235\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 25.7593 - mae: 25.7593\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 17.1762 - mae: 17.1762\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8.4779 - mae: 8.4779\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 13.3915 - mae: 13.3915\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.0651 - mae: 13.0651\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 32.5621 - mae: 32.5621\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 11.0931 - mae: 11.0931\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 20.0707 - mae: 20.0707\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 33.9851 - mae: 33.9851\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.6209 - mae: 8.6209\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 21.6987 - mae: 21.6987\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 14.0146 - mae: 14.0146\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 11.5422 - mae: 11.5422\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 10.6554 - mae: 10.6554\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 30.8215 - mae: 30.8215\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 10.5803 - mae: 10.5803\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 25.4374 - mae: 25.4374\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 13.5767 - mae: 13.5767\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.9196 - mae: 12.9196\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 15.3536 - mae: 15.3536\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 32.8064 - mae: 32.8064\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 13.8552 - mae: 13.8552\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 15.8616 - mae: 15.8616\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 18.9646 - mae: 18.9646\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 34.4663 - mae: 34.4663\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3153 - mae: 8.3153\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 21.9443 - mae: 21.9443\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 20.0882 - mae: 20.0882\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 11.0235 - mae: 11.0235\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 20.2409 - mae: 20.2409\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11.0532 - mae: 11.0532\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 6.8091 - mae: 6.8091\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 24.0727 - mae: 24.0727\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 29.8606 - mae: 29.8606\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3686 - mae: 8.3686\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 6.0773 - mae: 6.0773\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 35.0528 - mae: 35.0528\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 7.4204 - mae: 7.4204\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 9.6535 - mae: 9.6535\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 7.7702 - mae: 7.7702\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 20.0118 - mae: 20.0118\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 12.5274 - mae: 12.5274\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 26.4429 - mae: 26.4429\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 9.2162 - mae: 9.2162\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 4.8726 - mae: 4.8726\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 17.5805 - mae: 17.5805\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 14.2704 - mae: 14.2704\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 15.9166 - mae: 15.9166\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 19.9988 - mae: 19.9988\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 36.1196 - mae: 36.1196\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 10.2495 - mae: 10.2495\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 5.8632 - mae: 5.8632\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 14.8580 - mae: 14.8580\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 16.1466 - mae: 16.1466\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 11.6709 - mae: 11.6709\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 20.0729 - mae: 20.0729\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 24.0941 - mae: 24.0941\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 7.5358 - mae: 7.5358\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 14.1969 - mae: 14.1969\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.2606 - mae: 8.2606\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 15.5285 - mae: 15.5285\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 17.1731 - mae: 17.1731\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 10.5336 - mae: 10.5336\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 14.0768 - mae: 14.0768\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 28.4420 - mae: 28.4420\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 8.4660 - mae: 8.4660\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 11.2543 - mae: 11.2543\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 6.8726 - mae: 6.8726\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 14.1166 - mae: 14.1166\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 6.6696 - mae: 6.6696\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 7.9703 - mae: 7.9703\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 16.4047 - mae: 16.4047\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 12.3371 - mae: 12.3371\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 22.9282 - mae: 22.9282\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 18.1090 - mae: 18.1090\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 7.0175 - mae: 7.0175\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12.6449 - mae: 12.6449\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 5.6299 - mae: 5.6299\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 31.2798 - mae: 31.2798\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 9.2217 - mae: 9.2217\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 14.8502 - mae: 14.8502\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 21.7242 - mae: 21.7242\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12.6272 - mae: 12.6272\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 6.0184 - mae: 6.0184\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 13.2195 - mae: 13.2195\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 27.4240 - mae: 27.4240\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 10.6412 - mae: 10.6412\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 12.8061 - mae: 12.8061\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 15.8569 - mae: 15.8569\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 24.7285 - mae: 24.7285\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 17.5312 - mae: 17.5312\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.6795 - mae: 8.6795\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 24.9114 - mae: 24.9114\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 16.2572 - mae: 16.2572\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 7.1072 - mae: 7.1072\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 20.3678 - mae: 20.3678\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 6.2830 - mae: 6.2830\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 13.0449 - mae: 13.0449\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10.8271 - mae: 10.8271\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 11.6909 - mae: 11.6909\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 7.8627 - mae: 7.8627\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 22.1067 - mae: 22.1067\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 6.9650 - mae: 6.9650\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 32.0108 - mae: 32.0108\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 13.0289 - mae: 13.0289\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 28.1822 - mae: 28.1822\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.8262 - mae: 3.8262\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 15.0478 - mae: 15.0478\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 45.7967 - mae: 45.7967\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 26.0383 - mae: 26.0383\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 5.8769 - mae: 5.8769\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 23.2169 - mae: 23.2169\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 6.8779 - mae: 6.8779\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 20.8854 - mae: 20.8854\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 14.0130 - mae: 14.0130\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 16.6874 - mae: 16.6874\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 6.7808 - mae: 6.7808\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.0395 - mae: 6.0395\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 15.3882 - mae: 15.3882\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 17.9887 - mae: 17.9887\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 24.6002 - mae: 24.6002\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 28.9945 - mae: 28.9945\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 15.6249 - mae: 15.6249\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 13.9153 - mae: 13.9153\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 7.3765 - mae: 7.3765\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11.8344 - mae: 11.8344\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 15.2497 - mae: 15.2497\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 16.7698 - mae: 16.7698\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 6.2295 - mae: 6.2295\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 12.2659 - mae: 12.2659\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 12.5550 - mae: 12.5550\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 13.3543 - mae: 13.3543\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 29.6313 - mae: 29.6313\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 3.4352 - mae: 3.4352\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 15.2679 - mae: 15.2679\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 20.9322 - mae: 20.9322\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 30.2541 - mae: 30.2541\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 10.5714 - mae: 10.5714\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 15.0424 - mae: 15.0424\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 6.7104 - mae: 6.7104\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 22.8123 - mae: 22.8123\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 13.3622 - mae: 13.3622\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 15.2689 - mae: 15.2689\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11.7360 - mae: 11.7360\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 16.3928 - mae: 16.3928\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 13.8746 - mae: 13.8746\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 30.6594 - mae: 30.6594\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.5996 - mae: 8.5996\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 10.7436 - mae: 10.7436\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 17.9093 - mae: 17.9093\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.8112 - mae: 15.8112\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 21.3146 - mae: 21.3146\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 25.3601 - mae: 25.3601\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 23.9503 - mae: 23.9503\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.7577 - mae: 5.7577\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 19.9738 - mae: 19.9738\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 14.0435 - mae: 14.0435\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 30.6145 - mae: 30.6145\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 11.9475 - mae: 11.9475\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 12.7377 - mae: 12.7377\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 23.6220 - mae: 23.6220\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 20.5181 - mae: 20.5181\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 4.9792 - mae: 4.9792\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 12.7798 - mae: 12.7798\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 13.3816 - mae: 13.3816\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 12.6754 - mae: 12.6754\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 17.6226 - mae: 17.6226\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 23.5508 - mae: 23.5508\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 9.3653 - mae: 9.3653\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 14.6291 - mae: 14.6291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f87e49a4970>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and plot the predictions\n",
        "y_preds_3 = model_3.predict(X_test)\n",
        "plot_predictions(predictions = y_preds_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "BxWFZCRPttXL",
        "outputId": "1aed5f7c-4012-44f0-beee-ec26b1ea503a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics for model_3\n",
        "mae_3 = mae(y_test, y_preds_3)\n",
        "mse_3 = mse(y_test, y_preds_3)\n",
        "mae_3, mse_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9_1ymSoujyt",
        "outputId": "31060e97-e103-4c73-9fd7-13fd37706b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=68.700424>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=4806.219>)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** You want to start with small experiments (small models) and make sure they work and then increase their scale when necessary."
      ],
      "metadata": {
        "id": "r7fQ0Esr4sIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing the results of our experiments\n",
        "\n",
        "We've run a few experiments, let's compare the results."
      ],
      "metadata": {
        "id": "_cDHp_hBuzvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's compare model's result using a pandas DataFrame\n",
        "import pandas as pd\n",
        "model_results = [[\"model_1\", mae_1.numpy(), mse_1.numpy()],\n",
        "                 [\"model_2\", mae_2.numpy(), mse_2.numpy()],\n",
        "                 [\"model_3\", mae_3.numpy(), mse_3.numpy()]]\n",
        "              \n",
        "all_results = pd.DataFrame(model_results, columns = [\"Model\", \"mae\", \"mse\"])\n",
        "all_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "fPVl6meFvpjB",
        "outputId": "f105db9f-dac7-4b67-a4ca-ac3482809128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Model        mae          mse\n",
              "0  model_1  14.964757   224.790527\n",
              "1  model_2  13.202146   184.287476\n",
              "2  model_3  68.700424  4806.219238"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e29cb800-e951-4669-939c-aaee369108f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>mae</th>\n",
              "      <th>mse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_1</td>\n",
              "      <td>14.964757</td>\n",
              "      <td>224.790527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>model_2</td>\n",
              "      <td>13.202146</td>\n",
              "      <td>184.287476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>model_3</td>\n",
              "      <td>68.700424</td>\n",
              "      <td>4806.219238</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e29cb800-e951-4669-939c-aaee369108f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e29cb800-e951-4669-939c-aaee369108f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e29cb800-e951-4669-939c-aaee369108f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like `model_2` performed the best "
      ],
      "metadata": {
        "id": "yJuZbo6rCvXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS_Zspie8iBH",
        "outputId": "b61eb43e-a480-4321-a072-6a991f17dc28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 10)                20        \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** One of your main goals should be to minimize the time between your experiments. The more experim ent you do, the more things you'll figure out which don't work and in turn, get closer to figuring out what does work. Remember the machine learning practitioner's motto: \"experiment, experiment, experiment.\""
      ],
      "metadata": {
        "id": "IipJTV5XCSnj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tracking your experiments\n",
        "\n",
        "One really good habit in machine learning modelling is to track the results of your experiments.\n",
        "\n",
        "And when doing so, it can be tedious if you're running lots of experiments.\n",
        "\n",
        "Luckily, there are tools to help us!\n",
        "\n",
        "**Resource:** As you build more models, you'll want to look into using:\n",
        "\n",
        "* TensorBoard: a component of the TensorFlow library to help track modelling experiments (we'll see this one later).\n",
        "* Weights and biases: a tool for tracking all of kinds of machine learning experiments (plugs straight into TensorBoard)"
      ],
      "metadata": {
        "id": "bTtIgy9NDBTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving our model\n",
        "\n",
        "Saving our model allows us to use them outside of Google Colab (or wherever they were trained) such as in a web application or a mobile app.\n",
        "\n",
        "There are two main formats we can save our models to:\n",
        "1. The SavedModel format\n",
        "2. The HDF5 format "
      ],
      "metadata": {
        "id": "nNNIYQOrFIik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model using the SavedModel format\n",
        "model_2.save(\"best_model_SavedModel_format\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKQrYIE_H9Jv",
        "outputId": "3557dcc5-ae94-47d6-bf25-c1c4c6aa7f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model using the HDF5 format\n",
        "model_2.save(\"best_model_HDF5_format.h5\")"
      ],
      "metadata": {
        "id": "3fG_K2F2IIku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading in a saved model\n",
        "\n",
        "We can make sure that the model we saved above was saved perfectly if we can load that model back."
      ],
      "metadata": {
        "id": "45RIHCSkIm_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the SavedModel format model_1\n",
        "loaded_SavedModel_format = tf.keras.models.load_model(\"/content/best_model_SavedModel_format\")\n",
        "loaded_SavedModel_format.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZAO8zpaJZeP",
        "outputId": "a9fda30c-37c2-4b46-8f43-41236489503c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 10)                20        \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXgJa3neMfCk",
        "outputId": "220c4f27-591c-4e44-dede-075cb3a1da86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 10)                20        \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare model_2 predictions with SavedModel format model predictios\n",
        "model_2_preds = model_2.predict(X_test)\n",
        "loaded_SavedModel_format_preds = loaded_SavedModel_format.predict(X_test)\n",
        "model_2_preds == loaded_SavedModel_format_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Te1NqJA6NrBV",
        "outputId": "0c8433be-c740-45cf-81e2-59afa20f8efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae(y_true = y_test, y_pred = model_2_preds) == mae(y_true = y_test, y_pred = loaded_SavedModel_format_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGbNskDpORl6",
        "outputId": "5e9a319c-8107-454d-d882-3b5702ae0c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in a model using the .h5 format\n",
        "loaded_h5_model = tf.keras.models.load_model(\"/content/best_model_HDF5_format.h5\")\n",
        "loaded_h5_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N23PuSSFO8xR",
        "outputId": "c5d1eb6c-7aff-4790-af98-6671a176e043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 10)                20        \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buC11dXFPl-2",
        "outputId": "f221579c-5400-4f0b-939c-ca0271980b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 10)                20        \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to see if loaded .h5 model predictions match model_2\n",
        "model_2_preds = model_2.predict(X_test)\n",
        "loaded_h5_model_predictions = loaded_h5_model.predict(X_test)\n",
        "model_2_preds == loaded_SavedModel_format_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOu0f7IVPuAw",
        "outputId": "15c340de-2195-44e8-dbaf-d3bfabe00114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae(y_true = y_test, y_pred = model_2_preds) == mae(y_true = y_test, y_pred = loaded_h5_model_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sut1MzK0QSmU",
        "outputId": "344d62a7-889d-45a9-ad21-0dcddf31f281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download a model (or any other file) from Google Colab\n",
        "\n",
        "If you want to download your files from Google Colab:\n",
        "\n",
        "1. You can go to the \"files\" tab and right click on the file you're after and click \"download\"\n",
        "2. Use code (see the cell below).\n",
        "3. Save it to Google Drive by connecting Google Drive and connecting it there (see second code cell below)."
      ],
      "metadata": {
        "id": "8Owmxt3YQj2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a file from Google Colab\n",
        "from google.colab import files\n",
        "files.download(\"/content/best_model_HDF5_format.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "mkXNdXevcoYO",
        "outputId": "bc93e12f-4555-4e77-f3ef-b5ee68a721da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8af6d0f1-2d42-4fe5-a43c-88ff090d04fd\", \"best_model_HDF5_format.h5\", 22120)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save a file from Google Colab to Google Drive (requires mounting Google Drive)\n",
        "!cp /content/best_model_HDF5_format.h5 /content/drive/MyDrive/TensorFlow_Course "
      ],
      "metadata": {
        "id": "wE94ZZfddo_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/TensorFlow_Course"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMUxN0m7fAA2",
        "outputId": "42f03915-b349-4212-abb4-8cecc01e1981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_HDF5_format.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A larger example"
      ],
      "metadata": {
        "id": "sCsrpAtEfFxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt "
      ],
      "metadata": {
        "id": "GAIb9oFLgCnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the insurance dataset \n",
        "# Github -> Go to the dataset -> Click on \"Raw\" -> Copy the link \n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance "
      ],
      "metadata": {
        "id": "LVBP1G7sgFbl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "867220c0-2d75-47eb-dca8-b72b5b3d06a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79ea3389-17cd-4e1c-a269-575f04668f64\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79ea3389-17cd-4e1c-a269-575f04668f64')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-79ea3389-17cd-4e1c-a269-575f04668f64 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-79ea3389-17cd-4e1c-a269-575f04668f64');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try one hot encode our dataset so everything get's converted into numbers\n",
        "insurance_one_hot = pd.get_dummies(insurance)\n",
        "insurance_one_hot.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XeV6ycGXkhJe",
        "outputId": "99ca95a5-6a82-491f-9db1-fbf805c5a734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
              "0   19  27.900         0  16884.92400           1         0          0   \n",
              "1   18  33.770         1   1725.55230           0         1          1   \n",
              "2   28  33.000         3   4449.46200           0         1          1   \n",
              "3   33  22.705         0  21984.47061           0         1          1   \n",
              "4   32  28.880         0   3866.85520           0         1          1   \n",
              "\n",
              "   smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
              "0           1                 0                 0                 0   \n",
              "1           0                 0                 0                 1   \n",
              "2           0                 0                 0                 1   \n",
              "3           0                 0                 1                 0   \n",
              "4           0                 0                 1                 0   \n",
              "\n",
              "   region_southwest  \n",
              "0                 1  \n",
              "1                 0  \n",
              "2                 0  \n",
              "3                 0  \n",
              "4                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66be8184-509b-42be-9d9d-206759a03f80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66be8184-509b-42be-9d9d-206759a03f80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-66be8184-509b-42be-9d9d-206759a03f80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-66be8184-509b-42be-9d9d-206759a03f80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create X & y values (features and labels)\n",
        "X = insurance_one_hot.drop(\"charges\", axis = 1)\n",
        "y = insurance[\"charges\"]"
      ],
      "metadata": {
        "id": "2q8j8NoBnqLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_rPPxM99pAK2",
        "outputId": "7121ad98-2739-47be-fcaf-9942ba912cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
              "0   19  27.900         0           1         0          0           1   \n",
              "1   18  33.770         1           0         1          1           0   \n",
              "2   28  33.000         3           0         1          1           0   \n",
              "3   33  22.705         0           0         1          1           0   \n",
              "4   32  28.880         0           0         1          1           0   \n",
              "\n",
              "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
              "0                 0                 0                 0                 1  \n",
              "1                 0                 0                 1                 0  \n",
              "2                 0                 0                 1                 0  \n",
              "3                 0                 1                 0                 0  \n",
              "4                 0                 1                 0                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ad8aa40-a50f-44c0-8b79-c91705fba51f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ad8aa40-a50f-44c0-8b79-c91705fba51f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ad8aa40-a50f-44c0-8b79-c91705fba51f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ad8aa40-a50f-44c0-8b79-c91705fba51f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzOOhag1zUC3",
        "outputId": "dab6c74d-de6e-4b32-f7ec-21b1863a7e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    16884.92400\n",
              "1     1725.55230\n",
              "2     4449.46200\n",
              "3    21984.47061\n",
              "4     3866.85520\n",
              "Name: charges, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "len(X), len(X_train), len(X_test), len(y), len(y_train), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZZFuEWxzWrC",
        "outputId": "589d2cdc-223a-4ae7-abfb-b323969df785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1338, 1070, 268, 1338, 1070, 268)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a neural network (sort of like model_2 above)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model\n",
        "insurance_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model.compile(loss = tf.keras.losses.mae,\n",
        "                        optimizer = tf.keras.optimizers.SGD(),\n",
        "                        metrics = [\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "insurance_model.fit(X_train, y_train, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LfZd3ob0sO1",
        "outputId": "1c8453d2-3738-4a8d-d9d8-46f08fbeefca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 1s 4ms/step - loss: 8670.4580 - mae: 8670.4580\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7874.0469 - mae: 7874.0469\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7608.3691 - mae: 7608.3691\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7792.0381 - mae: 7792.0381\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7692.1118 - mae: 7692.1118\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7607.4956 - mae: 7607.4956\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7568.8550 - mae: 7568.8550\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7762.8291 - mae: 7762.8291\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7489.6558 - mae: 7489.6558\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7719.6357 - mae: 7719.6357\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7541.8618 - mae: 7541.8618\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7502.6650 - mae: 7502.6650\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7666.4121 - mae: 7666.4121\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7645.1577 - mae: 7645.1577\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7401.8267 - mae: 7401.8267\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7780.7334 - mae: 7780.7334\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7565.6553 - mae: 7565.6553\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7721.2847 - mae: 7721.2847\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 7781.7070 - mae: 7781.7070\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7867.2485 - mae: 7867.2485\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7558.3115 - mae: 7558.3115\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 7844.8120 - mae: 7844.8120\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7749.0986 - mae: 7749.0986\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7521.9839 - mae: 7521.9839\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7575.5366 - mae: 7575.5366\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7678.3237 - mae: 7678.3237\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7721.0713 - mae: 7721.0713\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 7597.0205 - mae: 7597.0205\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 7678.9170 - mae: 7678.9170\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7528.7720 - mae: 7528.7720\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7552.7476 - mae: 7552.7476\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7506.9541 - mae: 7506.9541\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 7397.6929 - mae: 7397.6929\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7407.8208 - mae: 7407.8208\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7476.7520 - mae: 7476.7520\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 7605.3267 - mae: 7605.3267\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7488.2788 - mae: 7488.2788\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7569.6978 - mae: 7569.6978\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7591.1328 - mae: 7591.1328\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7545.1567 - mae: 7545.1567\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7728.2251 - mae: 7728.2251\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7735.5894 - mae: 7735.5894\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7396.4448 - mae: 7396.4448\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7385.3193 - mae: 7385.3193\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 7398.5166 - mae: 7398.5166\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7450.6509 - mae: 7450.6509\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7399.0737 - mae: 7399.0737\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7553.9443 - mae: 7553.9443\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7533.2266 - mae: 7533.2266\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7477.3643 - mae: 7477.3643\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7407.4351 - mae: 7407.4351\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7577.1162 - mae: 7577.1162\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7561.9043 - mae: 7561.9043\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7263.0669 - mae: 7263.0669\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7443.9321 - mae: 7443.9321\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7279.3066 - mae: 7279.3066\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7342.0352 - mae: 7342.0352\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7575.9136 - mae: 7575.9136\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7499.5654 - mae: 7499.5654\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7419.5146 - mae: 7419.5146\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7535.9180 - mae: 7535.9180\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7411.6143 - mae: 7411.6143\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 7328.5840 - mae: 7328.5840\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 7181.9893 - mae: 7181.9893\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 7503.3047 - mae: 7503.3047\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 7247.0898 - mae: 7247.0898\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7245.9614 - mae: 7245.9614\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7500.9619 - mae: 7500.9619\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 7522.9287 - mae: 7522.9287\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 7541.8242 - mae: 7541.8242\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 7348.2666 - mae: 7348.2666\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 7454.1309 - mae: 7454.1309\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 7353.4077 - mae: 7353.4077\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 7470.0527 - mae: 7470.0527\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 7211.0991 - mae: 7211.0991\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7218.5190 - mae: 7218.5190\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 7313.8975 - mae: 7313.8975\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 7169.3574 - mae: 7169.3574\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 7518.7783 - mae: 7518.7783\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 7367.1465 - mae: 7367.1465\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 7270.7866 - mae: 7270.7866\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 7157.3799 - mae: 7157.3799\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 7480.0054 - mae: 7480.0054\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 7196.9976 - mae: 7196.9976\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 7362.9604 - mae: 7362.9604\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7512.4053 - mae: 7512.4053\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7248.4204 - mae: 7248.4204\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7379.7734 - mae: 7379.7734\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7503.8462 - mae: 7503.8462\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6977.3701 - mae: 6977.3701\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7234.1260 - mae: 7234.1260\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7343.4541 - mae: 7343.4541\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7540.5986 - mae: 7540.5986\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7192.3896 - mae: 7192.3896\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7470.7432 - mae: 7470.7432\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7235.1787 - mae: 7235.1787\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7191.3579 - mae: 7191.3579\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7250.3906 - mae: 7250.3906\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7403.5557 - mae: 7403.5557\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7274.8853 - mae: 7274.8853\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8743fcfd90>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the results of the insurance model on the test data \n",
        "insurance_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_ScXjQ91-1r",
        "outputId": "894a4486-428b-42e6-bd87-c6b2e83ae96c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 8557.6084 - mae: 8557.6084\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8557.6083984375, 8557.6083984375]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZScEUh0r2Zpr",
        "outputId": "9cab2f83-6262-49c2-f7d9-4ea94324447f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "560      9193.83850\n",
              "1285     8534.67180\n",
              "1142    27117.99378\n",
              "969      8596.82780\n",
              "486     12475.35130\n",
              "           ...     \n",
              "1095     4561.18850\n",
              "1130     8582.30230\n",
              "1294    11931.12525\n",
              "860     46113.51100\n",
              "1126    10214.63600\n",
              "Name: charges, Length: 1070, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.mean(), y_train.median()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rRrTIYC2lLz",
        "outputId": "739660d0-0747-4de8-981b-afed0374ce90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13346.089736364485, 9575.4421)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MAE which our model currently has is very significant as compared to the values in `y_train`. Hence, we need to try and improve our model.\n",
        "\n",
        "The experiments which we will be doing here are:\n",
        "\n",
        "1. Add one more extra layer, with more hidden units and use Adam optimizer, because SGD() made the model too complex. For a model of this complexity, a dataset like the one in use is too small to learn features. \n",
        "2. Same as above but train for longer (200 epochs)"
      ],
      "metadata": {
        "id": "poOTsnlC5pl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a neural network (sort of like model_2 above)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model\n",
        "insurance_model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_2.compile(loss = tf.keras.losses.mae,\n",
        "                        optimizer = tf.keras.optimizers.Adam(),\n",
        "                        metrics = [\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "insurance_model_2.fit(X_train, y_train, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezVJ6UD55_up",
        "outputId": "765b5e10-de54-4e61-c327-8bda69dc7ba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 1s 2ms/step - loss: 13286.3447 - mae: 13286.3447\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13129.7529 - mae: 13129.7529\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12788.2227 - mae: 12788.2227\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12110.6709 - mae: 12110.6709\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10973.4893 - mae: 10973.4893\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9512.3359 - mae: 9512.3359\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8170.0605 - mae: 8170.0605\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7519.9165 - mae: 7519.9165\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7412.3340 - mae: 7412.3340\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7392.2344 - mae: 7392.2344\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7373.6172 - mae: 7373.6172\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7352.3398 - mae: 7352.3398\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7332.5718 - mae: 7332.5718\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7310.6494 - mae: 7310.6494\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7292.1445 - mae: 7292.1445\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7270.6147 - mae: 7270.6147\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7249.9404 - mae: 7249.9404\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7227.3325 - mae: 7227.3325\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7205.2568 - mae: 7205.2568\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7181.7773 - mae: 7181.7773\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7163.0933 - mae: 7163.0933\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7135.0728 - mae: 7135.0728\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7110.2075 - mae: 7110.2075\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7084.6938 - mae: 7084.6938\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7066.0645 - mae: 7066.0645\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7034.4111 - mae: 7034.4111\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7005.9092 - mae: 7005.9092\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6977.5425 - mae: 6977.5425\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6948.8232 - mae: 6948.8232\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6921.4404 - mae: 6921.4404\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6890.7339 - mae: 6890.7339\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6861.9497 - mae: 6861.9497\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6830.4419 - mae: 6830.4419\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6799.1323 - mae: 6799.1323\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6764.4746 - mae: 6764.4746\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6730.9658 - mae: 6730.9658\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6694.5737 - mae: 6694.5737\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6665.4004 - mae: 6665.4004\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6627.8467 - mae: 6627.8467\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6594.5366 - mae: 6594.5366\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6565.7988 - mae: 6565.7988\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6543.1162 - mae: 6543.1162\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6517.5356 - mae: 6517.5356\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6496.7603 - mae: 6496.7603\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6489.8179 - mae: 6489.8179\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6469.9912 - mae: 6469.9912\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6454.3696 - mae: 6454.3696\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6441.2119 - mae: 6441.2119\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6428.9341 - mae: 6428.9341\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6415.2251 - mae: 6415.2251\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6402.7617 - mae: 6402.7617\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6390.9868 - mae: 6390.9868\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6377.4775 - mae: 6377.4775\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6364.2896 - mae: 6364.2896\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6351.1558 - mae: 6351.1558\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6337.0215 - mae: 6337.0215\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6324.9790 - mae: 6324.9790\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6311.2812 - mae: 6311.2812\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6297.1060 - mae: 6297.1060\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6286.6216 - mae: 6286.6216\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6267.5547 - mae: 6267.5547\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6255.6743 - mae: 6255.6743\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6237.9292 - mae: 6237.9292\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6221.5747 - mae: 6221.5747\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6205.3184 - mae: 6205.3184\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6188.8340 - mae: 6188.8340\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6177.0869 - mae: 6177.0869\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6155.5732 - mae: 6155.5732\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6140.0532 - mae: 6140.0532\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6120.7085 - mae: 6120.7085\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6101.7119 - mae: 6101.7119\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6084.8711 - mae: 6084.8711\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6068.8276 - mae: 6068.8276\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6043.7192 - mae: 6043.7192\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6022.7837 - mae: 6022.7837\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6009.9663 - mae: 6009.9663\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5978.9556 - mae: 5978.9556\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5957.3135 - mae: 5957.3135\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5934.7769 - mae: 5934.7769\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5908.8525 - mae: 5908.8525\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5884.4692 - mae: 5884.4692\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5858.7183 - mae: 5858.7183\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5831.8994 - mae: 5831.8994\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5799.5283 - mae: 5799.5283\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5775.4106 - mae: 5775.4106\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5743.1812 - mae: 5743.1812\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5709.2007 - mae: 5709.2007\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5677.8574 - mae: 5677.8574\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5640.7256 - mae: 5640.7256\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5602.9565 - mae: 5602.9565\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5570.3599 - mae: 5570.3599\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5524.1494 - mae: 5524.1494\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5486.5537 - mae: 5486.5537\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5445.6089 - mae: 5445.6089\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5396.4482 - mae: 5396.4482\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5354.8247 - mae: 5354.8247\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5305.1577 - mae: 5305.1577\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5247.9976 - mae: 5247.9976\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5193.3066 - mae: 5193.3066\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5139.5630 - mae: 5139.5630\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8743ee3370>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the `insurance_model_2`\n",
        "insurance_model_2.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2wIKr0H6zEf",
        "outputId": "a342d09d-e001-4ce8-b615-0492eab097a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 5009.0547 - mae: 5009.0547\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5009.0546875, 5009.0546875]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a neural network (sort of like model_2 above)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model\n",
        "insurance_model_3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_3.compile(loss = tf.keras.losses.mae,\n",
        "                        optimizer = tf.keras.optimizers.Adam(),\n",
        "                        metrics = [\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "history = insurance_model_3.fit(X_train, y_train, epochs = 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71L9GNIS67th",
        "outputId": "0a20f282-a3dd-4c19-9ce3-f50a1c196557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 1s 4ms/step - loss: 13282.4971 - mae: 13282.4971\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13096.3818 - mae: 13096.3818\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12719.3652 - mae: 12719.3652\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12000.6240 - mae: 12000.6240\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10829.5713 - mae: 10829.5713\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9377.6582 - mae: 9377.6582\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8088.1982 - mae: 8088.1982\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7507.3882 - mae: 7507.3882\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7418.3433 - mae: 7418.3433\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7398.7944 - mae: 7398.7944\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7380.1299 - mae: 7380.1299\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7357.6650 - mae: 7357.6650\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7336.9424 - mae: 7336.9424\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7314.3623 - mae: 7314.3623\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7295.0107 - mae: 7295.0107\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7272.2061 - mae: 7272.2061\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7251.4844 - mae: 7251.4844\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7227.4766 - mae: 7227.4766\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7204.3125 - mae: 7204.3125\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7179.8247 - mae: 7179.8247\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7159.6152 - mae: 7159.6152\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7130.8608 - mae: 7130.8608\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7104.5273 - mae: 7104.5273\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7077.2173 - mae: 7077.2173\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7056.0742 - mae: 7056.0742\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7023.2397 - mae: 7023.2397\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6992.3521 - mae: 6992.3521\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6961.4731 - mae: 6961.4731\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6929.9023 - mae: 6929.9023\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6900.7881 - mae: 6900.7881\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6866.2700 - mae: 6866.2700\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6834.1602 - mae: 6834.1602\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6798.4229 - mae: 6798.4229\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6762.8979 - mae: 6762.8979\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6724.3730 - mae: 6724.3730\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6686.5938 - mae: 6686.5938\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6647.3618 - mae: 6647.3618\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6614.8115 - mae: 6614.8115\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6575.5806 - mae: 6575.5806\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6545.9453 - mae: 6545.9453\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6521.4976 - mae: 6521.4976\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6499.8452 - mae: 6499.8452\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6481.3364 - mae: 6481.3364\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6462.9365 - mae: 6462.9365\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6454.1650 - mae: 6454.1650\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6436.3931 - mae: 6436.3931\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6420.6123 - mae: 6420.6123\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6406.3228 - mae: 6406.3228\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6394.9004 - mae: 6394.9004\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6379.9160 - mae: 6379.9160\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6365.6030 - mae: 6365.6030\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6352.1826 - mae: 6352.1826\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6336.8169 - mae: 6336.8169\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6322.3804 - mae: 6322.3804\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6307.8691 - mae: 6307.8691\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6293.0840 - mae: 6293.0840\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6278.4878 - mae: 6278.4878\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6263.5415 - mae: 6263.5415\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6246.5303 - mae: 6246.5303\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6234.3823 - mae: 6234.3823\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6213.1426 - mae: 6213.1426\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6199.3242 - mae: 6199.3242\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6179.3350 - mae: 6179.3350\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6161.0151 - mae: 6161.0151\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6141.7446 - mae: 6141.7446\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6122.6577 - mae: 6122.6577\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6108.4321 - mae: 6108.4321\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6082.9990 - mae: 6082.9990\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6065.2373 - mae: 6065.2373\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6043.4736 - mae: 6043.4736\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6020.6978 - mae: 6020.6978\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5998.5596 - mae: 5998.5596\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5982.5771 - mae: 5982.5771\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5950.0986 - mae: 5950.0986\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5925.8242 - mae: 5925.8242\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5906.8799 - mae: 5906.8799\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5873.4678 - mae: 5873.4678\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5846.3281 - mae: 5846.3281\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5817.5273 - mae: 5817.5273\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5785.8096 - mae: 5785.8096\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5757.1592 - mae: 5757.1592\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5723.4531 - mae: 5723.4531\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5691.4932 - mae: 5691.4932\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5654.6475 - mae: 5654.6475\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5624.3350 - mae: 5624.3350\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5584.3364 - mae: 5584.3364\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5541.6357 - mae: 5541.6357\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5500.0122 - mae: 5500.0122\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5455.8320 - mae: 5455.8320\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5407.1948 - mae: 5407.1948\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5363.7144 - mae: 5363.7144\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5312.1362 - mae: 5312.1362\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5261.3628 - mae: 5261.3628\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5207.5537 - mae: 5207.5537\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5148.4199 - mae: 5148.4199\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5097.7246 - mae: 5097.7246\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 5035.7783 - mae: 5035.7783\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 4967.7222 - mae: 4967.7222\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 4897.3472 - mae: 4897.3472\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 4837.0059 - mae: 4837.0059\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4757.2319 - mae: 4757.2319\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 4676.1226 - mae: 4676.1226\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4598.9497 - mae: 4598.9497\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4512.8306 - mae: 4512.8306\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4424.7661 - mae: 4424.7661\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4347.9785 - mae: 4347.9785\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4266.5991 - mae: 4266.5991\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4187.7671 - mae: 4187.7671\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4112.3789 - mae: 4112.3789\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4046.4795 - mae: 4046.4795\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3992.2332 - mae: 3992.2332\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3955.2729 - mae: 3955.2729\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3921.4673 - mae: 3921.4673\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3907.6021 - mae: 3907.6021\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3872.8037 - mae: 3872.8037\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3863.8318 - mae: 3863.8318\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3854.2842 - mae: 3854.2842\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3840.8447 - mae: 3840.8447\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3825.5676 - mae: 3825.5676\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3812.2722 - mae: 3812.2722\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3808.9854 - mae: 3808.9854\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3806.8491 - mae: 3806.8491\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3800.2583 - mae: 3800.2583\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3794.2034 - mae: 3794.2034\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3785.6179 - mae: 3785.6179\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3793.5886 - mae: 3793.5886\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3788.9333 - mae: 3788.9333\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3782.9458 - mae: 3782.9458\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3796.1155 - mae: 3796.1155\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3784.1543 - mae: 3784.1543\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3776.3962 - mae: 3776.3962\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3769.6729 - mae: 3769.6729\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3765.2446 - mae: 3765.2446\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3767.0679 - mae: 3767.0679\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3762.3613 - mae: 3762.3613\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3761.4646 - mae: 3761.4646\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3768.8289 - mae: 3768.8289\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3778.8110 - mae: 3778.8110\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3756.5291 - mae: 3756.5291\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3757.9595 - mae: 3757.9595\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3758.8943 - mae: 3758.8943\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3762.2124 - mae: 3762.2124\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3749.3328 - mae: 3749.3328\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3746.0535 - mae: 3746.0535\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3746.4922 - mae: 3746.4922\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3751.8713 - mae: 3751.8713\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3747.3818 - mae: 3747.3818\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3751.0027 - mae: 3751.0027\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3739.4661 - mae: 3739.4661\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3734.8730 - mae: 3734.8730\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3736.1914 - mae: 3736.1914\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3737.6240 - mae: 3737.6240\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3741.4871 - mae: 3741.4871\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3732.2544 - mae: 3732.2544\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3733.5715 - mae: 3733.5715\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3732.9236 - mae: 3732.9236\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3729.0371 - mae: 3729.0371\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3725.7798 - mae: 3725.7798\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3722.4072 - mae: 3722.4072\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3729.0486 - mae: 3729.0486\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3725.6233 - mae: 3725.6233\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3720.7383 - mae: 3720.7383\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3719.6741 - mae: 3719.6741\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3724.1572 - mae: 3724.1572\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3712.6672 - mae: 3712.6672\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3717.5400 - mae: 3717.5400\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3716.8330 - mae: 3716.8330\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3712.2056 - mae: 3712.2056\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3710.2690 - mae: 3710.2690\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3705.0359 - mae: 3705.0359\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3704.7043 - mae: 3704.7043\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3708.3491 - mae: 3708.3491\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3701.9036 - mae: 3701.9036\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3707.2561 - mae: 3707.2561\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3708.8201 - mae: 3708.8201\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3703.4900 - mae: 3703.4900\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3700.0071 - mae: 3700.0071\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3694.3594 - mae: 3694.3594\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3703.3506 - mae: 3703.3506\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3708.5254 - mae: 3708.5254\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3693.8779 - mae: 3693.8779\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3690.4656 - mae: 3690.4656\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3688.8596 - mae: 3688.8596\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3696.1411 - mae: 3696.1411\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3690.9966 - mae: 3690.9966\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3691.2983 - mae: 3691.2983\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3683.3147 - mae: 3683.3147\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3691.1187 - mae: 3691.1187\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3681.0137 - mae: 3681.0139\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3682.1904 - mae: 3682.1904\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3695.8721 - mae: 3695.8721\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3681.5247 - mae: 3681.5247\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3672.3000 - mae: 3672.3000\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3672.4260 - mae: 3672.4260\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3670.6047 - mae: 3670.6047\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3680.8501 - mae: 3680.8501\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3664.5586 - mae: 3664.5586\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3670.7024 - mae: 3670.7024\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3679.8687 - mae: 3679.8687\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3664.4253 - mae: 3664.4253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our third model aka `insurance_model_3`\n",
        "insurance_model_3.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFkMdlY68Q7X",
        "outputId": "57fec020-456b-4e23-b0c3-0d394aa0abb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3485.9097 - mae: 3485.9097\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3485.90966796875, 3485.90966796875]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "insurance_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm7fzlPN8V6-",
        "outputId": "7902449a-b5e6-4c64-ce43-6eecd1f90435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 8557.6084 - mae: 8557.6084\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8557.6083984375, 8557.6083984375]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot history (also known as loss curve or training curve)\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epochs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "3O7lvGL28-Bi",
        "outputId": "df71467f-66ed-404d-f157-896cdf31bc31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** How long should we train the model for?\n",
        "It depends on the question you are working on. To deal with this question, TensorFlow has a solution in the name of Early Stopping Callback. In a nuthsell, it means that stop training the model if a given metric of the model does not improve for some continuous number of epochs i.e. that the model has stopped learning"
      ],
      "metadata": {
        "id": "6wEFukEK9ckh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing data (normalization and standarization)\n",
        "\n",
        "In terms of scaling values, neural networks tend to prefer normalization.\n",
        "\n",
        "If you're not sure which one to use, you could try both and see which one performs better."
      ],
      "metadata": {
        "id": "ixDctNDZ-XLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "kcBluDg3_FvG",
        "outputId": "65cb4935-2486-4bc5-829f-9bf8d0faee59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ed080bf-8374-4d00-9b51-2d2d9b9cfb4c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ed080bf-8374-4d00-9b51-2d2d9b9cfb4c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ed080bf-8374-4d00-9b51-2d2d9b9cfb4c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ed080bf-8374-4d00-9b51-2d2d9b9cfb4c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To prepare our data, we import a few classes from Scikit-Learn "
      ],
      "metadata": {
        "id": "qT15RFkxCayP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "\n",
        "# Create column transformer (this will help us normalize/preprocess our data)\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]), # get all values between 0 and 1\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
        ")\n",
        "\n",
        "# Create X & y\n",
        "X = insurance.drop(\"charges\", axis=1)\n",
        "y = insurance[\"charges\"]\n",
        "\n",
        "# Build our train and test sets (use random state to ensure same split as before)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit column transformer on the training data only (doing so on test data would result in data leakage)\n",
        "ct.fit(X_train)\n",
        "\n",
        "# Transform training and test data with normalization (MinMaxScalar) and one hot encoding (OneHotEncoder)\n",
        "X_train_normal = ct.transform(X_train)\n",
        "X_test_normal = ct.transform(X_test)"
      ],
      "metadata": {
        "id": "36eHSA6wysSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What does our data look like now?\n",
        "X_train.loc[0] # This is the original data, the one we started with "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-nl_Dp7HQXc",
        "outputId": "625f9434-d7fb-494c-b7db-c635837a5947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                19\n",
              "sex            female\n",
              "bmi              27.9\n",
              "children            0\n",
              "smoker            yes\n",
              "region      southwest\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_normal[78] # This is the data we have right now, after normalization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOgvtBM_IZXk",
        "outputId": "9300b2a0-c843-4051-da50-01fd7459f19f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.43478261, 0.33118106, 0.2       , 0.        , 1.        ,\n",
              "       1.        , 0.        , 0.        , 0.        , 1.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_normal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebqP8HkSIa_d",
        "outputId": "b2376c69-de71-45de-b85d-e6226b4cdc0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.60869565, 0.10734463, 0.4       , ..., 1.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.63043478, 0.22491256, 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.73913043, 0.23944041, 0.        , ..., 0.        , 1.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.86956522, 0.24791499, 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.41304348, 0.85122411, 0.4       , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.80434783, 0.37503363, 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_train_normal.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f48VU81hIuHa",
        "outputId": "a488a558-7cf4-44ac-fd5b-be9e0b64dca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1070, 6), (1070, 11))"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our data is normalized and one hot encoded. Now, let's build a neural network model"
      ],
      "metadata": {
        "id": "uagVi7GCI3U7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a neural network model to fit on our normalized data\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "insurance_model_4 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_4.compile(loss= tf.keras.losses.mae,\n",
        "                         optimizer = tf.keras.optimizers.SGD(),\n",
        "                         metrics = [\"mae\"])\n",
        "\n",
        "# 3. Fit the model \n",
        "insurance_model_4.fit(X_train_normal, y_train, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n97WfVg6JKl3",
        "outputId": "1bb1a551-55b3-4398-cc25-d66cab3a2f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 1s 2ms/step - loss: 13340.8467 - mae: 13340.8467\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 11583.2441 - mae: 11583.2441\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6287.0601 - mae: 6287.0601\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5571.6865 - mae: 5571.6865\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5250.2153 - mae: 5250.2153\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5036.7227 - mae: 5036.7227\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5106.2729 - mae: 5106.2729\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5412.0571 - mae: 5412.0571\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5048.9932 - mae: 5048.9932\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5307.3394 - mae: 5307.3394\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4679.8555 - mae: 4679.8555\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5212.4229 - mae: 5212.4229\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4801.4463 - mae: 4801.4463\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5145.7339 - mae: 5145.7339\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5106.3833 - mae: 5106.3833\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4885.1704 - mae: 4885.1704\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4762.7974 - mae: 4762.7974\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5320.4565 - mae: 5320.4565\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5248.4097 - mae: 5248.4097\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5271.5796 - mae: 5271.5796\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5160.9478 - mae: 5160.9478\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5034.9272 - mae: 5034.9272\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4571.2134 - mae: 4571.2134\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4716.7065 - mae: 4716.7065\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4956.1567 - mae: 4956.1567\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5193.8589 - mae: 5193.8589\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5148.2085 - mae: 5148.2085\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5223.1416 - mae: 5223.1416\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5052.6704 - mae: 5052.6704\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5326.1860 - mae: 5326.1860\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5300.8608 - mae: 5300.8608\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5080.5391 - mae: 5080.5391\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5047.6558 - mae: 5047.6558\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4909.4517 - mae: 4909.4517\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5003.3389 - mae: 5003.3389\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5309.7012 - mae: 5309.7012\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5112.4131 - mae: 5112.4131\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4935.5405 - mae: 4935.5405\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5473.8672 - mae: 5473.8672\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4935.1064 - mae: 4935.1064\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5312.4033 - mae: 5312.4033\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4675.7285 - mae: 4675.7285\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5195.0361 - mae: 5195.0361\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5016.5830 - mae: 5016.5830\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4846.5786 - mae: 4846.5786\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5032.6934 - mae: 5032.6934\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5147.8286 - mae: 5147.8286\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5159.2324 - mae: 5159.2324\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4814.2803 - mae: 4814.2803\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4816.1162 - mae: 4816.1162\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4760.0903 - mae: 4760.0903\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4604.5254 - mae: 4604.5254\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4906.2778 - mae: 4906.2778\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5257.8530 - mae: 5257.8530\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5143.9556 - mae: 5143.9556\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4889.7852 - mae: 4889.7852\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5473.2290 - mae: 5473.2290\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5121.8809 - mae: 5121.8809\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5136.2563 - mae: 5136.2563\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5133.0049 - mae: 5133.0049\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5418.5127 - mae: 5418.5127\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4781.3101 - mae: 4781.3101\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4691.5293 - mae: 4691.5293\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5370.6299 - mae: 5370.6299\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5268.4741 - mae: 5268.4741\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5010.0464 - mae: 5010.0464\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5126.2056 - mae: 5126.2056\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5246.7373 - mae: 5246.7373\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5153.9062 - mae: 5153.9062\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5133.3057 - mae: 5133.3057\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4994.3086 - mae: 4994.3086\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5553.7188 - mae: 5553.7188\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4888.7261 - mae: 4888.7261\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4789.7085 - mae: 4789.7085\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 5034.5293 - mae: 5034.5293\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 4713.4907 - mae: 4713.4907\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 5130.7910 - mae: 5130.7910\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 5121.4941 - mae: 5121.4941\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5007.2383 - mae: 5007.2383\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4973.2026 - mae: 4973.2026\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5076.0654 - mae: 5076.0654\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5592.3740 - mae: 5592.3740\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4976.1421 - mae: 4976.1421\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4427.4639 - mae: 4427.4639\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4596.1396 - mae: 4596.1396\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4976.5605 - mae: 4976.5605\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 5123.2979 - mae: 5123.2979\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 5073.4883 - mae: 5073.4883\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 4897.0977 - mae: 4897.0977\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 4882.5098 - mae: 4882.5098\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 4990.8149 - mae: 4990.8149\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 5407.8384 - mae: 5407.8384\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5040.9878 - mae: 5040.9878\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5640.0776 - mae: 5640.0776\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4693.7915 - mae: 4693.7915\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4950.9390 - mae: 4950.9390\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4805.2095 - mae: 4805.2095\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4871.9683 - mae: 4871.9683\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4894.0679 - mae: 4894.0679\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4743.1641 - mae: 4743.1641\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f874891f9a0>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our `insurance_model_4` trained on normalised data\n",
        "insurance_model_4.evaluate(X_test_normal, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKv6BzQcKuN3",
        "outputId": "af037b71-72f9-477f-d798-f5ca775b2d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 3ms/step - loss: 3574.3762 - mae: 3574.3762\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3574.376220703125, 3574.376220703125]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Insurance model 2 results \n",
        "# 9/9 [==============================] - 0s 3ms/step - loss: 4880.5015 - mae: 4880.5015\n",
        "# [4880.50146484375, 4880.50146484375]"
      ],
      "metadata": {
        "id": "WQQpcIF9LJp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "1. Create your own regression dataset (or make the one we created in \"Create data to view and fit\" bigger) and build fit a model to it.\n",
        "2. Try building a neural network with 4 Dense layers and fitting it to your own regression dataset, how does it perform?\n",
        "3. Try and improve the results we got on the insurance dataset, some things you might want to try include:\n",
        "  * Building a larger model (how does one with 4 dense layers go?).\n",
        "  * Increasing the number of units in each layer.\n",
        "  * Lookup the documentation of Adam and find out what the first parameter is, what happens if you increase it by 10x?\n",
        "4. What happens if you train for longer (say 300 epochs instead of 200)?\n",
        "5. Import the Boston pricing dataset from TensorFlow tf.keras.datasets and model it."
      ],
      "metadata": {
        "id": "GwkM3J7UP7Xh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1 and Question 2:\n"
      ],
      "metadata": {
        "id": "Li1BK1ULXNLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Put the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Making the data\n",
        "X = np.random.randint(0, 1000, size = 500)\n",
        "y = (50*X)+ 10\n",
        "\n",
        "# Making the training and test sets \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "metadata": {
        "id": "6Yst6M1_S7Ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the model\n",
        "ex_model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "ex_model_1.compile(loss = tf.keras.losses.mae,\n",
        "                   optimizer = tf.keras.optimizers.Adam(),\n",
        "                   metrics = [\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "ex_model_1.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaWC73WtT1-P",
        "outputId": "55410ab1-99c0-4e0b-ba8b-3ed9373aaa72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "13/13 [==============================] - 1s 2ms/step - loss: 23651.9453 - mae: 23651.9453\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 23240.5645 - mae: 23240.5645\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 22770.0527 - mae: 22770.0527\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 22195.6699 - mae: 22195.6699\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 21480.1191 - mae: 21480.1191\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 20541.9531 - mae: 20541.9531\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 19345.3418 - mae: 19345.3418\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 17832.5430 - mae: 17832.5430\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 15893.5088 - mae: 15893.5088\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 13565.9248 - mae: 13565.9248\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10720.7471 - mae: 10720.7471\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7308.2642 - mae: 7308.2642\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3267.0908 - mae: 3267.0908\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 805.6335 - mae: 805.6335\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 404.0069 - mae: 404.0069\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 148.5140 - mae: 148.5140\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 75.7204 - mae: 75.7204\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 73.1989 - mae: 73.1989\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 35.5027 - mae: 35.5027\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 20.1014 - mae: 20.1014\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 21.1141 - mae: 21.1141\n",
            "Epoch 22/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 42.2725 - mae: 42.2725\n",
            "Epoch 23/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 34.2992 - mae: 34.2992\n",
            "Epoch 24/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 14.5429 - mae: 14.5429\n",
            "Epoch 25/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 20.8890 - mae: 20.8890\n",
            "Epoch 26/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 32.9329 - mae: 32.9329\n",
            "Epoch 27/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 35.1876 - mae: 35.1876\n",
            "Epoch 28/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 25.5023 - mae: 25.5023\n",
            "Epoch 29/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 16.4505 - mae: 16.4505\n",
            "Epoch 30/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 11.1583 - mae: 11.1583\n",
            "Epoch 31/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 17.5930 - mae: 17.5930\n",
            "Epoch 32/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 29.7575 - mae: 29.7575\n",
            "Epoch 33/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 17.6571 - mae: 17.6571\n",
            "Epoch 34/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 18.4051 - mae: 18.4051\n",
            "Epoch 35/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 14.4447 - mae: 14.4447\n",
            "Epoch 36/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 27.8465 - mae: 27.8465\n",
            "Epoch 37/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 35.0571 - mae: 35.0571\n",
            "Epoch 38/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 43.0228 - mae: 43.0228\n",
            "Epoch 39/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 19.3097 - mae: 19.3097\n",
            "Epoch 40/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 25.8681 - mae: 25.8681\n",
            "Epoch 41/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 38.1228 - mae: 38.1228\n",
            "Epoch 42/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 28.1914 - mae: 28.1914\n",
            "Epoch 43/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 31.9273 - mae: 31.9273\n",
            "Epoch 44/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 12.1043 - mae: 12.1043\n",
            "Epoch 45/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 14.6887 - mae: 14.6887\n",
            "Epoch 46/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 21.9964 - mae: 21.9964\n",
            "Epoch 47/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 51.2510 - mae: 51.2510\n",
            "Epoch 48/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 38.1274 - mae: 38.1274\n",
            "Epoch 49/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 14.4364 - mae: 14.4364\n",
            "Epoch 50/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 35.8421 - mae: 35.8421\n",
            "Epoch 51/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 34.6493 - mae: 34.6493\n",
            "Epoch 52/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 13.3312 - mae: 13.3312\n",
            "Epoch 53/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 13.0865 - mae: 13.0865\n",
            "Epoch 54/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 17.6750 - mae: 17.6750\n",
            "Epoch 55/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 24.4808 - mae: 24.4808\n",
            "Epoch 56/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 19.5249 - mae: 19.5249\n",
            "Epoch 57/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 27.6361 - mae: 27.6361\n",
            "Epoch 58/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 28.2260 - mae: 28.2260\n",
            "Epoch 59/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 19.7399 - mae: 19.7399\n",
            "Epoch 60/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 40.6318 - mae: 40.6318\n",
            "Epoch 61/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 62.5078 - mae: 62.5078\n",
            "Epoch 62/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 23.0837 - mae: 23.0837\n",
            "Epoch 63/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 15.2708 - mae: 15.2708\n",
            "Epoch 64/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 36.6413 - mae: 36.6413\n",
            "Epoch 65/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 39.9367 - mae: 39.9367\n",
            "Epoch 66/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 47.6950 - mae: 47.6950\n",
            "Epoch 67/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 23.8598 - mae: 23.8598\n",
            "Epoch 68/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 31.5159 - mae: 31.5159\n",
            "Epoch 69/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 11.0649 - mae: 11.0649\n",
            "Epoch 70/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.5902 - mae: 7.5902\n",
            "Epoch 71/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 12.3752 - mae: 12.3752\n",
            "Epoch 72/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 18.9757 - mae: 18.9757\n",
            "Epoch 73/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 17.8073 - mae: 17.8073\n",
            "Epoch 74/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 44.4856 - mae: 44.4856\n",
            "Epoch 75/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 19.5959 - mae: 19.5959\n",
            "Epoch 76/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 32.9223 - mae: 32.9223\n",
            "Epoch 77/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 35.0925 - mae: 35.0925\n",
            "Epoch 78/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 35.7052 - mae: 35.7052\n",
            "Epoch 79/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 22.2319 - mae: 22.2319\n",
            "Epoch 80/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 18.4719 - mae: 18.4719\n",
            "Epoch 81/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 18.7411 - mae: 18.7411\n",
            "Epoch 82/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 16.2900 - mae: 16.2900\n",
            "Epoch 83/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 12.1703 - mae: 12.1703\n",
            "Epoch 84/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 11.7381 - mae: 11.7381\n",
            "Epoch 85/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 19.1518 - mae: 19.1518\n",
            "Epoch 86/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 49.8346 - mae: 49.8346\n",
            "Epoch 87/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 28.0082 - mae: 28.0082\n",
            "Epoch 88/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 33.5576 - mae: 33.5576\n",
            "Epoch 89/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 33.5811 - mae: 33.5811\n",
            "Epoch 90/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 15.8966 - mae: 15.8966\n",
            "Epoch 91/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 21.8435 - mae: 21.8435\n",
            "Epoch 92/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 30.5467 - mae: 30.5467\n",
            "Epoch 93/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 24.3674 - mae: 24.3674\n",
            "Epoch 94/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 11.5736 - mae: 11.5736\n",
            "Epoch 95/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 31.1553 - mae: 31.1553\n",
            "Epoch 96/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 21.6486 - mae: 21.6486\n",
            "Epoch 97/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 14.3013 - mae: 14.3013\n",
            "Epoch 98/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 29.9769 - mae: 29.9769\n",
            "Epoch 99/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 53.9892 - mae: 53.9892\n",
            "Epoch 100/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 23.2642 - mae: 23.2642\n",
            "Epoch 101/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 20.9684 - mae: 20.9684\n",
            "Epoch 102/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 32.8008 - mae: 32.8008\n",
            "Epoch 103/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 30.8313 - mae: 30.8313\n",
            "Epoch 104/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 31.7417 - mae: 31.7417\n",
            "Epoch 105/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 29.0327 - mae: 29.0327\n",
            "Epoch 106/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 46.3773 - mae: 46.3773\n",
            "Epoch 107/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 42.9049 - mae: 42.9049\n",
            "Epoch 108/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 34.6537 - mae: 34.6537\n",
            "Epoch 109/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 26.3954 - mae: 26.3954\n",
            "Epoch 110/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 47.5926 - mae: 47.5926\n",
            "Epoch 111/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 35.8893 - mae: 35.8893\n",
            "Epoch 112/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 11.2096 - mae: 11.2096\n",
            "Epoch 113/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 16.3727 - mae: 16.3727\n",
            "Epoch 114/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 10.0352 - mae: 10.0352\n",
            "Epoch 115/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 14.8919 - mae: 14.8919\n",
            "Epoch 116/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 30.3215 - mae: 30.3215\n",
            "Epoch 117/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 20.9882 - mae: 20.9882\n",
            "Epoch 118/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 11.9843 - mae: 11.9843\n",
            "Epoch 119/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 15.8197 - mae: 15.8197\n",
            "Epoch 120/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.7297 - mae: 10.7297\n",
            "Epoch 121/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 21.0310 - mae: 21.0310\n",
            "Epoch 122/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 34.0179 - mae: 34.0179\n",
            "Epoch 123/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 36.6413 - mae: 36.6413\n",
            "Epoch 124/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 44.6308 - mae: 44.6308\n",
            "Epoch 125/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 19.2376 - mae: 19.2376\n",
            "Epoch 126/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 18.0976 - mae: 18.0976\n",
            "Epoch 127/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 17.6236 - mae: 17.6236\n",
            "Epoch 128/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 11.7534 - mae: 11.7534\n",
            "Epoch 129/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 12.2926 - mae: 12.2926\n",
            "Epoch 130/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 11.5036 - mae: 11.5036\n",
            "Epoch 131/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 29.8982 - mae: 29.8982\n",
            "Epoch 132/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 17.7736 - mae: 17.7736\n",
            "Epoch 133/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 27.7361 - mae: 27.7361\n",
            "Epoch 134/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 29.5794 - mae: 29.5794\n",
            "Epoch 135/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 34.4196 - mae: 34.4196\n",
            "Epoch 136/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 39.9341 - mae: 39.9341\n",
            "Epoch 137/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 33.5928 - mae: 33.5928\n",
            "Epoch 138/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 39.7989 - mae: 39.7989\n",
            "Epoch 139/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 13.4312 - mae: 13.4312\n",
            "Epoch 140/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 28.8750 - mae: 28.8750\n",
            "Epoch 141/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 22.5514 - mae: 22.5514\n",
            "Epoch 142/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 21.6400 - mae: 21.6400\n",
            "Epoch 143/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 21.3068 - mae: 21.3068\n",
            "Epoch 144/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 16.4266 - mae: 16.4266\n",
            "Epoch 145/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 23.2562 - mae: 23.2562\n",
            "Epoch 146/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 33.7204 - mae: 33.7204\n",
            "Epoch 147/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 72.7229 - mae: 72.7229\n",
            "Epoch 148/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 67.9977 - mae: 67.9977\n",
            "Epoch 149/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 42.6295 - mae: 42.6295\n",
            "Epoch 150/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 32.5098 - mae: 32.5098\n",
            "Epoch 151/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 35.1042 - mae: 35.1042\n",
            "Epoch 152/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 10.3137 - mae: 10.3137\n",
            "Epoch 153/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 16.5973 - mae: 16.5973\n",
            "Epoch 154/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 34.4464 - mae: 34.4464\n",
            "Epoch 155/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 19.5159 - mae: 19.5159\n",
            "Epoch 156/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 21.1507 - mae: 21.1507\n",
            "Epoch 157/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 20.9813 - mae: 20.9813\n",
            "Epoch 158/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 19.6772 - mae: 19.6772\n",
            "Epoch 159/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 26.6262 - mae: 26.6262\n",
            "Epoch 160/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 29.7887 - mae: 29.7887\n",
            "Epoch 161/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 39.6742 - mae: 39.6742\n",
            "Epoch 162/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 21.5850 - mae: 21.5850\n",
            "Epoch 163/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 55.2790 - mae: 55.2790\n",
            "Epoch 164/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 15.5135 - mae: 15.5135\n",
            "Epoch 165/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 17.0181 - mae: 17.0181\n",
            "Epoch 166/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 25.5484 - mae: 25.5484\n",
            "Epoch 167/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 20.5291 - mae: 20.5291\n",
            "Epoch 168/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 32.3073 - mae: 32.3073\n",
            "Epoch 169/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 16.5072 - mae: 16.5072\n",
            "Epoch 170/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 15.8874 - mae: 15.8874\n",
            "Epoch 171/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 11.2220 - mae: 11.2220\n",
            "Epoch 172/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 19.4588 - mae: 19.4588\n",
            "Epoch 173/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 30.6182 - mae: 30.6182\n",
            "Epoch 174/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 18.1402 - mae: 18.1402\n",
            "Epoch 175/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 30.2796 - mae: 30.2796\n",
            "Epoch 176/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 27.2362 - mae: 27.2362\n",
            "Epoch 177/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 27.9233 - mae: 27.9233\n",
            "Epoch 178/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 29.6414 - mae: 29.6414\n",
            "Epoch 179/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 31.4183 - mae: 31.4183\n",
            "Epoch 180/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 40.9469 - mae: 40.9469\n",
            "Epoch 181/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 14.5202 - mae: 14.5202\n",
            "Epoch 182/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 16.7867 - mae: 16.7867\n",
            "Epoch 183/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 11.0800 - mae: 11.0800\n",
            "Epoch 184/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 11.1488 - mae: 11.1488\n",
            "Epoch 185/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 28.5491 - mae: 28.5491\n",
            "Epoch 186/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 45.6780 - mae: 45.6780\n",
            "Epoch 187/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 29.3403 - mae: 29.3403\n",
            "Epoch 188/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 25.4349 - mae: 25.4349\n",
            "Epoch 189/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 25.3779 - mae: 25.3779\n",
            "Epoch 190/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 19.9922 - mae: 19.9922\n",
            "Epoch 191/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 31.5250 - mae: 31.5250\n",
            "Epoch 192/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.9406 - mae: 10.9406\n",
            "Epoch 193/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 15.5648 - mae: 15.5648\n",
            "Epoch 194/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 14.7386 - mae: 14.7386\n",
            "Epoch 195/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 13.9401 - mae: 13.9401\n",
            "Epoch 196/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 17.6205 - mae: 17.6205\n",
            "Epoch 197/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 33.3200 - mae: 33.3200\n",
            "Epoch 198/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 51.5425 - mae: 51.5425\n",
            "Epoch 199/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 29.0055 - mae: 29.0055\n",
            "Epoch 200/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 50.6299 - mae: 50.6299\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f87487e2bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_model_1.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_5mv-aOV-c4",
        "outputId": "32dedfd0-c965-4464-d994-0bf301594325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 6ms/step - loss: 40.2396 - mae: 40.2396\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[40.23963928222656, 40.23963928222656]"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3"
      ],
      "metadata": {
        "id": "BtwJiOcDV4W8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N4jbIvgV8rH",
        "outputId": "6bfc66f5-4ce0-4387-f54d-b505dd3b78dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 10)                20        \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the dependencies and dataset\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Rv36xRepXfXh",
        "outputId": "71a163e1-0230-4e99-87ca-865bd832c456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a468375-236f-408e-889c-788bbdfa2ed8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a468375-236f-408e-889c-788bbdfa2ed8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8a468375-236f-408e-889c-788bbdfa2ed8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8a468375-236f-408e-889c-788bbdfa2ed8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_insurance = pd.get_dummies(insurance)\n",
        "one_hot_insurance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "oBSz2lfYjuNf",
        "outputId": "186bc359-e7a5-40ab-c956-d2cc9de090bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
              "0      19  27.900         0  16884.92400           1         0          0   \n",
              "1      18  33.770         1   1725.55230           0         1          1   \n",
              "2      28  33.000         3   4449.46200           0         1          1   \n",
              "3      33  22.705         0  21984.47061           0         1          1   \n",
              "4      32  28.880         0   3866.85520           0         1          1   \n",
              "...   ...     ...       ...          ...         ...       ...        ...   \n",
              "1333   50  30.970         3  10600.54830           0         1          1   \n",
              "1334   18  31.920         0   2205.98080           1         0          1   \n",
              "1335   18  36.850         0   1629.83350           1         0          1   \n",
              "1336   21  25.800         0   2007.94500           1         0          1   \n",
              "1337   61  29.070         0  29141.36030           1         0          0   \n",
              "\n",
              "      smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
              "0              1                 0                 0                 0   \n",
              "1              0                 0                 0                 1   \n",
              "2              0                 0                 0                 1   \n",
              "3              0                 0                 1                 0   \n",
              "4              0                 0                 1                 0   \n",
              "...          ...               ...               ...               ...   \n",
              "1333           0                 0                 1                 0   \n",
              "1334           0                 1                 0                 0   \n",
              "1335           0                 0                 0                 1   \n",
              "1336           0                 0                 0                 0   \n",
              "1337           1                 0                 1                 0   \n",
              "\n",
              "      region_southwest  \n",
              "0                    1  \n",
              "1                    0  \n",
              "2                    0  \n",
              "3                    0  \n",
              "4                    0  \n",
              "...                ...  \n",
              "1333                 0  \n",
              "1334                 0  \n",
              "1335                 0  \n",
              "1336                 1  \n",
              "1337                 0  \n",
              "\n",
              "[1338 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aed9bad5-faaa-4f94-8eb7-99f64c56557d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>10600.54830</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>2205.98080</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>1629.83350</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>2007.94500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>29141.36030</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aed9bad5-faaa-4f94-8eb7-99f64c56557d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aed9bad5-faaa-4f94-8eb7-99f64c56557d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aed9bad5-faaa-4f94-8eb7-99f64c56557d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = one_hot_insurance.drop(\"charges\", axis = 1)\n",
        "y = one_hot_insurance[\"charges\"]"
      ],
      "metadata": {
        "id": "f-ULlugmhRK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YozvOBIFhWj4",
        "outputId": "8c96b454-2057-4dd2-b52f-626d7a9f7266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1070, 268, 1070, 268)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "ex_model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1000),\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "ex_model_2.compile(loss= tf.keras.losses.mae,\n",
        "                   optimizer = tf.keras.optimizers.Adam(),\n",
        "                   metrics = [\"mae\"])"
      ],
      "metadata": {
        "id": "JX8Z3h4Ih4O-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex_model_2.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utAH8TJtim5O",
        "outputId": "3636e5ac-f040-4d45-f0aa-abde67586b2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 2s 10ms/step - loss: 13177.9238 - mae: 13177.9238\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 12290.2559 - mae: 12290.2559\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 12044.1338 - mae: 12044.1338\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 11819.1436 - mae: 11819.1436\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 11161.1387 - mae: 11161.1387\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 9567.2100 - mae: 9567.2100\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8473.5127 - mae: 8473.5127\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8417.7559 - mae: 8417.7559\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8399.5107 - mae: 8399.5107\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8411.2705 - mae: 8411.2705\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8408.4600 - mae: 8408.4600\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8406.6318 - mae: 8406.6318\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8442.9707 - mae: 8442.9707\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8420.2354 - mae: 8420.2354\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8396.4678 - mae: 8396.4678\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 8395.3916 - mae: 8395.3916\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8399.0166 - mae: 8399.0166\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8400.4707 - mae: 8400.4707\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8405.2891 - mae: 8405.2891\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8403.4326 - mae: 8403.4326\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 8403.0410 - mae: 8403.0410\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8395.0557 - mae: 8395.0557\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8403.4072 - mae: 8403.4072\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8398.1328 - mae: 8398.1328\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8394.0977 - mae: 8394.0977\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8394.2188 - mae: 8394.2188\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8395.0342 - mae: 8395.0342\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8418.2236 - mae: 8418.2236\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 8417.7666 - mae: 8417.7666\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8397.4180 - mae: 8397.4180\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8413.2656 - mae: 8413.2656\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8393.3691 - mae: 8393.3691\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 8401.8213 - mae: 8401.8213\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 8395.1406 - mae: 8395.1406\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 8396.3760 - mae: 8396.3760\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 8404.9189 - mae: 8404.9189\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 8405.2217 - mae: 8405.2217\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 15ms/step - loss: 8407.6475 - mae: 8407.6475\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 8395.3672 - mae: 8395.3672\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 8394.8135 - mae: 8394.8135\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 8398.4756 - mae: 8398.4756\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8399.2520 - mae: 8399.2520\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8402.2500 - mae: 8402.2500\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8409.2480 - mae: 8409.2480\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8423.4033 - mae: 8423.4033\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8398.0625 - mae: 8398.0625\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8401.7598 - mae: 8401.7598\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8400.8555 - mae: 8400.8555\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8398.4102 - mae: 8398.4102\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8407.8945 - mae: 8407.8945\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8407.6768 - mae: 8407.6768\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8403.4395 - mae: 8403.4395\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8400.2598 - mae: 8400.2598\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8416.8223 - mae: 8416.8223\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8428.1406 - mae: 8428.1406\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8407.5449 - mae: 8407.5449\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8410.0391 - mae: 8410.0391\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8399.2529 - mae: 8399.2529\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8393.1982 - mae: 8393.1982\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8418.3369 - mae: 8418.3369\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8422.9736 - mae: 8422.9736\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8414.9932 - mae: 8414.9932\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8395.6934 - mae: 8395.6934\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8396.2803 - mae: 8396.2803\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8408.5479 - mae: 8408.5479\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8399.6631 - mae: 8399.6631\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8402.6289 - mae: 8402.6289\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8394.5664 - mae: 8394.5664\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8394.1445 - mae: 8394.1445\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8402.8525 - mae: 8402.8525\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 8397.6191 - mae: 8397.6191\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 8413.2061 - mae: 8413.2061\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 1s 28ms/step - loss: 8394.6064 - mae: 8394.6064\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 8399.1670 - mae: 8399.1670\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 8408.9463 - mae: 8408.9463\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 1s 14ms/step - loss: 8399.0586 - mae: 8399.0586\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 8401.2188 - mae: 8401.2188\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 8396.0850 - mae: 8396.0850\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 8397.4766 - mae: 8397.4766\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 8398.4570 - mae: 8398.4570\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 8405.5762 - mae: 8405.5762\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 8405.9258 - mae: 8405.9258\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 15ms/step - loss: 8398.6895 - mae: 8398.6895\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 8405.5195 - mae: 8405.5195\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 8423.2051 - mae: 8423.2051\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 8416.7588 - mae: 8416.7588\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 8414.7002 - mae: 8414.7002\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8395.3350 - mae: 8395.3350\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8407.6895 - mae: 8407.6895\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8399.7676 - mae: 8399.7676\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8404.2939 - mae: 8404.2939\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8422.8613 - mae: 8422.8613\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8406.9355 - mae: 8406.9355\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8404.9727 - mae: 8404.9727\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8399.7275 - mae: 8399.7275\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 8395.3145 - mae: 8395.3145\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8407.2441 - mae: 8407.2441\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8411.5186 - mae: 8411.5186\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8399.7646 - mae: 8399.7646\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8411.6338 - mae: 8411.6338\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8406.8389 - mae: 8406.8389\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8399.8711 - mae: 8399.8711\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8401.2393 - mae: 8401.2393\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8394.9473 - mae: 8394.9473\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8394.5303 - mae: 8394.5303\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8414.0566 - mae: 8414.0566\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8405.0498 - mae: 8405.0498\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8393.6846 - mae: 8393.6846\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8405.3086 - mae: 8405.3086\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 8404.6973 - mae: 8404.6973\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 8402.2852 - mae: 8402.2852\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 8393.8584 - mae: 8393.8584\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 8406.3506 - mae: 8406.3506\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 8404.5283 - mae: 8404.5283\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 1s 25ms/step - loss: 8392.9521 - mae: 8392.9521\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 8394.4697 - mae: 8394.4697\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 1s 24ms/step - loss: 8398.0615 - mae: 8398.0615\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 1s 26ms/step - loss: 8399.9746 - mae: 8399.9746\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 8399.6455 - mae: 8399.6455\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 8424.7031 - mae: 8424.7031\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 8392.6328 - mae: 8392.6328\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 8404.9150 - mae: 8404.9150\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 8400.3672 - mae: 8400.3672\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 8398.0781 - mae: 8398.0781\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 8404.5967 - mae: 8404.5967\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 8408.4893 - mae: 8408.4893\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 8402.7920 - mae: 8402.7920\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 8401.4463 - mae: 8401.4463\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 8406.7461 - mae: 8406.7461\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 8409.8008 - mae: 8409.8008\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 8399.5908 - mae: 8399.5908\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 8398.4248 - mae: 8398.4248\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 8394.4902 - mae: 8394.4902\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 8402.6992 - mae: 8402.6992\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 1s 28ms/step - loss: 8410.1328 - mae: 8410.1328\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 8398.3242 - mae: 8398.3242\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 1s 26ms/step - loss: 8403.7295 - mae: 8403.7295\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 1s 27ms/step - loss: 8399.8613 - mae: 8399.8613\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 1s 25ms/step - loss: 8401.7002 - mae: 8401.7002\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 8396.5469 - mae: 8396.5469\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 8405.5430 - mae: 8405.5430\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 8396.7344 - mae: 8396.7344\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 8395.8633 - mae: 8395.8633\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 8401.5586 - mae: 8401.5586\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 8397.6670 - mae: 8397.6670\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 8399.4023 - mae: 8399.4023\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 8405.3418 - mae: 8405.3418\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 8402.5518 - mae: 8402.5518\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 8405.1289 - mae: 8405.1289\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 8417.7090 - mae: 8417.7090\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 8402.8818 - mae: 8402.8818\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 8410.3584 - mae: 8410.3584\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 8415.6826 - mae: 8415.6826\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 8409.8008 - mae: 8409.8008\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 8423.7451 - mae: 8423.7451\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 8410.5547 - mae: 8410.5547\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 1s 25ms/step - loss: 8402.1934 - mae: 8402.1934\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 8397.9873 - mae: 8397.9873\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 1s 24ms/step - loss: 8406.9404 - mae: 8406.9404\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 8399.7041 - mae: 8399.7041\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 1s 25ms/step - loss: 8394.0322 - mae: 8394.0322\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 8394.3672 - mae: 8394.3672\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 8410.4092 - mae: 8410.4092\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 8401.8613 - mae: 8401.8613\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 8397.8516 - mae: 8397.8516\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 8398.8408 - mae: 8398.8408\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 8397.0977 - mae: 8397.0977\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 8404.9883 - mae: 8404.9883\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 8399.6328 - mae: 8399.6328\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 8402.9033 - mae: 8402.9033\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 8398.4775 - mae: 8398.4775\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 8391.9014 - mae: 8391.9014\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 8401.9131 - mae: 8401.9131\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 8407.0762 - mae: 8407.0762\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 8396.5850 - mae: 8396.5850\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 8411.0156 - mae: 8411.0156\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 8397.6543 - mae: 8397.6543\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 8406.3838 - mae: 8406.3838\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 1s 35ms/step - loss: 8396.8086 - mae: 8396.8086\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 1s 25ms/step - loss: 8401.2207 - mae: 8401.2207\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 1s 24ms/step - loss: 8422.0664 - mae: 8422.0664\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 1s 26ms/step - loss: 8405.9795 - mae: 8405.9795\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 8398.3184 - mae: 8398.3184\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 1s 27ms/step - loss: 8422.5439 - mae: 8422.5439\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 1s 24ms/step - loss: 8400.0049 - mae: 8400.0049\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 1s 24ms/step - loss: 8399.2910 - mae: 8399.2910\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 1s 25ms/step - loss: 8401.0615 - mae: 8401.0615\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 1s 24ms/step - loss: 8405.8916 - mae: 8405.8916\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 8414.3848 - mae: 8414.3848\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 8397.8535 - mae: 8397.8535\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 8408.9141 - mae: 8408.9141\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 8395.4238 - mae: 8395.4238\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 8398.2627 - mae: 8398.2627\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 8408.2705 - mae: 8408.2705\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 8413.8193 - mae: 8413.8193\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 8409.0654 - mae: 8409.0654\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 8418.5518 - mae: 8418.5518\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 8403.1289 - mae: 8403.1289\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 8407.9951 - mae: 8407.9951\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 1s 24ms/step - loss: 8402.5127 - mae: 8402.5127\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f87489456d0>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_model_2.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA77aOD1jC5t",
        "outputId": "5a535074-f151-4563-890b-182fc453a79a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 1s 8ms/step - loss: 8218.4541 - mae: 8218.4541\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8218.4541015625, 8218.4541015625]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "ex_model_3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(200),\n",
        "    tf.keras.layers.Dense(20),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "ex_model_3.compile(loss= tf.keras.losses.mae,\n",
        "                   optimizer = tf.keras.optimizers.Adam(),\n",
        "                   metrics = [\"mae\"])\n",
        "\n",
        "ex_model_3.fit(X_test, y_test, epochs = 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjmT1pYZkQhu",
        "outputId": "b70a2afc-28ff-47f4-b81d-fe16cd2efbde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "9/9 [==============================] - 2s 4ms/step - loss: 12930.5234 - mae: 12930.5234\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12869.9287 - mae: 12869.9287\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12797.5264 - mae: 12797.5264\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12703.9229 - mae: 12703.9229\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12580.2910 - mae: 12580.2910\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12416.3818 - mae: 12416.3818\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12202.1934 - mae: 12202.1934\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 11927.6260 - mae: 11927.6260\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 11581.3721 - mae: 11581.3721\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 11157.3027 - mae: 11157.3027\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10649.5840 - mae: 10649.5840\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10079.1602 - mae: 10079.1602\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9448.0518 - mae: 9448.0518\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8813.6660 - mae: 8813.6660\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8283.4502 - mae: 8283.4502\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 7833.4692 - mae: 7833.4692\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7568.0928 - mae: 7568.0928\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 7426.9194 - mae: 7426.9194\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 7377.7305 - mae: 7377.7305\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7354.9106 - mae: 7354.9106\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7346.5552 - mae: 7346.5552\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7334.1992 - mae: 7334.1992\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7323.1201 - mae: 7323.1201\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7313.0010 - mae: 7313.0010\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7304.3027 - mae: 7304.3027\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7293.2847 - mae: 7293.2847\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7280.9199 - mae: 7280.9199\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7270.5771 - mae: 7270.5771\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7259.3994 - mae: 7259.3994\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7250.7446 - mae: 7250.7446\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7237.1196 - mae: 7237.1196\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7233.9478 - mae: 7233.9478\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7215.7124 - mae: 7215.7124\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7206.1523 - mae: 7206.1523\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7192.3506 - mae: 7192.3506\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7182.6655 - mae: 7182.6655\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7167.2856 - mae: 7167.2856\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7155.3667 - mae: 7155.3667\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7145.8740 - mae: 7145.8740\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7130.1821 - mae: 7130.1821\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7119.1045 - mae: 7119.1045\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7105.4429 - mae: 7105.4429\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7091.9600 - mae: 7091.9600\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7080.0073 - mae: 7080.0073\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7067.7402 - mae: 7067.7402\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7056.4712 - mae: 7056.4712\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7039.4536 - mae: 7039.4536\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7025.7227 - mae: 7025.7227\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7017.8936 - mae: 7017.8936\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6997.2104 - mae: 6997.2104\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6985.5459 - mae: 6985.5459\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6969.2456 - mae: 6969.2456\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6954.8237 - mae: 6954.8237\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6939.4780 - mae: 6939.4780\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6923.0957 - mae: 6923.0957\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6906.0923 - mae: 6906.0923\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6890.7603 - mae: 6890.7603\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6873.7969 - mae: 6873.7969\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6856.4072 - mae: 6856.4072\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6839.1431 - mae: 6839.1431\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6823.2207 - mae: 6823.2207\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6806.2808 - mae: 6806.2808\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6790.2041 - mae: 6790.2041\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6772.2852 - mae: 6772.2852\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6758.8608 - mae: 6758.8608\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6732.4707 - mae: 6732.4707\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6718.3926 - mae: 6718.3926\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6702.1172 - mae: 6702.1172\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6680.9390 - mae: 6680.9390\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6660.5884 - mae: 6660.5884\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6642.2734 - mae: 6642.2734\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6622.1128 - mae: 6622.1128\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6603.8667 - mae: 6603.8667\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6582.2998 - mae: 6582.2998\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6563.3789 - mae: 6563.3789\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6541.9888 - mae: 6541.9888\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6522.7969 - mae: 6522.7969\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6501.7622 - mae: 6501.7622\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6481.7168 - mae: 6481.7168\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6465.4375 - mae: 6465.4375\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6451.9634 - mae: 6451.9634\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6437.3218 - mae: 6437.3218\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6423.0645 - mae: 6423.0645\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6412.9663 - mae: 6412.9663\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6400.2720 - mae: 6400.2720\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6391.4585 - mae: 6391.4585\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6382.9165 - mae: 6382.9165\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6379.5659 - mae: 6379.5659\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6369.3496 - mae: 6369.3496\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6365.3335 - mae: 6365.3335\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6363.7163 - mae: 6363.7163\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6355.1851 - mae: 6355.1851\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6347.7583 - mae: 6347.7583\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6343.3350 - mae: 6343.3350\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6338.0713 - mae: 6338.0713\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6335.6836 - mae: 6335.6836\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6330.2686 - mae: 6330.2686\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6325.4404 - mae: 6325.4404\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6318.8633 - mae: 6318.8633\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6313.8447 - mae: 6313.8447\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6309.2227 - mae: 6309.2227\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6304.7485 - mae: 6304.7485\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6301.3896 - mae: 6301.3896\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6296.6201 - mae: 6296.6201\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6296.9888 - mae: 6296.9888\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6288.9849 - mae: 6288.9849\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6284.6738 - mae: 6284.6738\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6279.3286 - mae: 6279.3286\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6275.2734 - mae: 6275.2734\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6271.8784 - mae: 6271.8784\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6273.8232 - mae: 6273.8232\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6260.5571 - mae: 6260.5571\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6262.2168 - mae: 6262.2168\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6256.3936 - mae: 6256.3936\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6249.3408 - mae: 6249.3408\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6250.0137 - mae: 6250.0137\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6248.8862 - mae: 6248.8862\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6239.7700 - mae: 6239.7700\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6239.0674 - mae: 6239.0674\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6229.6123 - mae: 6229.6123\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6229.9604 - mae: 6229.9604\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6224.5576 - mae: 6224.5576\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6216.3940 - mae: 6216.3940\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 6211.5771 - mae: 6211.5771\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6210.4556 - mae: 6210.4556\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6203.7090 - mae: 6203.7090\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6201.0073 - mae: 6201.0073\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6215.1001 - mae: 6215.1001\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 6193.2563 - mae: 6193.2563\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6185.5874 - mae: 6185.5874\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6182.2554 - mae: 6182.2554\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 6179.3237 - mae: 6179.3237\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6170.1294 - mae: 6170.1294\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 6166.0894 - mae: 6166.0894\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 6163.6685 - mae: 6163.6685\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6157.4399 - mae: 6157.4399\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6154.7739 - mae: 6154.7739\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6148.7700 - mae: 6148.7700\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6143.5415 - mae: 6143.5415\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6138.1694 - mae: 6138.1694\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6132.2114 - mae: 6132.2114\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6129.8149 - mae: 6129.8149\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6123.0415 - mae: 6123.0415\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6116.2212 - mae: 6116.2212\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6112.4634 - mae: 6112.4634\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6106.0327 - mae: 6106.0327\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6102.2422 - mae: 6102.2422\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6098.4531 - mae: 6098.4531\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6095.7241 - mae: 6095.7241\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6087.0015 - mae: 6087.0015\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6090.7310 - mae: 6090.7310\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6071.3931 - mae: 6071.3931\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6072.6270 - mae: 6072.6270\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6063.7515 - mae: 6063.7515\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6058.9980 - mae: 6058.9980\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 6053.6758 - mae: 6053.6758\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6052.8306 - mae: 6052.8306\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6044.3364 - mae: 6044.3364\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6037.6465 - mae: 6037.6465\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6033.1758 - mae: 6033.1758\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 6024.3174 - mae: 6024.3174\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6017.6992 - mae: 6017.6992\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6012.8848 - mae: 6012.8848\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6004.6841 - mae: 6004.6841\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6001.1821 - mae: 6001.1821\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5991.7129 - mae: 5991.7129\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 5985.1489 - mae: 5985.1489\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 5980.0620 - mae: 5980.0620\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 5973.1226 - mae: 5973.1226\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5965.2856 - mae: 5965.2856\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5968.5249 - mae: 5968.5249\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5950.1768 - mae: 5950.1768\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5952.4688 - mae: 5952.4688\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 5940.9048 - mae: 5940.9048\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5935.3379 - mae: 5935.3379\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5922.5078 - mae: 5922.5078\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5915.4019 - mae: 5915.4019\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5905.6118 - mae: 5905.6118\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5902.9531 - mae: 5902.9531\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 5893.0957 - mae: 5893.0957\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5884.8701 - mae: 5884.8701\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5882.7559 - mae: 5882.7559\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5863.4131 - mae: 5863.4131\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5857.6025 - mae: 5857.6025\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5851.4458 - mae: 5851.4458\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5840.1582 - mae: 5840.1582\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5836.1196 - mae: 5836.1196\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5830.1099 - mae: 5830.1099\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5820.9336 - mae: 5820.9336\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5813.3613 - mae: 5813.3613\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5794.0347 - mae: 5794.0347\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5788.6309 - mae: 5788.6309\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5786.2715 - mae: 5786.2715\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5766.1084 - mae: 5766.1084\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5760.8086 - mae: 5760.8086\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5749.8687 - mae: 5749.8687\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5737.9326 - mae: 5737.9326\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5728.3594 - mae: 5728.3594\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5717.1362 - mae: 5717.1362\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5706.7896 - mae: 5706.7896\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f87485ac5b0>"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_model_3.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLaC5V6CknZP",
        "outputId": "f19c99e4-e24f-4768-d821-21669c2c6de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 5ms/step - loss: 5698.1250 - mae: 5698.1250\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5698.125, 5698.125]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "ex_model_4 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "ex_model_4.compile(loss= tf.keras.losses.mae,\n",
        "                   optimizer = tf.keras.optimizers.Adam(lr=0.01),\n",
        "                   metrics = [\"mae\"])\n",
        "\n",
        "ex_model_4.fit(X_test, y_test, epochs = 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl9Ba6EO7gzx",
        "outputId": "52255764-7ae3-43fd-9349-676daa598511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "9/9 [==============================] - 1s 5ms/step - loss: 12942.7783 - mae: 12942.7783\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12907.0264 - mae: 12907.0264\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 12869.3662 - mae: 12869.3662\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 12827.4814 - mae: 12827.4814\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12779.2090 - mae: 12779.2090\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12721.7637 - mae: 12721.7637\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12652.3838 - mae: 12652.3838\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12568.4287 - mae: 12568.4287\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12466.7383 - mae: 12466.7383\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12344.6846 - mae: 12344.6846\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12198.2080 - mae: 12198.2080\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12024.2646 - mae: 12024.2646\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 11817.5801 - mae: 11817.5801\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 11580.6777 - mae: 11580.6777\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 11307.7139 - mae: 11307.7139\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10997.4980 - mae: 10997.4980\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10652.8291 - mae: 10652.8291\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10279.5898 - mae: 10279.5898\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9901.2383 - mae: 9901.2383\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9489.2402 - mae: 9489.2402\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9092.3594 - mae: 9092.3594\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8696.7461 - mae: 8696.7461\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8359.1836 - mae: 8359.1836\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 8060.2734 - mae: 8060.2734\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7839.6885 - mae: 7839.6885\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7674.2935 - mae: 7674.2935\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7553.2573 - mae: 7553.2573\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7472.9834 - mae: 7472.9834\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7431.9185 - mae: 7431.9185\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7409.2119 - mae: 7409.2119\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7402.3018 - mae: 7402.3018\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7395.0664 - mae: 7395.0664\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7387.0889 - mae: 7387.0889\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7379.4321 - mae: 7379.4321\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7371.5410 - mae: 7371.5410\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7364.9102 - mae: 7364.9102\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7355.9106 - mae: 7355.9106\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7348.8022 - mae: 7348.8022\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7343.5063 - mae: 7343.5063\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7333.9165 - mae: 7333.9165\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7327.1733 - mae: 7327.1733\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7319.1016 - mae: 7319.1016\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7311.1758 - mae: 7311.1758\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7304.5767 - mae: 7304.5767\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7297.8789 - mae: 7297.8789\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7291.7358 - mae: 7291.7358\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7281.8262 - mae: 7281.8262\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7274.2588 - mae: 7274.2588\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7270.6187 - mae: 7270.6187\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7258.9385 - mae: 7258.9385\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7252.7246 - mae: 7252.7246\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7243.9873 - mae: 7243.9873\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7236.2734 - mae: 7236.2734\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7228.7944 - mae: 7228.7944\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7220.8599 - mae: 7220.8599\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7212.7344 - mae: 7212.7344\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7204.7012 - mae: 7204.7012\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7196.1440 - mae: 7196.1440\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7187.5781 - mae: 7187.5781\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7179.7437 - mae: 7179.7437\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7171.6636 - mae: 7171.6636\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7163.1650 - mae: 7163.1650\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7155.9961 - mae: 7155.9961\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7148.2798 - mae: 7148.2798\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7140.0596 - mae: 7140.0596\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7129.0161 - mae: 7129.0161\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7121.6689 - mae: 7121.6689\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7113.5415 - mae: 7113.5415\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7104.4429 - mae: 7104.4429\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7094.9634 - mae: 7094.9634\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7085.9639 - mae: 7085.9639\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7076.9355 - mae: 7076.9355\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7069.3872 - mae: 7069.3872\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7058.7290 - mae: 7058.7290\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7050.3384 - mae: 7050.3384\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7040.3906 - mae: 7040.3906\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 7030.4517 - mae: 7030.4517\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 7022.5269 - mae: 7022.5269\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7012.1826 - mae: 7012.1826\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7002.3809 - mae: 7002.3809\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 6991.7383 - mae: 6991.7383\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 6983.3184 - mae: 6983.3184\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 6972.6133 - mae: 6972.6133\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 6962.8203 - mae: 6962.8203\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6953.3257 - mae: 6953.3257\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6940.9531 - mae: 6940.9531\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 6929.7930 - mae: 6929.7930\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 6919.8252 - mae: 6919.8252\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 6908.2988 - mae: 6908.2988\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6897.0503 - mae: 6897.0503\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6886.3638 - mae: 6886.3638\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6874.8110 - mae: 6874.8110\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6863.3174 - mae: 6863.3174\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6852.7915 - mae: 6852.7915\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6839.9575 - mae: 6839.9575\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6830.1821 - mae: 6830.1821\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6816.5610 - mae: 6816.5610\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6805.9927 - mae: 6805.9927\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6793.5610 - mae: 6793.5610\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6781.4595 - mae: 6781.4595\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6769.1758 - mae: 6769.1758\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6756.0830 - mae: 6756.0830\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6745.8076 - mae: 6745.8076\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6733.0381 - mae: 6733.0381\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6720.7231 - mae: 6720.7231\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6707.2925 - mae: 6707.2925\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6695.7827 - mae: 6695.7827\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6682.2495 - mae: 6682.2495\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6671.4688 - mae: 6671.4688\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6658.3003 - mae: 6658.3003\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6645.1475 - mae: 6645.1475\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6631.4609 - mae: 6631.4609\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6619.8486 - mae: 6619.8486\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6605.3569 - mae: 6605.3569\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6592.9595 - mae: 6592.9595\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6582.6323 - mae: 6582.6323\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6569.0908 - mae: 6569.0908\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6553.5415 - mae: 6553.5415\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6537.5024 - mae: 6537.5024\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6522.6406 - mae: 6522.6406\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6507.7134 - mae: 6507.7134\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6497.3887 - mae: 6497.3887\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6484.1514 - mae: 6484.1514\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6473.0889 - mae: 6473.0889\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 6466.6592 - mae: 6466.6592\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6451.5415 - mae: 6451.5415\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6445.4873 - mae: 6445.4873\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6439.5054 - mae: 6439.5054\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6425.0366 - mae: 6425.0366\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6416.9326 - mae: 6416.9326\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6409.4561 - mae: 6409.4561\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6410.1411 - mae: 6410.1411\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6393.6099 - mae: 6393.6099\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6388.7114 - mae: 6388.7114\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6382.7480 - mae: 6382.7480\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6377.2310 - mae: 6377.2310\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6374.2959 - mae: 6374.2959\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6369.6665 - mae: 6369.6665\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6363.5142 - mae: 6363.5142\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6360.6704 - mae: 6360.6704\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6356.7334 - mae: 6356.7334\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6355.7686 - mae: 6355.7686\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6350.1367 - mae: 6350.1367\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6346.6963 - mae: 6346.6963\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6344.0386 - mae: 6344.0386\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6339.3081 - mae: 6339.3081\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6337.3408 - mae: 6337.3408\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6341.0664 - mae: 6341.0664\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6331.1426 - mae: 6331.1426\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6327.9741 - mae: 6327.9741\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6325.5371 - mae: 6325.5371\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6321.7285 - mae: 6321.7285\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6317.1309 - mae: 6317.1309\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6313.2461 - mae: 6313.2461\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6311.3833 - mae: 6311.3833\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6308.4146 - mae: 6308.4146\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6308.7104 - mae: 6308.7104\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6304.3652 - mae: 6304.3652\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6298.8506 - mae: 6298.8506\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6297.7017 - mae: 6297.7017\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6293.4595 - mae: 6293.4595\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6291.1484 - mae: 6291.1484\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6288.0049 - mae: 6288.0049\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6285.5327 - mae: 6285.5327\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6281.8804 - mae: 6281.8804\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6280.1851 - mae: 6280.1851\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6276.6978 - mae: 6276.6978\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6274.4482 - mae: 6274.4482\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6271.6968 - mae: 6271.6968\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6268.4741 - mae: 6268.4741\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6269.4282 - mae: 6269.4282\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6263.6948 - mae: 6263.6948\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6261.9429 - mae: 6261.9429\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6258.1807 - mae: 6258.1807\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6255.7300 - mae: 6255.7300\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6252.2983 - mae: 6252.2983\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6248.5952 - mae: 6248.5952\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6245.8774 - mae: 6245.8774\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6244.9824 - mae: 6244.9824\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6240.7422 - mae: 6240.7422\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6237.4800 - mae: 6237.4800\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6237.6753 - mae: 6237.6753\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6231.5649 - mae: 6231.5649\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6230.1050 - mae: 6230.1050\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6227.7783 - mae: 6227.7783\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6226.0898 - mae: 6226.0898\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6223.3555 - mae: 6223.3555\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6219.8291 - mae: 6219.8291\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6217.8560 - mae: 6217.8560\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6212.7759 - mae: 6212.7759\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6213.5879 - mae: 6213.5879\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6206.0225 - mae: 6206.0225\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6209.2446 - mae: 6209.2446\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6200.9570 - mae: 6200.9570\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6198.5752 - mae: 6198.5752\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6194.6304 - mae: 6194.6304\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6193.0479 - mae: 6193.0479\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6189.4526 - mae: 6189.4526\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6187.5264 - mae: 6187.5264\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6186.0464 - mae: 6186.0464\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f87483f4b50>"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_model_4.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrJNhMyN8HBS",
        "outputId": "ea0e66a0-02a3-476d-d041-6886a0c6268d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 4ms/step - loss: 6180.6187 - mae: 6180.6187\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6180.61865234375, 6180.61865234375]"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 4 "
      ],
      "metadata": {
        "id": "d-ihNNNT8juj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "ex_model_5 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "ex_model_5.compile(loss= tf.keras.losses.mae,\n",
        "                   optimizer = tf.keras.optimizers.Adam(),\n",
        "                   metrics = [\"mae\"])\n",
        "\n",
        "ex_model_5.fit(X_test, y_test, epochs = 300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hquifvWG8LE9",
        "outputId": "06e70c3c-7da7-4b94-9725-bfb2756bd508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 7ms/step - loss: 12938.6963 - mae: 12938.6963\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12901.9492 - mae: 12901.9492\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12861.9141 - mae: 12861.9141\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12815.6338 - mae: 12815.6338\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12760.7607 - mae: 12760.7607\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12694.5850 - mae: 12694.5850\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12614.6162 - mae: 12614.6162\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12518.3828 - mae: 12518.3828\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12402.8193 - mae: 12402.8193\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12265.4902 - mae: 12265.4902\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12102.4531 - mae: 12102.4531\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 11911.0654 - mae: 11911.0654\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 11686.2803 - mae: 11686.2803\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 11432.2881 - mae: 11432.2881\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 11142.8818 - mae: 11142.8818\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10816.2275 - mae: 10816.2275\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10461.8643 - mae: 10461.8643\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10086.6309 - mae: 10086.6309\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9702.9766 - mae: 9702.9766\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9295.7783 - mae: 9295.7783\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8906.6621 - mae: 8906.6621\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8536.9980 - mae: 8536.9980\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8227.4004 - mae: 8227.4004\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7953.5933 - mae: 7953.5933\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7757.7573 - mae: 7757.7573\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7615.3716 - mae: 7615.3716\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7510.5835 - mae: 7510.5835\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7443.1348 - mae: 7443.1348\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7410.2764 - mae: 7410.2764\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7392.2144 - mae: 7392.2144\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7386.6167 - mae: 7386.6167\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7379.9331 - mae: 7379.9331\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 7372.2705 - mae: 7372.2705\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7365.9082 - mae: 7365.9082\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 7358.2656 - mae: 7358.2656\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 7352.7695 - mae: 7352.7695\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7344.1948 - mae: 7344.1948\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 7337.5894 - mae: 7337.5894\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 7331.9766 - mae: 7331.9766\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 7323.4824 - mae: 7323.4824\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 7317.2324 - mae: 7317.2324\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7309.6797 - mae: 7309.6797\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7302.3096 - mae: 7302.3096\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 7296.2026 - mae: 7296.2026\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7290.0474 - mae: 7290.0474\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 7284.3965 - mae: 7284.3965\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7275.0967 - mae: 7275.0967\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 7268.0889 - mae: 7268.0889\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 7266.0068 - mae: 7266.0068\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7254.1582 - mae: 7254.1582\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7247.8267 - mae: 7247.8267\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7240.0923 - mae: 7240.0923\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7232.8887 - mae: 7232.8887\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7226.0181 - mae: 7226.0181\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7218.9390 - mae: 7218.9390\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7211.5264 - mae: 7211.5264\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 7203.8882 - mae: 7203.8882\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7196.0532 - mae: 7196.0532\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 7188.1924 - mae: 7188.1924\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 7181.0151 - mae: 7181.0151\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 7173.7363 - mae: 7173.7363\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 7165.9561 - mae: 7165.9561\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 7159.4116 - mae: 7159.4116\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 7152.6357 - mae: 7152.6357\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 7145.0000 - mae: 7145.0000\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 7134.9360 - mae: 7134.9360\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7128.3096 - mae: 7128.3096\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7120.6045 - mae: 7120.6045\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7112.7290 - mae: 7112.7290\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7104.0728 - mae: 7104.0728\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7095.9785 - mae: 7095.9785\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7087.7573 - mae: 7087.7573\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7080.9014 - mae: 7080.9014\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7071.4399 - mae: 7071.4399\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7063.9482 - mae: 7063.9482\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7055.1050 - mae: 7055.1050\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 7046.0156 - mae: 7046.0156\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 7039.0645 - mae: 7039.0645\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 7029.5718 - mae: 7029.5718\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 7020.7969 - mae: 7020.7969\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 7011.2822 - mae: 7011.2822\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7003.6846 - mae: 7003.6846\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 6994.0962 - mae: 6994.0962\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6985.4458 - mae: 6985.4458\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 6976.6978 - mae: 6976.6978\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6966.1929 - mae: 6966.1929\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6956.3701 - mae: 6956.3701\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 6947.2778 - mae: 6947.2778\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6937.2554 - mae: 6937.2554\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 6927.2896 - mae: 6927.2896\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 6917.7515 - mae: 6917.7515\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6907.5527 - mae: 6907.5527\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6896.8345 - mae: 6896.8345\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6887.4883 - mae: 6887.4883\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6875.6953 - mae: 6875.6953\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6867.1572 - mae: 6867.1572\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6854.5791 - mae: 6854.5791\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6845.2759 - mae: 6845.2759\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6834.7646 - mae: 6834.7646\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6823.5640 - mae: 6823.5640\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6812.7280 - mae: 6812.7280\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6800.5640 - mae: 6800.5640\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6791.7554 - mae: 6791.7554\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6779.9297 - mae: 6779.9297\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6767.7529 - mae: 6767.7529\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6756.1523 - mae: 6756.1523\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6745.1294 - mae: 6745.1294\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6732.1870 - mae: 6732.1870\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6721.7646 - mae: 6721.7646\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 6709.8218 - mae: 6709.8218\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6699.3413 - mae: 6699.3413\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6687.7041 - mae: 6687.7041\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6677.1455 - mae: 6677.1455\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6662.8760 - mae: 6662.8760\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6650.5576 - mae: 6650.5576\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6644.1465 - mae: 6644.1465\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6631.1372 - mae: 6631.1372\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6617.0933 - mae: 6617.0933\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6602.9009 - mae: 6602.9009\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6589.2144 - mae: 6589.2144\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 6575.5625 - mae: 6575.5625\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6563.8965 - mae: 6563.8965\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6552.0840 - mae: 6552.0840\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6538.5947 - mae: 6538.5947\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6529.9683 - mae: 6529.9683\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6511.2476 - mae: 6511.2476\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6499.9404 - mae: 6499.9404\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6492.1641 - mae: 6492.1641\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6476.1055 - mae: 6476.1055\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6466.1055 - mae: 6466.1055\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6455.7788 - mae: 6455.7788\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6453.1982 - mae: 6453.1982\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6435.2793 - mae: 6435.2793\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6427.2446 - mae: 6427.2446\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6422.4009 - mae: 6422.4009\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6410.6294 - mae: 6410.6294\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6403.9683 - mae: 6403.9683\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6396.6602 - mae: 6396.6602\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6389.5469 - mae: 6389.5469\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6381.8062 - mae: 6381.8062\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6376.2578 - mae: 6376.2578\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6372.7935 - mae: 6372.7935\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6366.8677 - mae: 6366.8677\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6362.1841 - mae: 6362.1841\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6359.6821 - mae: 6359.6821\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6354.8809 - mae: 6354.8809\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6352.6699 - mae: 6352.6699\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6357.0874 - mae: 6357.0874\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6346.6665 - mae: 6346.6665\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6343.3857 - mae: 6343.3857\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6340.5854 - mae: 6340.5854\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6337.3594 - mae: 6337.3594\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6332.5181 - mae: 6332.5181\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6328.0947 - mae: 6328.0947\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6326.9380 - mae: 6326.9380\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6323.9062 - mae: 6323.9062\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6320.5215 - mae: 6320.5210\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6322.1460 - mae: 6322.1460\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6312.9150 - mae: 6312.9150\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6312.0991 - mae: 6312.0991\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6308.0972 - mae: 6308.0972\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6305.1880 - mae: 6305.1880\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6302.0771 - mae: 6302.0771\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6299.2510 - mae: 6299.2510\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6295.8779 - mae: 6295.8779\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6294.0337 - mae: 6294.0337\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6290.7515 - mae: 6290.7515\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6288.5288 - mae: 6288.5288\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6285.2915 - mae: 6285.2915\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6282.8726 - mae: 6282.8726\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6282.5752 - mae: 6282.5752\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6277.9775 - mae: 6277.9775\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6275.9067 - mae: 6275.9067\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6272.5625 - mae: 6272.5625\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6269.2017 - mae: 6269.2017\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6266.4814 - mae: 6266.4814\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6262.9038 - mae: 6262.9038\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6260.6929 - mae: 6260.6929\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6258.6821 - mae: 6258.6821\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6255.0386 - mae: 6255.0386\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6252.3882 - mae: 6252.3882\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6251.5444 - mae: 6251.5444\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6246.6377 - mae: 6246.6377\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6244.9229 - mae: 6244.9229\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6242.3091 - mae: 6242.3091\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6240.3696 - mae: 6240.3696\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6238.3594 - mae: 6238.3594\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6235.2778 - mae: 6235.2778\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6232.0645 - mae: 6232.0645\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6228.5635 - mae: 6228.5635\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6227.5205 - mae: 6227.5205\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6221.8994 - mae: 6221.8994\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6224.4771 - mae: 6224.4771\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6217.1929 - mae: 6217.1929\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6216.1479 - mae: 6216.1479\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6210.8491 - mae: 6210.8491\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6209.8384 - mae: 6209.8384\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 6206.7271 - mae: 6206.7271\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6204.2896 - mae: 6204.2896\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6202.7114 - mae: 6202.7114\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6198.3423 - mae: 6198.3423\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6194.3340 - mae: 6194.3340\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6192.0366 - mae: 6192.0366\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6188.6655 - mae: 6188.6655\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6186.4727 - mae: 6186.4727\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6188.3530 - mae: 6188.3530\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6181.8345 - mae: 6181.8345\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6178.1719 - mae: 6178.1719\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6179.1089 - mae: 6179.1089\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6172.2324 - mae: 6172.2324\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6168.9219 - mae: 6168.9219\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6168.9146 - mae: 6168.9146\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6164.7339 - mae: 6164.7339\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6160.5664 - mae: 6160.5664\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6156.5566 - mae: 6156.5566\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6153.6445 - mae: 6153.6445\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6150.9663 - mae: 6150.9663\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6148.7856 - mae: 6148.7856\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6145.6499 - mae: 6145.6499\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6143.1265 - mae: 6143.1265\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6140.5801 - mae: 6140.5801\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6137.5962 - mae: 6137.5962\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6135.4038 - mae: 6135.4038\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6130.2148 - mae: 6130.2148\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6127.7705 - mae: 6127.7705\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6126.2954 - mae: 6126.2954\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6121.0381 - mae: 6121.0381\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6117.5757 - mae: 6117.5757\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6114.5366 - mae: 6114.5366\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6112.1880 - mae: 6112.1880\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6109.5000 - mae: 6109.5000\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6104.1084 - mae: 6104.1084\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6106.5410 - mae: 6106.5410\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6098.1958 - mae: 6098.1958\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6097.0098 - mae: 6097.0098\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6093.6060 - mae: 6093.6060\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6094.3452 - mae: 6094.3452\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6090.3750 - mae: 6090.3750\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6084.6333 - mae: 6084.6333\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6078.8896 - mae: 6078.8896\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6075.7207 - mae: 6075.7207\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6073.9380 - mae: 6073.9380\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6071.1631 - mae: 6071.1631\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6066.9849 - mae: 6066.9849\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6063.0908 - mae: 6063.0908\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6059.3433 - mae: 6059.3433\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6058.3867 - mae: 6058.3867\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6050.1118 - mae: 6050.1118\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6048.7866 - mae: 6048.7866\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6044.4663 - mae: 6044.4663\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6041.2231 - mae: 6041.2231\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6038.0928 - mae: 6038.0928\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6034.5273 - mae: 6034.5273\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6030.1772 - mae: 6030.1772\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6027.2207 - mae: 6027.2207\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 6026.5137 - mae: 6026.5137\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6019.2246 - mae: 6019.2246\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6017.4937 - mae: 6017.4937\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6011.1665 - mae: 6011.1665\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6007.6743 - mae: 6007.6743\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6003.6279 - mae: 6003.6279\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5999.7427 - mae: 5999.7427\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5996.1587 - mae: 5996.1587\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5992.9619 - mae: 5992.9619\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5991.0347 - mae: 5991.0347\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5986.4580 - mae: 5986.4580\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5983.6045 - mae: 5983.6045\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5976.3193 - mae: 5976.3193\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5972.3530 - mae: 5972.3530\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5969.8198 - mae: 5969.8198\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5962.6875 - mae: 5962.6875\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5960.1582 - mae: 5960.1582\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5954.2065 - mae: 5954.2065\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 5949.8208 - mae: 5949.8208\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 5948.1636 - mae: 5948.1636\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5942.0186 - mae: 5942.0186\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5936.6406 - mae: 5936.6406\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5932.4038 - mae: 5932.4038\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5927.2725 - mae: 5927.2725\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5922.7568 - mae: 5922.7568\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 5917.4624 - mae: 5917.4624\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 5913.0869 - mae: 5913.0869\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5909.4243 - mae: 5909.4243\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 5905.1177 - mae: 5905.1177\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5898.1084 - mae: 5898.1084\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5894.2549 - mae: 5894.2549\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5888.6904 - mae: 5888.6904\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5883.1567 - mae: 5883.1567\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5880.8687 - mae: 5880.8687\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5873.7700 - mae: 5873.7700\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 5867.9839 - mae: 5867.9839\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5863.8232 - mae: 5863.8232\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5857.7925 - mae: 5857.7925\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5854.9355 - mae: 5854.9355\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5851.1855 - mae: 5851.1855\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5840.6338 - mae: 5840.6338\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5837.6753 - mae: 5837.6753\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5828.6123 - mae: 5828.6123\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5834.5332 - mae: 5834.5332\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5826.0137 - mae: 5826.0137\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8743bf3610>"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_model_5.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqaGiuKu8ZgF",
        "outputId": "e98c4247-9a98-47be-b147-1d0d7e7cbef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 9ms/step - loss: 5820.6641 - mae: 5820.6641\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5820.6640625, 5820.6640625]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 5"
      ],
      "metadata": {
        "id": "hYkXzM8r8cBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import boston_housing"
      ],
      "metadata": {
        "id": "T4lwQgBr90-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnj7XQjtThqq",
        "outputId": "98e29057-857b-4e05-dc77-772826e30330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57026/57026 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgvyUAmKT10g",
        "outputId": "4da46190-aafe-4302-a630-25abca5eccc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1070, 11), (1070,), (268, 11), (268,))"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train), len(y_train),len( X_test),len( y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LwYJv7ZT_EX",
        "outputId": "a0e8539d-60a5-42e4-8155-d58eb6743d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1070, 1070, 268, 268)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "ex_model_6 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "ex_model_6.compile(loss = tf.keras.losses.mae,\n",
        "                   optimizer = tf.keras.optimizers.Adam(lr = 0.01),\n",
        "                   metrics = [\"mae\"])\n",
        "\n",
        "ex_model_6.fit(X_train, y_train, epochs = 300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0ggCNBPUH3T",
        "outputId": "cec900df-8572-4ae7-b9b7-53d0e952e08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "34/34 [==============================] - 2s 4ms/step - loss: 13310.4082 - mae: 13310.4082\n",
            "Epoch 2/300\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 13170.0791 - mae: 13170.0791\n",
            "Epoch 3/300\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 12866.8076 - mae: 12866.8076\n",
            "Epoch 4/300\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 12247.8516 - mae: 12247.8516\n",
            "Epoch 5/300\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 11166.3467 - mae: 11166.3467\n",
            "Epoch 6/300\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 9731.4297 - mae: 9731.4297\n",
            "Epoch 7/300\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 8364.5283 - mae: 8364.5283\n",
            "Epoch 8/300\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7613.2300 - mae: 7613.2300\n",
            "Epoch 9/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7459.6138 - mae: 7459.6138\n",
            "Epoch 10/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7437.1177 - mae: 7437.1177\n",
            "Epoch 11/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7419.1592 - mae: 7419.1592\n",
            "Epoch 12/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7392.2681 - mae: 7392.2681\n",
            "Epoch 13/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7372.1050 - mae: 7372.1050\n",
            "Epoch 14/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7348.9282 - mae: 7348.9282\n",
            "Epoch 15/300\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7323.1538 - mae: 7323.1538\n",
            "Epoch 16/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7301.2695 - mae: 7301.2695\n",
            "Epoch 17/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7279.5386 - mae: 7279.5386\n",
            "Epoch 18/300\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7253.4614 - mae: 7253.4614\n",
            "Epoch 19/300\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7229.1006 - mae: 7229.1006\n",
            "Epoch 20/300\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7206.6919 - mae: 7206.6919\n",
            "Epoch 21/300\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7177.9932 - mae: 7177.9932\n",
            "Epoch 22/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7156.3101 - mae: 7156.3101\n",
            "Epoch 23/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7126.8740 - mae: 7126.8740\n",
            "Epoch 24/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7099.3140 - mae: 7099.3140\n",
            "Epoch 25/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7071.2744 - mae: 7071.2744\n",
            "Epoch 26/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7041.9751 - mae: 7041.9751\n",
            "Epoch 27/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7012.0879 - mae: 7012.0879\n",
            "Epoch 28/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6984.0444 - mae: 6984.0444\n",
            "Epoch 29/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6954.0786 - mae: 6954.0786\n",
            "Epoch 30/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6921.9565 - mae: 6921.9565\n",
            "Epoch 31/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6887.7686 - mae: 6887.7686\n",
            "Epoch 32/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6853.4771 - mae: 6853.4771\n",
            "Epoch 33/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6819.4839 - mae: 6819.4839\n",
            "Epoch 34/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6782.6602 - mae: 6782.6602\n",
            "Epoch 35/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6747.6089 - mae: 6747.6089\n",
            "Epoch 36/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6708.2666 - mae: 6708.2666\n",
            "Epoch 37/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6672.7969 - mae: 6672.7969\n",
            "Epoch 38/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6633.8218 - mae: 6633.8218\n",
            "Epoch 39/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6598.3638 - mae: 6598.3638\n",
            "Epoch 40/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6566.7935 - mae: 6566.7935\n",
            "Epoch 41/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6541.6030 - mae: 6541.6030\n",
            "Epoch 42/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6523.6602 - mae: 6523.6602\n",
            "Epoch 43/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6500.4316 - mae: 6500.4316\n",
            "Epoch 44/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6484.1328 - mae: 6484.1328\n",
            "Epoch 45/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6467.2646 - mae: 6467.2646\n",
            "Epoch 46/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6452.2598 - mae: 6452.2598\n",
            "Epoch 47/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6438.4727 - mae: 6438.4727\n",
            "Epoch 48/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6428.0259 - mae: 6428.0259\n",
            "Epoch 49/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6409.9326 - mae: 6409.9326\n",
            "Epoch 50/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6395.6636 - mae: 6395.6636\n",
            "Epoch 51/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6384.2837 - mae: 6384.2837\n",
            "Epoch 52/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6368.5493 - mae: 6368.5493\n",
            "Epoch 53/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6354.4937 - mae: 6354.4937\n",
            "Epoch 54/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6342.2207 - mae: 6342.2207\n",
            "Epoch 55/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6331.8555 - mae: 6331.8555\n",
            "Epoch 56/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6312.0488 - mae: 6312.0488\n",
            "Epoch 57/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6295.5156 - mae: 6295.5156\n",
            "Epoch 58/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6282.8633 - mae: 6282.8633\n",
            "Epoch 59/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6269.6030 - mae: 6269.6030\n",
            "Epoch 60/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6253.2520 - mae: 6253.2520\n",
            "Epoch 61/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6238.8477 - mae: 6238.8477\n",
            "Epoch 62/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6223.7222 - mae: 6223.7222\n",
            "Epoch 63/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6202.7026 - mae: 6202.7026\n",
            "Epoch 64/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6187.3486 - mae: 6187.3486\n",
            "Epoch 65/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6172.5474 - mae: 6172.5474\n",
            "Epoch 66/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6153.8672 - mae: 6153.8672\n",
            "Epoch 67/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6134.6968 - mae: 6134.6968\n",
            "Epoch 68/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6115.4727 - mae: 6115.4727\n",
            "Epoch 69/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6098.7207 - mae: 6098.7207\n",
            "Epoch 70/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6078.4058 - mae: 6078.4058\n",
            "Epoch 71/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6056.6450 - mae: 6056.6450\n",
            "Epoch 72/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6040.5942 - mae: 6040.5942\n",
            "Epoch 73/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6017.8750 - mae: 6017.8750\n",
            "Epoch 74/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5996.2090 - mae: 5996.2090\n",
            "Epoch 75/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5971.2090 - mae: 5971.2090\n",
            "Epoch 76/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5947.0815 - mae: 5947.0815\n",
            "Epoch 77/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5920.9189 - mae: 5920.9189\n",
            "Epoch 78/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5898.6309 - mae: 5898.6309\n",
            "Epoch 79/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5870.6812 - mae: 5870.6812\n",
            "Epoch 80/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5845.9170 - mae: 5845.9170\n",
            "Epoch 81/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5813.8921 - mae: 5813.8921\n",
            "Epoch 82/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5790.4624 - mae: 5790.4624\n",
            "Epoch 83/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5756.0723 - mae: 5756.0723\n",
            "Epoch 84/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5727.1763 - mae: 5727.1763\n",
            "Epoch 85/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5689.7168 - mae: 5689.7168\n",
            "Epoch 86/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5656.4946 - mae: 5656.4946\n",
            "Epoch 87/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5623.7822 - mae: 5623.7822\n",
            "Epoch 88/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5581.7861 - mae: 5581.7861\n",
            "Epoch 89/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5549.8652 - mae: 5549.8652\n",
            "Epoch 90/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5503.7988 - mae: 5503.7988\n",
            "Epoch 91/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5459.1050 - mae: 5459.1050\n",
            "Epoch 92/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5419.7358 - mae: 5419.7358\n",
            "Epoch 93/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5382.2402 - mae: 5382.2402\n",
            "Epoch 94/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5314.5713 - mae: 5314.5713\n",
            "Epoch 95/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5270.0435 - mae: 5270.0435\n",
            "Epoch 96/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5214.9346 - mae: 5214.9346\n",
            "Epoch 97/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5153.7495 - mae: 5153.7495\n",
            "Epoch 98/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5103.3853 - mae: 5103.3853\n",
            "Epoch 99/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5035.7935 - mae: 5035.7935\n",
            "Epoch 100/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4962.3823 - mae: 4962.3823\n",
            "Epoch 101/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4899.2778 - mae: 4899.2778\n",
            "Epoch 102/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4822.9116 - mae: 4822.9116\n",
            "Epoch 103/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4746.1680 - mae: 4746.1680\n",
            "Epoch 104/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4665.1841 - mae: 4665.1841\n",
            "Epoch 105/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4579.8423 - mae: 4579.8423\n",
            "Epoch 106/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4496.7241 - mae: 4496.7241\n",
            "Epoch 107/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4409.0142 - mae: 4409.0142\n",
            "Epoch 108/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4318.3018 - mae: 4318.3018\n",
            "Epoch 109/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4235.0859 - mae: 4235.0859\n",
            "Epoch 110/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4139.0942 - mae: 4139.0942\n",
            "Epoch 111/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4063.3743 - mae: 4063.3743\n",
            "Epoch 112/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3992.8835 - mae: 3992.8835\n",
            "Epoch 113/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3929.6646 - mae: 3929.6646\n",
            "Epoch 114/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3902.7593 - mae: 3902.7593\n",
            "Epoch 115/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3845.7661 - mae: 3845.7661\n",
            "Epoch 116/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3821.0857 - mae: 3821.0857\n",
            "Epoch 117/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3804.6287 - mae: 3804.6287\n",
            "Epoch 118/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3782.9089 - mae: 3782.9089\n",
            "Epoch 119/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3764.8943 - mae: 3764.8943\n",
            "Epoch 120/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3783.0466 - mae: 3783.0466\n",
            "Epoch 121/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3758.9814 - mae: 3758.9814\n",
            "Epoch 122/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3749.4580 - mae: 3749.4580\n",
            "Epoch 123/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3737.9680 - mae: 3737.9680\n",
            "Epoch 124/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3733.7290 - mae: 3733.7290\n",
            "Epoch 125/300\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3732.6765 - mae: 3732.6765\n",
            "Epoch 126/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3742.7712 - mae: 3742.7712\n",
            "Epoch 127/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3726.8274 - mae: 3726.8274\n",
            "Epoch 128/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3720.4553 - mae: 3720.4553\n",
            "Epoch 129/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3726.1562 - mae: 3726.1562\n",
            "Epoch 130/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3722.9521 - mae: 3722.9521\n",
            "Epoch 131/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3713.5869 - mae: 3713.5869\n",
            "Epoch 132/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3712.5916 - mae: 3712.5916\n",
            "Epoch 133/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3709.1567 - mae: 3709.1567\n",
            "Epoch 134/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3709.3318 - mae: 3709.3318\n",
            "Epoch 135/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3709.5757 - mae: 3709.5757\n",
            "Epoch 136/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3720.8564 - mae: 3720.8564\n",
            "Epoch 137/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3704.0200 - mae: 3704.0200\n",
            "Epoch 138/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3701.5066 - mae: 3701.5066\n",
            "Epoch 139/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3703.4810 - mae: 3703.4810\n",
            "Epoch 140/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3698.0920 - mae: 3698.0920\n",
            "Epoch 141/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3713.3010 - mae: 3713.3010\n",
            "Epoch 142/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3694.9583 - mae: 3694.9583\n",
            "Epoch 143/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3699.1331 - mae: 3699.1331\n",
            "Epoch 144/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3702.1736 - mae: 3702.1736\n",
            "Epoch 145/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3687.6570 - mae: 3687.6570\n",
            "Epoch 146/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3700.4202 - mae: 3700.4202\n",
            "Epoch 147/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3690.7805 - mae: 3690.7805\n",
            "Epoch 148/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3693.1292 - mae: 3693.1292\n",
            "Epoch 149/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3686.3176 - mae: 3686.3176\n",
            "Epoch 150/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3686.4128 - mae: 3686.4128\n",
            "Epoch 151/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3684.4084 - mae: 3684.4084\n",
            "Epoch 152/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3685.5227 - mae: 3685.5227\n",
            "Epoch 153/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3686.3743 - mae: 3686.3743\n",
            "Epoch 154/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3685.1736 - mae: 3685.1736\n",
            "Epoch 155/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3678.8071 - mae: 3678.8071\n",
            "Epoch 156/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3678.0845 - mae: 3678.0845\n",
            "Epoch 157/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3680.2563 - mae: 3680.2563\n",
            "Epoch 158/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3673.8442 - mae: 3673.8442\n",
            "Epoch 159/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3672.1724 - mae: 3672.1724\n",
            "Epoch 160/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3672.3196 - mae: 3672.3196\n",
            "Epoch 161/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3671.6602 - mae: 3671.6602\n",
            "Epoch 162/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3667.9097 - mae: 3667.9097\n",
            "Epoch 163/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3667.9287 - mae: 3667.9287\n",
            "Epoch 164/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3666.7791 - mae: 3666.7791\n",
            "Epoch 165/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3665.7456 - mae: 3665.7456\n",
            "Epoch 166/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3664.9175 - mae: 3664.9175\n",
            "Epoch 167/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3663.5046 - mae: 3663.5046\n",
            "Epoch 168/300\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3670.0925 - mae: 3670.0925\n",
            "Epoch 169/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3666.1006 - mae: 3666.1006\n",
            "Epoch 170/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3661.0938 - mae: 3661.0938\n",
            "Epoch 171/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3666.8489 - mae: 3666.8489\n",
            "Epoch 172/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3663.0715 - mae: 3663.0715\n",
            "Epoch 173/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3654.6296 - mae: 3654.6296\n",
            "Epoch 174/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3655.0645 - mae: 3655.0645\n",
            "Epoch 175/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3653.6357 - mae: 3653.6357\n",
            "Epoch 176/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3669.7554 - mae: 3669.7554\n",
            "Epoch 177/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3654.2441 - mae: 3654.2441\n",
            "Epoch 178/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3653.7275 - mae: 3653.7275\n",
            "Epoch 179/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3658.3574 - mae: 3658.3574\n",
            "Epoch 180/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3647.0242 - mae: 3647.0242\n",
            "Epoch 181/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3654.6179 - mae: 3654.6179\n",
            "Epoch 182/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3645.8943 - mae: 3645.8943\n",
            "Epoch 183/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3644.3289 - mae: 3644.3289\n",
            "Epoch 184/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3643.1418 - mae: 3643.1418\n",
            "Epoch 185/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3647.1604 - mae: 3647.1604\n",
            "Epoch 186/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3638.7639 - mae: 3638.7639\n",
            "Epoch 187/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3639.3977 - mae: 3639.3977\n",
            "Epoch 188/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3641.3816 - mae: 3641.3816\n",
            "Epoch 189/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3636.6643 - mae: 3636.6643\n",
            "Epoch 190/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3641.3428 - mae: 3641.3428\n",
            "Epoch 191/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3640.6631 - mae: 3640.6631\n",
            "Epoch 192/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3635.6206 - mae: 3635.6206\n",
            "Epoch 193/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3633.2800 - mae: 3633.2800\n",
            "Epoch 194/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3661.0623 - mae: 3661.0623\n",
            "Epoch 195/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3654.6829 - mae: 3654.6829\n",
            "Epoch 196/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3634.1082 - mae: 3634.1082\n",
            "Epoch 197/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3635.1169 - mae: 3635.1169\n",
            "Epoch 198/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3643.1428 - mae: 3643.1428\n",
            "Epoch 199/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3625.9160 - mae: 3625.9160\n",
            "Epoch 200/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3625.8140 - mae: 3625.8140\n",
            "Epoch 201/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3629.2668 - mae: 3629.2668\n",
            "Epoch 202/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3628.2229 - mae: 3628.2229\n",
            "Epoch 203/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3621.7151 - mae: 3621.7151\n",
            "Epoch 204/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3625.3613 - mae: 3625.3613\n",
            "Epoch 205/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3623.0417 - mae: 3623.0417\n",
            "Epoch 206/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3623.4919 - mae: 3623.4919\n",
            "Epoch 207/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3617.7554 - mae: 3617.7554\n",
            "Epoch 208/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3616.9634 - mae: 3616.9634\n",
            "Epoch 209/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3614.3945 - mae: 3614.3945\n",
            "Epoch 210/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3613.7427 - mae: 3613.7427\n",
            "Epoch 211/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3613.5557 - mae: 3613.5557\n",
            "Epoch 212/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3611.4741 - mae: 3611.4741\n",
            "Epoch 213/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3609.3594 - mae: 3609.3594\n",
            "Epoch 214/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3612.4622 - mae: 3612.4622\n",
            "Epoch 215/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3612.7771 - mae: 3612.7771\n",
            "Epoch 216/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3605.7637 - mae: 3605.7637\n",
            "Epoch 217/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3602.7415 - mae: 3602.7415\n",
            "Epoch 218/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3607.5977 - mae: 3607.5977\n",
            "Epoch 219/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3603.4089 - mae: 3603.4089\n",
            "Epoch 220/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3602.2715 - mae: 3602.2715\n",
            "Epoch 221/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3600.9495 - mae: 3600.9495\n",
            "Epoch 222/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3598.0581 - mae: 3598.0581\n",
            "Epoch 223/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3597.9973 - mae: 3597.9973\n",
            "Epoch 224/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3594.7378 - mae: 3594.7378\n",
            "Epoch 225/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3598.7949 - mae: 3598.7949\n",
            "Epoch 226/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3593.5693 - mae: 3593.5693\n",
            "Epoch 227/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3607.9265 - mae: 3607.9265\n",
            "Epoch 228/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3598.4802 - mae: 3598.4802\n",
            "Epoch 229/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3588.9888 - mae: 3588.9888\n",
            "Epoch 230/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3590.3474 - mae: 3590.3474\n",
            "Epoch 231/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3585.9609 - mae: 3585.9609\n",
            "Epoch 232/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3587.3838 - mae: 3587.3838\n",
            "Epoch 233/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3586.2603 - mae: 3586.2603\n",
            "Epoch 234/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3584.9980 - mae: 3584.9980\n",
            "Epoch 235/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3580.8506 - mae: 3580.8506\n",
            "Epoch 236/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3586.2830 - mae: 3586.2830\n",
            "Epoch 237/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3574.8535 - mae: 3574.8535\n",
            "Epoch 238/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3580.7039 - mae: 3580.7039\n",
            "Epoch 239/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3578.8157 - mae: 3578.8157\n",
            "Epoch 240/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3580.8384 - mae: 3580.8384\n",
            "Epoch 241/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3586.2107 - mae: 3586.2107\n",
            "Epoch 242/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3583.0833 - mae: 3583.0833\n",
            "Epoch 243/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3572.5085 - mae: 3572.5085\n",
            "Epoch 244/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3572.5886 - mae: 3572.5886\n",
            "Epoch 245/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3569.1047 - mae: 3569.1047\n",
            "Epoch 246/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3562.9844 - mae: 3562.9844\n",
            "Epoch 247/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3565.8535 - mae: 3565.8535\n",
            "Epoch 248/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3574.8696 - mae: 3574.8696\n",
            "Epoch 249/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3565.2549 - mae: 3565.2549\n",
            "Epoch 250/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3562.3833 - mae: 3562.3833\n",
            "Epoch 251/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3563.3083 - mae: 3563.3083\n",
            "Epoch 252/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3559.2463 - mae: 3559.2463\n",
            "Epoch 253/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3557.1892 - mae: 3557.1892\n",
            "Epoch 254/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3557.8745 - mae: 3557.8745\n",
            "Epoch 255/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3555.0210 - mae: 3555.0210\n",
            "Epoch 256/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3556.8770 - mae: 3556.8770\n",
            "Epoch 257/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3549.7732 - mae: 3549.7732\n",
            "Epoch 258/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3552.5535 - mae: 3552.5535\n",
            "Epoch 259/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3549.6702 - mae: 3549.6702\n",
            "Epoch 260/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3545.3079 - mae: 3545.3079\n",
            "Epoch 261/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3545.3618 - mae: 3545.3618\n",
            "Epoch 262/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3551.8069 - mae: 3551.8069\n",
            "Epoch 263/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3547.6821 - mae: 3547.6821\n",
            "Epoch 264/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3553.7400 - mae: 3553.7400\n",
            "Epoch 265/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3546.2539 - mae: 3546.2539\n",
            "Epoch 266/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3541.0315 - mae: 3541.0315\n",
            "Epoch 267/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3542.9263 - mae: 3542.9263\n",
            "Epoch 268/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3544.4968 - mae: 3544.4968\n",
            "Epoch 269/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3540.2297 - mae: 3540.2297\n",
            "Epoch 270/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3546.6001 - mae: 3546.6001\n",
            "Epoch 271/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3533.2039 - mae: 3533.2039\n",
            "Epoch 272/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3532.6516 - mae: 3532.6516\n",
            "Epoch 273/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3544.8887 - mae: 3544.8887\n",
            "Epoch 274/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3533.8015 - mae: 3533.8015\n",
            "Epoch 275/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3532.1274 - mae: 3532.1274\n",
            "Epoch 276/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3525.5747 - mae: 3525.5747\n",
            "Epoch 277/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3526.6763 - mae: 3526.6763\n",
            "Epoch 278/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3522.1558 - mae: 3522.1558\n",
            "Epoch 279/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3532.3669 - mae: 3532.3669\n",
            "Epoch 280/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3536.1611 - mae: 3536.1611\n",
            "Epoch 281/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3549.9187 - mae: 3549.9187\n",
            "Epoch 282/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3522.8120 - mae: 3522.8120\n",
            "Epoch 283/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3522.7078 - mae: 3522.7078\n",
            "Epoch 284/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3521.7148 - mae: 3521.7148\n",
            "Epoch 285/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3533.3274 - mae: 3533.3274\n",
            "Epoch 286/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3518.1006 - mae: 3518.1006\n",
            "Epoch 287/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3522.4573 - mae: 3522.4573\n",
            "Epoch 288/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3516.2463 - mae: 3516.2463\n",
            "Epoch 289/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3519.6406 - mae: 3519.6406\n",
            "Epoch 290/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3522.5071 - mae: 3522.5071\n",
            "Epoch 291/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3524.2161 - mae: 3524.2161\n",
            "Epoch 292/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3512.9861 - mae: 3512.9861\n",
            "Epoch 293/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3512.4541 - mae: 3512.4541\n",
            "Epoch 294/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3526.9238 - mae: 3526.9238\n",
            "Epoch 295/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3508.2991 - mae: 3508.2991\n",
            "Epoch 296/300\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3504.9458 - mae: 3504.9458\n",
            "Epoch 297/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3518.0847 - mae: 3518.0847\n",
            "Epoch 298/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3509.3894 - mae: 3509.3894\n",
            "Epoch 299/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3515.2688 - mae: 3515.2688\n",
            "Epoch 300/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3501.6819 - mae: 3501.6819\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8748571a90>"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_model_6.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxOXRRomVCSx",
        "outputId": "c6aac6ee-3550-47ac-c4b0-0a75a52c5118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 3ms/step - loss: 3368.9800 - mae: 3368.9800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3368.97998046875, 3368.97998046875]"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    }
  ]
}